<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>YeSQL on The Art of PostgreSQL</title>
    <link>https://tapoueh.org/categories/yesql/</link>
    <description>Recent content in YeSQL on The Art of PostgreSQL</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <lastBuildDate>Tue, 14 Dec 2021 22:36:36 +0100</lastBuildDate><atom:link href="https://tapoueh.org/categories/yesql/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>Postgres HA: roles are dynamic</title>
      <link>https://tapoueh.org/blog/2021/12/postgres-ha-roles-are-dynamic/</link>
      <pubDate>Tue, 14 Dec 2021 22:36:36 +0100</pubDate>
      
      <guid>https://tapoueh.org/blog/2021/12/postgres-ha-roles-are-dynamic/</guid>
      <description>&lt;p&gt;High-Availability comes with some impact on your architecture choices, in
particular when applied to RDBMS such as Postgres. One such impact is the
idea of a failover. When implementing database HA, it is usually expected
that both the service and the data are maintained available in the face of
operational faults. The most common way to implement resilience includes
automated (or manual) failover, where a new primary is elected among a list
of standby nodes.&lt;/p&gt;
&lt;p&gt;In other words, as soon as Postgres High-Availability is implemented, the
roles of your Postgres nodes are dynamic. The fact that a given node is a
primary or a standby at any given point in time ceases to be relevant to
understanding your architecture. In fact, the only thing that&amp;rsquo;s now given
about the role of a node is that it will change. Otherwise you don&amp;rsquo;t have
failover capability, and then, you probably don&amp;rsquo;t have HA in the first
place, right?&lt;/p&gt;
&lt;p&gt;In this article we are going to try and understand what having dynamic roles
for Postgres nodes in a HA system means.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>An introduction to the pg_auto_failover project</title>
      <link>https://tapoueh.org/blog/2021/11/an-introduction-to-the-pg_auto_failover-project/</link>
      <pubDate>Wed, 10 Nov 2021 17:11:29 +0100</pubDate>
      
      <guid>https://tapoueh.org/blog/2021/11/an-introduction-to-the-pg_auto_failover-project/</guid>
      <description>&lt;p&gt;We just released &lt;a href=&#34;https://github.com/citusdata/pg_auto_failover/releases/tag/v1.6.3&#34;&gt;pg_auto_failover version
1.6.3&lt;/a&gt; on
GitHub, and the binary packages should be already available at the usual
PGDG and CitusData places, both for debian based distributions and RPM based
distributions too.&lt;/p&gt;
&lt;p&gt;This article is an introduction to the pg_auto_failover project: we answer
the &lt;em&gt;Five W&lt;/em&gt; questions, starting with why does the project exist in the
first place?&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;TL;DR&lt;/strong&gt; pg_auto_failover is an awesome project. It fills the gap between
&lt;em&gt;“Postgres is awesome, makes developping my application so much easier, it
solves so many problems for me!”&lt;/em&gt; and the next step &lt;em&gt;“so, how do I run
Postgres in Production?”&lt;/em&gt;. If you&amp;rsquo;re not sure how to bridge that gap
yourself, how to deploy your first production system with automated
failover, then pg_auto_failover is for you. It is simple to use, user
friendly, and well documented. &lt;strong&gt;Star it&lt;/strong&gt; on the &lt;a href=&#34;https://github.com/citusdata/pg_auto_failover&#34;&gt;pg_auto_failover GitHub
repository&lt;/a&gt; and get started
today. Consider contributing to the project, it is fully Open Source, and
you are welcome to join us.&lt;/p&gt;
&lt;p&gt;Buckle up, our guide tour is starting now!&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>PostgreSQL as a Microservice</title>
      <link>https://tapoueh.org/blog/2021/06/postgresql-as-a-microservice/</link>
      <pubDate>Tue, 08 Jun 2021 13:40:00 +0200</pubDate>
      
      <guid>https://tapoueh.org/blog/2021/06/postgresql-as-a-microservice/</guid>
      <description>The MACI French podcast honoured me with an invitation to a guest appearance on their weekly schedule. As you can imagine, we talked about many things related to PostgreSQL&amp;hellip; and also reacted to some newsworthy articles carefully curated by the MACI team. One of the topics we discussed in the podcast started with looking at PostgreSQL through the angle of it being one of the microservices that your application would be composed of.</description>
    </item>
    
    <item>
      <title>2020: Online Conferences</title>
      <link>https://tapoueh.org/blog/2020/11/2020-online-conferences/</link>
      <pubDate>Fri, 27 Nov 2020 13:10:00 +0100</pubDate>
      
      <guid>https://tapoueh.org/blog/2020/11/2020-online-conferences/</guid>
      <description>Among a lot of other changes, the year 2020 brings Online Conferences to us. In the Postgres community too we now record our talks at home and send a video file to be playedto a virtual audience, and sometimes shared later in a platform online.
So this year I did participate in Postgres Vision 2020 where I did deliver a talk about The Art of PostgreSQL. This a talk all about the book that I have written and self-publish at The Art of PostgreSQL: learn how to turn thousands of lines of code into simple SQL queries.</description>
    </item>
    
    <item>
      <title>List PostgreSQL tables using extensions</title>
      <link>https://tapoueh.org/blog/2019/11/list-postgresql-tables-using-extensions/</link>
      <pubDate>Tue, 12 Nov 2019 19:30:00 +0200</pubDate>
      
      <guid>https://tapoueh.org/blog/2019/11/list-postgresql-tables-using-extensions/</guid>
      <description>&lt;p&gt;Postgres has extensions, and that&amp;rsquo;s awesome! Of course as the author of
&lt;code&gt;CREATE EXTENSION&lt;/code&gt; I&amp;rsquo;m a little biased… just remember that the ability to
extend Postgres is way more than just this command. The whole database
system has been design from the ground up to allow for extensibility. Parts
of the design is to be found in the way you can register new objects at
runtime: functions of course, and also data types, operators, index support
structures such as operator classes and families, even index access methods!&lt;/p&gt;
&lt;p&gt;Today&amp;rsquo;s article shows a query that you can use to list those tables in your
schemas that are using a data type which is provided by an extension.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Postgres Connection Strings and psql</title>
      <link>https://tapoueh.org/blog/2019/09/postgres-connection-strings-and-psql/</link>
      <pubDate>Wed, 04 Sep 2019 11:38:02 +0200</pubDate>
      
      <guid>https://tapoueh.org/blog/2019/09/postgres-connection-strings-and-psql/</guid>
      <description>&lt;p&gt;&lt;a href=&#34;https://www.postgresql.org/docs/current/libpq-connect.html#LIBPQ-CONNSTRING&#34;&gt;PostgreSQL connection
strings&lt;/a&gt;
embedded in your application can take two different forms: the key-value
notation or the &lt;code&gt;postgresql://&lt;/code&gt; URI scheme. When it comes to using &lt;code&gt;psql&lt;/code&gt;
though, another form of connection string is introduced, with command line
options &lt;code&gt;-h -p -U&lt;/code&gt; and environment variable support.&lt;/p&gt;
&lt;p&gt;In this short article you will learn that you can use either of the three
different forms in &lt;code&gt;psql&lt;/code&gt; and thus easily copy &amp;amp; paste you application
connection string right at the console to test it!&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>The Art Of PostgreSQL</title>
      <link>https://tapoueh.org/blog/2019/08/the-art-of-postgresql/</link>
      <pubDate>Mon, 26 Aug 2019 10:15:00 +0100</pubDate>
      
      <guid>https://tapoueh.org/blog/2019/08/the-art-of-postgresql/</guid>
      <description>&lt;p&gt;I did it again! Today I am releasing the new edition of my book, with a new
title: “The Art of PostgreSQL”. I&amp;rsquo;m very happy (and quite excited) to
declare my book as &lt;em&gt;Generally Available&lt;/em&gt;!&lt;/p&gt;
&lt;figure class=&#34;right&#34;&gt;&lt;a href=&#34;https://theartofpostgresql.com&#34;&gt;&lt;img src=&#34;https://tapoueh.org/img/TAOPCoverTablet.png&#34;/&gt;&lt;/a&gt;
&lt;/figure&gt;

&lt;p&gt;&lt;a href=&#34;https://theartofpostgresql.com&#34;&gt;The Art of PostgreSQL&lt;/a&gt; is the new edition
of my previous release, &lt;em&gt;Mastering PostgreSQL in Application Development&lt;/em&gt;.
It contains mostly fixes to the old content, a new title, and a new book
design (PDF and paperback). Content wise, &lt;a href=&#34;https://theartofpostgresql.com&#34;&gt;The Art of
PostgreSQL&lt;/a&gt; also comes with a new whole
chapter about PostgreSQL Extensions.&lt;/p&gt;
&lt;p&gt;The new chapter covers extensions such as &lt;code&gt;hstore&lt;/code&gt;, &lt;code&gt;pg_trgm&lt;/code&gt;, &lt;code&gt;intarray&lt;/code&gt;,
&lt;code&gt;earthdistance&lt;/code&gt;, &lt;code&gt;ip4r&lt;/code&gt;, and &lt;code&gt;hll&lt;/code&gt; or HyperLogLog, one of the all times
favorite extensions of &lt;a href=&#34;http://www.craigkerstiens.com&#34;&gt;Craig Kerstiens&lt;/a&gt;… who
made himself available to answer my questions and share his view of
PostgreSQL Extensions in an interview!&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Preventing SQL Injections</title>
      <link>https://tapoueh.org/blog/2018/11/preventing-sql-injections/</link>
      <pubDate>Sat, 10 Nov 2018 15:40:01 +0100</pubDate>
      
      <guid>https://tapoueh.org/blog/2018/11/preventing-sql-injections/</guid>
      <description>&lt;p&gt;An &lt;em&gt;SQL Injection&lt;/em&gt; is a security breach, one made famous by the &lt;a href=&#34;https://xkcd.com/327/&#34;&gt;Exploits of
a Mom&lt;/a&gt; &lt;code&gt;xkcd&lt;/code&gt; comic episode in which we read about
&lt;em&gt;little Bobby Tables&lt;/em&gt;:&lt;/p&gt;
&lt;figure class=&#34;center&#34;&gt;&lt;a href=&#34;https://xkcd.com/327/&#34;&gt;&lt;img src=&#34;https://tapoueh.org/img/exploits_of_a_mom.png&#34;/&gt;&lt;/a&gt;
&lt;/figure&gt;

&lt;p&gt;PostgreSQL implements a protocol level facility to send the static SQL query
text separately from its dynamic arguments. An SQL injection happens when
the database server is mistakenly led to consider a dynamic argument of a
query as part of the query text. Sending those parts as separate entities
over the protocol means that SQL injection is no longer possible.&lt;/p&gt;
&lt;!--toc--&gt;</description>
    </item>
    
    <item>
      <title>Geolocation with PostgreSQL</title>
      <link>https://tapoueh.org/blog/2018/08/geolocation-with-postgresql/</link>
      <pubDate>Fri, 24 Aug 2018 12:11:33 +0200</pubDate>
      
      <guid>https://tapoueh.org/blog/2018/08/geolocation-with-postgresql/</guid>
      <description>&lt;p&gt;We have loaded Open Street Map points of interests in the article &lt;a href=&#34;https://tapoueh.org/blog/2013/08/the-most-popular-pub-names/&#34;&gt;The Most
Popular Pub Names&lt;/a&gt; — which
compares PostgreSQL with MongoDB for simple geographical queries, and is
part of our &lt;a href=&#34;https://tapoueh.org/tags/extensions/&#34;&gt;PostgreSQL Extensions&lt;/a&gt; article series. In
today&amp;rsquo;s article, look at how to geolocalize an IP address and locate the
nearest pub, all within a single SQL query!&lt;/p&gt;
&lt;p&gt;For that, we are going to use the awesome
&lt;a href=&#34;https://github.com/RhodiumToad/ip4r&#34;&gt;ip4r&lt;/a&gt; extension from
&lt;a href=&#34;http://blog.rhodiumtoad.org.uk/&#34;&gt;RhodiumToad&lt;/a&gt;.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>PostgreSQL Concurrency: an Article Series</title>
      <link>https://tapoueh.org/blog/2018/08/postgresql-concurrency-an-article-series/</link>
      <pubDate>Tue, 14 Aug 2018 11:49:02 +0300</pubDate>
      
      <guid>https://tapoueh.org/blog/2018/08/postgresql-concurrency-an-article-series/</guid>
      <description>&lt;p&gt;&lt;a href=&#34;https://www.postgresql.org&#34;&gt;PostgreSQL&lt;/a&gt; is a relational database management
system. It&amp;rsquo;s even the world&amp;rsquo;s most advanced open source one of them. As
such, as its core, Postgres solves concurrent access to a set of data and
maintains consistency while allowing concurrent operations.&lt;/p&gt;
&lt;p&gt;In the &lt;a href=&#34;https://tapoueh.org/tags/concurrency/&#34;&gt;PostgreSQL Concurrency&lt;/a&gt; series of articles here
we did see several aspects of how to handle concurrent use cases of your
application design with PostgreSQL. The main thing to remember is that a
Database Management System first task is to handle concurrency access to the
data for you.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Scheduled Data Processing: How to use cron?</title>
      <link>https://tapoueh.org/blog/2018/08/scheduled-data-processing-how-to-use-cron/</link>
      <pubDate>Wed, 01 Aug 2018 11:24:25 +0200</pubDate>
      
      <guid>https://tapoueh.org/blog/2018/08/scheduled-data-processing-how-to-use-cron/</guid>
      <description>&lt;p&gt;A previous article in the &lt;a href=&#34;https://tapoueh.org/tags/concurrency&#34;&gt;PostgreSQL Concurrency&lt;/a&gt; series
covered how to manage concurrent retweets in an efficient way: in &lt;a href=&#34;https://tapoueh.org/blog/2018/07/computing-and-caching/&#34;&gt;Computing
and Caching&lt;/a&gt;, we learnt how to
maintain a cache right in your PostgreSQL database, using MATERIALIZED
VIEWS. We also had a look at how to take care of &lt;a href=&#34;https://tapoueh.org/blog/2018/07/batch-updates-and-concurrency/&#34;&gt;Batch Updates and
Concurrency&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;While in the first case we are providing a solution to a technical problem
where we want to solve performance issues while keeping the same semantics,
in the second case we are actually implementing a part of the application&amp;rsquo;s
&lt;a href=&#34;https://tapoueh.org/blog/2017/06/sql-and-business-logic/&#34;&gt;Business Logic&lt;/a&gt; as a scheduled job.&lt;/p&gt;
&lt;p&gt;Today&amp;rsquo;s article shows a modern technique to handle the scheduling of those
business oriented activities that are not tied to any user activity. When
thinking about it this way, you certainly don&amp;rsquo;t want to implement the
backbone of your business logic in a &lt;em&gt;shell script&lt;/em&gt; that&amp;rsquo;s directly
maintained in the production environment, do you?&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Batch Updates and Concurrency</title>
      <link>https://tapoueh.org/blog/2018/07/batch-updates-and-concurrency/</link>
      <pubDate>Mon, 23 Jul 2018 22:45:43 +0200</pubDate>
      
      <guid>https://tapoueh.org/blog/2018/07/batch-updates-and-concurrency/</guid>
      <description>&lt;p&gt;This article fits in the &lt;a href=&#34;https://tapoueh.org/tags/concurrency&#34;&gt;PostgreSQL Concurrency&lt;/a&gt; series,
where we installed a tweeter like application schema and had all the
characters from Shakespeare&amp;rsquo;s &lt;em&gt;A Midsummer Night&amp;rsquo;s Dream&lt;/em&gt; tweet their own
lines in our database in &lt;a href=&#34;https://tapoueh.org/blog/2018/06/PostgreSQL-DML.md&#34;&gt;PostgreSQL Concurrency: Data Modification
Language&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;A previous article in the series covered how to manage concurrent retweets
in an efficient way: &lt;a href=&#34;https://tapoueh.org/blog/2018/07/computing-and-caching/&#34;&gt;Computing and
Caching&lt;/a&gt;, where we learn how to
maintain a cache right in your PostgreSQL database, thanks for materialized
views. We even went as far as maintaining an &lt;em&gt;external&lt;/em&gt; cache in another
application layer using PostgreSQL
&lt;a href=&#34;https://www.postgresql.org/docs/current/static/sql-listen.html&#34;&gt;LISTEN&lt;/a&gt; and
&lt;a href=&#34;https://www.postgresql.org/docs/current/static/sql-notify.html&#34;&gt;NOTIFY&lt;/a&gt;
features and a Golang application.&lt;/p&gt;
&lt;p&gt;Today&amp;rsquo;s article is going to address concurrency in the context of updating
data in a batch. This activity is quite common, as soon as your system is
connected to other systems either internally or with external providers.
While it&amp;rsquo;s pretty easy to ingest new data, and easy enough to update data
from an external source when nothing happens in your database, doing the
operation safely with concurrent activity is more complex. Once more though,
PostgreSQL comes with all the tooling you need to handle that situation.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>PostgreSQL LISTEN/NOTIFY</title>
      <link>https://tapoueh.org/blog/2018/07/postgresql-listen/notify/</link>
      <pubDate>Thu, 19 Jul 2018 12:58:21 +0200</pubDate>
      
      <guid>https://tapoueh.org/blog/2018/07/postgresql-listen/notify/</guid>
      <description>&lt;p&gt;This article fits in the &lt;a href=&#34;https://tapoueh.org/tags/concurrency&#34;&gt;PostgreSQL Concurrency&lt;/a&gt; series,
where we installed a tweeter like application schema and had all the
characters from Shakespeare&amp;rsquo;s &lt;em&gt;A Midsummer Night&amp;rsquo;s Dream&lt;/em&gt; tweet their own
lines in our database in &lt;a href=&#34;https://tapoueh.org/blog/2018/06/PostgreSQL-DML.md&#34;&gt;PostgreSQL Concurrency: Data Modification
Language&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;A previous article in the series covered how to manage concurrent retweets
in an efficient way: &lt;a href=&#34;https://tapoueh.org/blog/2018/07/computing-and-caching/&#34;&gt;Computing and
Caching&lt;/a&gt;, where we learn how to
maintain a cache right in your PostgreSQL database, thanks for materialized
views.&lt;/p&gt;
&lt;p&gt;Today&amp;rsquo;s article shows how to maintain an &lt;em&gt;external&lt;/em&gt; cache in another
application layer. In this article we are going to maintain an in-memory
cache in a Golang service, using PostgreSQL
&lt;a href=&#34;https://www.postgresql.org/docs/current/static/sql-listen.html&#34;&gt;LISTEN&lt;/a&gt; and
&lt;a href=&#34;https://www.postgresql.org/docs/current/static/sql-notify.html&#34;&gt;NOTIFY&lt;/a&gt;
features.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>PostgreSQL Event Based Processing</title>
      <link>https://tapoueh.org/blog/2018/07/postgresql-event-based-processing/</link>
      <pubDate>Mon, 16 Jul 2018 09:27:54 +0200</pubDate>
      
      <guid>https://tapoueh.org/blog/2018/07/postgresql-event-based-processing/</guid>
      <description>&lt;p&gt;In the previous article of the series &lt;a href=&#34;https://tapoueh.org/blog/2018/07/modeling-for-concurrency/&#34;&gt;Modeling for
Concurrency&lt;/a&gt;, we saw how to model
your application for highly concurrent activity. It was a follow-up to the
article entitled &lt;a href=&#34;https://tapoueh.org/blog/2018/07/postgresql-concurrency-isolation-and-locking/&#34;&gt;PostgreSQL Concurrency: Isolation and
Locking&lt;/a&gt;, which
was a primer on PostgreSQL isolation and locking properties and behaviors.&lt;/p&gt;
&lt;p&gt;Today&amp;rsquo;s article takes us a step further and builds on what we did in the
previous articles in our series. After having had all the characters from
Shakespeare&amp;rsquo;s &lt;em&gt;A Midsummer Night&amp;rsquo;s Dream&lt;/em&gt; tweet their own lines in our
database in &lt;a href=&#34;https://tapoueh.org/blog/2018/06/PostgreSQL-DML.md&#34;&gt;PostgreSQL Concurrency: Data Modification
Language&lt;/a&gt;, and having had them like and
retweet a lot in &lt;a href=&#34;https://tapoueh.org/blog/2018/07/postgresql-concurrency-isolation-and-locking/&#34;&gt;PostgreSQL Concurrency: Isolation and
Locking&lt;/a&gt;, we
saw how to manage concurrent retweets in an efficient way in &lt;a href=&#34;https://tapoueh.org/blog/2018/07/computing-and-caching/&#34;&gt;Computing and
Caching&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;What we did implement in the previous article is a &lt;em&gt;cache&lt;/em&gt; system, all with
its necessary &lt;strong&gt;cache invalidation policy&lt;/strong&gt;. Sometimes though, the
processing of an &lt;em&gt;event&lt;/em&gt; needs to happen within the same transaction where
the event is registered in your system. PostgreSQL makes it possible to
maintain a summary table transactionally thanks to its
&lt;a href=&#34;https://www.postgresql.org/docs/current/static/sql-createtrigger.html&#34;&gt;trigger&lt;/a&gt;
support. Today, we&amp;rsquo;re going to dive in how to maintain a summary table with
triggers, and its impact on concurrency.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Computing and Caching</title>
      <link>https://tapoueh.org/blog/2018/07/computing-and-caching/</link>
      <pubDate>Fri, 13 Jul 2018 13:10:21 +0200</pubDate>
      
      <guid>https://tapoueh.org/blog/2018/07/computing-and-caching/</guid>
      <description>&lt;p&gt;Let&amp;rsquo;s continue to dive in PostgreSQL Concurrency. In the previous article of
the series, &lt;a href=&#34;https://tapoueh.org/blog/2018/07/modeling-for-concurrency/&#34;&gt;Modeling for
Concurrency&lt;/a&gt;, we saw how to model
your application for highly concurrent activity. It was a follow-up to the
article entitled &lt;a href=&#34;https://tapoueh.org/blog/2018/07/postgresql-concurrency-isolation-and-locking/&#34;&gt;PostgreSQL Concurrency: Isolation and
Locking&lt;/a&gt;, which
was a primer on PostgreSQL isolation and locking properties and behaviors.&lt;/p&gt;
&lt;p&gt;Today&amp;rsquo;s article takes us a step further and builds on what we did in the
previous articles in our series. After having had all the characters from
Shakespeare&amp;rsquo;s &lt;em&gt;A Midsummer Night&amp;rsquo;s Dream&lt;/em&gt; tweet their own lines in our
database in &lt;a href=&#34;https://tapoueh.org/blog/2018/06/PostgreSQL-DML.md&#34;&gt;PostgreSQL Concurrency: Data Modification
Language&lt;/a&gt;, and having had them like a
retweet a lot in &lt;a href=&#34;https://tapoueh.org/blog/2018/07/postgresql-concurrency-isolation-and-locking/&#34;&gt;PostgreSQL Concurrency: Isolation and
Locking&lt;/a&gt;, it&amp;rsquo;s
time to think about how to display our counters in an efficient way.&lt;/p&gt;
&lt;p&gt;In this article, we&amp;rsquo;re going to think about when we should compute results
and when we should cache them for instant retrieval, all within the SQL
tooling. The SQL tooling for handling cache is a &lt;a href=&#34;https://www.postgresql.org/docs/current/static/sql-creatematerializedview.html&#34;&gt;MATERIALIZED
VIEW&lt;/a&gt;,
and it comes with &lt;strong&gt;cache invalidation&lt;/strong&gt; routines, of course.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Modeling for Concurrency</title>
      <link>https://tapoueh.org/blog/2018/07/modeling-for-concurrency/</link>
      <pubDate>Tue, 10 Jul 2018 10:26:47 +0200</pubDate>
      
      <guid>https://tapoueh.org/blog/2018/07/modeling-for-concurrency/</guid>
      <description>&lt;p&gt;Let&amp;rsquo;s continue to dive in PostgreSQL Concurrency. Last week&amp;rsquo;s article
&lt;a href=&#34;https://tapoueh.org/blog/2018/07/postgresql-concurrency-isolation-and-locking/&#34;&gt;PostgreSQL Concurrency: Isolation and
Locking&lt;/a&gt; was a
primer on PostgreSQL isolation and locking properties and behaviors.&lt;/p&gt;
&lt;p&gt;Today&amp;rsquo;s article takes us a step further and builds on what we did last week,
in particular the database modeling for a &lt;em&gt;tweet&lt;/em&gt; like application. After
having had all the characters from Shakespeare&amp;rsquo;s &lt;em&gt;A Midsummer Night&amp;rsquo;s Dream&lt;/em&gt;
tweet their own lines in our database in &lt;a href=&#34;https://tapoueh.org/blog/2018/06/PostgreSQL-DML.md&#34;&gt;PostgreSQL Concurrency: Data
Modification Language&lt;/a&gt;, it&amp;rsquo;s time for them
to do some actions on the tweets: likes and retweet.&lt;/p&gt;
&lt;p&gt;Of course, we&amp;rsquo;re going to put concurrency to the test, so we&amp;rsquo;re going to
have to handle very very popular tweets from the play!&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>PostgreSQL Concurrency: Isolation and Locking</title>
      <link>https://tapoueh.org/blog/2018/07/postgresql-concurrency-isolation-and-locking/</link>
      <pubDate>Tue, 03 Jul 2018 13:30:13 +0200</pubDate>
      
      <guid>https://tapoueh.org/blog/2018/07/postgresql-concurrency-isolation-and-locking/</guid>
      <description>&lt;p&gt;&lt;a href=&#34;https://www.postgresql.org&#34;&gt;PostgreSQL&lt;/a&gt; is a relational database management
system. It&amp;rsquo;s even the world&amp;rsquo;s most advanced open source one of them. As
such, as its core, Postgres solves concurrent access to a set of data and
maintains consistency while allowing concurrent operations.&lt;/p&gt;
&lt;p&gt;This article is a primer on PostgreSQL Isolation and Locking properties and
behaviors. You might be interested into the previous article in the series:
&lt;a href=&#34;https://tapoueh.org/blog/2018/06/postgresql-concurrency-data-modification-language/&#34;&gt;PostgreSQL Concurrency: Data Modification
Language&lt;/a&gt;.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>PostgreSQL Concurrency: Data Modification Language</title>
      <link>https://tapoueh.org/blog/2018/06/postgresql-concurrency-data-modification-language/</link>
      <pubDate>Mon, 25 Jun 2018 09:58:53 +0200</pubDate>
      
      <guid>https://tapoueh.org/blog/2018/06/postgresql-concurrency-data-modification-language/</guid>
      <description>PostgreSQL is a relational database management system. It&amp;rsquo;s even the world&amp;rsquo;s most advanced open source one of them. As such, as its core, Postgres solves concurrent access to a set of data and maintains consistency while allowing concurrent operations.
Postgres exposes its concurrency APIs in the SQL language, in particular in the DML parts of it: you can read the Data Manipulation Language chapter of the PostgreSQL docs for all the details.</description>
    </item>
    
    <item>
      <title>PostgreSQL Data Types</title>
      <link>https://tapoueh.org/blog/2018/05/postgresql-data-types/</link>
      <pubDate>Thu, 24 May 2018 14:47:05 +0200</pubDate>
      
      <guid>https://tapoueh.org/blog/2018/05/postgresql-data-types/</guid>
      <description>&lt;p&gt;Today it&amp;rsquo;s time to conclude our series of &lt;a href=&#34;https://tapoueh.org/tags/data-types/&#34;&gt;PostgreSQL Data
Types&lt;/a&gt; articles with a recap. The series cover lots of
core PostgreSQL data types and shows how to benefit from the PostgreSQL
concept of a data type: more than input validation, a PostgreSQL data type
also implements expected behaviors and processing functions.&lt;/p&gt;
&lt;p&gt;This allows an application developer to rely on PostgreSQL for more complex
queries, having the processing happen where the data is, for instance when
implementing advanced JOIN operations, then retrieving only the data set
that is interesting for the application.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>PostgreSQL Data Types: Point</title>
      <link>https://tapoueh.org/blog/2018/05/postgresql-data-types-point/</link>
      <pubDate>Mon, 07 May 2018 10:46:17 +0200</pubDate>
      
      <guid>https://tapoueh.org/blog/2018/05/postgresql-data-types-point/</guid>
      <description>&lt;p&gt;Continuing our series of &lt;a href=&#34;https://tapoueh.org/tags/data-types/&#34;&gt;PostgreSQL Data Types&lt;/a&gt; today
we&amp;rsquo;re going to introduce the PostgreSQL Point type.&lt;/p&gt;
&lt;p&gt;In order to put the Point datatype in a context where it makes sense, we&amp;rsquo;re
going to download a complete geolocation data set and normalize it, thus
making good use of both the normalization good practice and those other
PostgreSQL data types we&amp;rsquo;ve been learning about in the previous articles of
this series.&lt;/p&gt;
&lt;p&gt;Buckle-up, this is a long article with a lot of SQL inside.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>PostgreSQL Data Types: ENUM</title>
      <link>https://tapoueh.org/blog/2018/05/postgresql-data-types-enum/</link>
      <pubDate>Wed, 02 May 2018 11:00:26 +0200</pubDate>
      
      <guid>https://tapoueh.org/blog/2018/05/postgresql-data-types-enum/</guid>
      <description>&lt;p&gt;Continuing our series of &lt;a href=&#34;https://tapoueh.org/tags/data-types/&#34;&gt;PostgreSQL Data Types&lt;/a&gt; today
we&amp;rsquo;re going to introduce the PostgreSQL ENUM type.&lt;/p&gt;
&lt;p&gt;This data type has been added to PostgreSQL in order to make it easier to
support migrations from MySQL. Proper relational design would use a
reference table and a foreign key instead.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>PostgreSQL Data Types: JSON</title>
      <link>https://tapoueh.org/blog/2018/04/postgresql-data-types-json/</link>
      <pubDate>Mon, 30 Apr 2018 09:49:33 +0200</pubDate>
      
      <guid>https://tapoueh.org/blog/2018/04/postgresql-data-types-json/</guid>
      <description>&lt;p&gt;Continuing our series of &lt;a href=&#34;https://tapoueh.org/tags/data-types/&#34;&gt;PostgreSQL Data Types&lt;/a&gt; today
we&amp;rsquo;re going to introduce the PostgreSQL JSON type.&lt;/p&gt;
&lt;p&gt;PostgreSQL has built-in support for JSON with a great range of processing
functions and operators, and complete indexing support. The documentation
covers all the details in the chapters entitled &lt;a href=&#34;https://www.postgresql.org/docs/current/static/datatype-json.html&#34;&gt;JSON
Types&lt;/a&gt;
and &lt;a href=&#34;https://www.postgresql.org/docs/current/static/functions-json.html&#34;&gt;JSON Functions and
Operators&lt;/a&gt;.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>PostgreSQL Data Types: XML</title>
      <link>https://tapoueh.org/blog/2018/04/postgresql-data-types-xml/</link>
      <pubDate>Mon, 23 Apr 2018 18:18:48 +0200</pubDate>
      
      <guid>https://tapoueh.org/blog/2018/04/postgresql-data-types-xml/</guid>
      <description>&lt;p&gt;Continuing our series of &lt;a href=&#34;https://tapoueh.org/tags/data-types/&#34;&gt;PostgreSQL Data Types&lt;/a&gt; today
we&amp;rsquo;re going to introduce the PostgreSQL XML type.&lt;/p&gt;
&lt;p&gt;The SQL standard includes a &lt;a href=&#34;https://en.wikipedia.org/wiki/SQL/XML&#34;&gt;SQL/XML&lt;/a&gt;
which &lt;em&gt;introduces the predefined data type XML together with constructors,
several routines, functions, and XML-to-SQL data type mappings to support
manipulation and storage of XML in a SQL database&lt;/em&gt;, as per the Wikipedia
page.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>PostgreSQL Data Types: Arrays</title>
      <link>https://tapoueh.org/blog/2018/04/postgresql-data-types-arrays/</link>
      <pubDate>Fri, 20 Apr 2018 14:47:25 +0200</pubDate>
      
      <guid>https://tapoueh.org/blog/2018/04/postgresql-data-types-arrays/</guid>
      <description>&lt;p&gt;Continuing our series of &lt;a href=&#34;https://tapoueh.org/tags/data-types/&#34;&gt;PostgreSQL Data Types&lt;/a&gt; today
we&amp;rsquo;re going to introduce the PostgreSQL array data types.&lt;/p&gt;
&lt;p&gt;Arrays can be used to denormalize data and avoid lookup tables. A good rule
of thumb for using them that way is that you mostly use the array as a
whole, even if you might at times search for elements in the array. Heavier
processing is going to be more complex than a lookup table.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>PostgreSQL Data Types: Ranges</title>
      <link>https://tapoueh.org/blog/2018/04/postgresql-data-types-ranges/</link>
      <pubDate>Wed, 18 Apr 2018 13:41:12 +0200</pubDate>
      
      <guid>https://tapoueh.org/blog/2018/04/postgresql-data-types-ranges/</guid>
      <description>&lt;p&gt;Continuing our series of &lt;a href=&#34;https://tapoueh.org/tags/data-types/&#34;&gt;PostgreSQL Data Types&lt;/a&gt; today
we&amp;rsquo;re going to introduce the PostgreSQL ranges data type.&lt;/p&gt;
&lt;p&gt;Range types are a unique feature of PostgreSQL, managing two dimensions of
data in a single column, and allowing advanced processing. The main example
is the &lt;em&gt;daterange&lt;/em&gt; data type, which stores as a single value a lower and an
upper bound of the range as a single value. This allows PostgreSQL to
implement a concurrent safe check against &lt;em&gt;overlapping&lt;/em&gt; ranges, as we&amp;rsquo;re
going to see in this article.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>PostgreSQL Data Types: Network Addresses</title>
      <link>https://tapoueh.org/blog/2018/04/postgresql-data-types-network-addresses/</link>
      <pubDate>Mon, 16 Apr 2018 12:32:53 +0200</pubDate>
      
      <guid>https://tapoueh.org/blog/2018/04/postgresql-data-types-network-addresses/</guid>
      <description>&lt;p&gt;Continuing our series of &lt;a href=&#34;https://tapoueh.org/tags/data-types/&#34;&gt;PostgreSQL Data Types&lt;/a&gt; today
we&amp;rsquo;re going to introduce network address types.&lt;/p&gt;
&lt;p&gt;PostgreSQL includes support for both &lt;em&gt;cidr&lt;/em&gt;, &lt;em&gt;inet&lt;/em&gt;, and &lt;em&gt;macaddr&lt;/em&gt; data
types. Again, those types are bundled with indexing support and advanced
functions and operator support.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>PostgreSQL Data Types: Date and Time Processing</title>
      <link>https://tapoueh.org/blog/2018/04/postgresql-data-types-date-and-time-processing/</link>
      <pubDate>Fri, 13 Apr 2018 13:35:47 +0200</pubDate>
      
      <guid>https://tapoueh.org/blog/2018/04/postgresql-data-types-date-and-time-processing/</guid>
      <description>&lt;p&gt;Continuing our series of &lt;a href=&#34;https://tapoueh.org/tags/data-types/&#34;&gt;PostgreSQL Data Types&lt;/a&gt; today
we&amp;rsquo;re going to introduce date and time based processing functions.&lt;/p&gt;
&lt;p&gt;Once the application&amp;rsquo;s data, or rather the user data is properly stored as
timestamp with time zone, PostgreSQL allows implementing all the processing
you need to. In this article we dive into a set of examples to help you get
started with time based processing in your database. Can we boost your
reporting skills?&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>PostgreSQL Data Types: Text Processing</title>
      <link>https://tapoueh.org/blog/2018/04/postgresql-data-types-text-processing/</link>
      <pubDate>Wed, 11 Apr 2018 23:15:42 +0200</pubDate>
      
      <guid>https://tapoueh.org/blog/2018/04/postgresql-data-types-text-processing/</guid>
      <description>&lt;p&gt;Continuing our series of &lt;a href=&#34;https://tapoueh.org/tags/data-types/&#34;&gt;PostgreSQL Data Types&lt;/a&gt; today
we&amp;rsquo;re going to introduce some of the PostgreSQL text processing functions.&lt;/p&gt;
&lt;p&gt;There&amp;rsquo;s a very rich set of PostgreSQL functions to process text — you can
find them all in the &lt;a href=&#34;https://www.postgresql.org/docs/current/static/functions-string.html&#34;&gt;string functions and
operators&lt;/a&gt;
documentation chapter — with functions such as &lt;em&gt;overlay()&lt;/em&gt;, &lt;em&gt;substring()&lt;/em&gt;,
&lt;em&gt;position()&lt;/em&gt; or &lt;em&gt;trim()&lt;/em&gt;. Or aggregates such as &lt;em&gt;string_agg()&lt;/em&gt;. There are
also &lt;em&gt;regular expression&lt;/em&gt; functions, including the very powerful
&lt;em&gt;regexp_split_to_table()&lt;/em&gt;. In this article we see practical example putting
them in practice.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>PostgreSQL Data Types: Text Encoding</title>
      <link>https://tapoueh.org/blog/2018/04/postgresql-data-types-text-encoding/</link>
      <pubDate>Mon, 09 Apr 2018 13:33:01 +0200</pubDate>
      
      <guid>https://tapoueh.org/blog/2018/04/postgresql-data-types-text-encoding/</guid>
      <description>&lt;p&gt;Continuing our series of &lt;a href=&#34;https://tapoueh.org/tags/data-types/&#34;&gt;PostgreSQL Data Types&lt;/a&gt; today
we&amp;rsquo;re going to introduce the PostgreSQL text data type. The first notion to
understand when processing text in any program is of course the notion of
encoding.&lt;/p&gt;
&lt;p&gt;So when addressing the text datatype we must mention encoding settings, and
possibly also issues. An encoding is a particular representation of
characters in bits and bytes. In the ASCII encoding the letter &lt;code&gt;A&lt;/code&gt; is
encoded as the 7-bits byte &lt;code&gt;1000001&lt;/code&gt;, or 65 in decimal, or 41 in
hexadecimal. All those numbers are going to be written the same way on-disk,
and the letter &lt;code&gt;A&lt;/code&gt; too.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>PostgreSQL Data Types: an intro</title>
      <link>https://tapoueh.org/blog/2018/04/postgresql-data-types-an-intro/</link>
      <pubDate>Fri, 06 Apr 2018 11:32:43 +0200</pubDate>
      
      <guid>https://tapoueh.org/blog/2018/04/postgresql-data-types-an-intro/</guid>
      <description>&lt;p&gt;Today, we&amp;rsquo;re going to begin a dive into the PostgreSQL Data Types. As my
colleague &lt;a href=&#34;https://bitfission.com&#34;&gt;Will Leinweber&lt;/a&gt; said recently in his talk
&lt;a href=&#34;https://www.postgresql.eu/events/pgdayparis2018/schedule/session/1835-constraints-a-developers-secret-weapon/&#34;&gt;Constraints: a Developer&amp;rsquo;s Secret
Weapon&lt;/a&gt;
that he gave at &lt;a href=&#34;https://2018.pgday.paris&#34;&gt;pgDay Paris&lt;/a&gt;: &lt;a href=&#34;https://www.citusdata.com/blog/2018/03/19/postgres-database-constraints/&#34;&gt;database
constraints in Postgres are the last line of
defense&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;The most important of those constraints is the data type, or the &lt;em&gt;attribute
domain&lt;/em&gt; in normalization slang. By declaring an attribute to be of a certain
data type, then PostgreSQL ensures that this property is always true, and
then implements advanced processing features for each data type, so that you
may push the computation to the data, when needed.&lt;/p&gt;
&lt;p&gt;This article is the first of a series that will go through many of the
PostgreSQL data types, and we open the journey with &lt;code&gt;boolean&lt;/code&gt;.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Object Relational Database Management System</title>
      <link>https://tapoueh.org/blog/2018/03/object-relational-database-management-system/</link>
      <pubDate>Thu, 22 Mar 2018 17:40:39 +0100</pubDate>
      
      <guid>https://tapoueh.org/blog/2018/03/object-relational-database-management-system/</guid>
      <description>&lt;p&gt;&lt;a href=&#34;https://www.postgresql.org&#34;&gt;PostgreSQL&lt;/a&gt; is the world&amp;rsquo;s most advanced open
source database, and per the &lt;a href=&#34;https://en.wikipedia.org/wiki/PostgreSQL&#34;&gt;PostgreSQL Wikipedia
page&lt;/a&gt; it is &lt;em&gt;an
&lt;strong&gt;object-relational&lt;/strong&gt; database management system (ORDBMS) with an emphasis
on extensibility and standards compliance&lt;/em&gt;.&lt;/p&gt;
&lt;p&gt;In this article, we try to understand why would PostgreSQL be named an
&lt;em&gt;object-relational&lt;/em&gt; thing. What is Object Oriented Programming and how does
that apply to a database system?&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Database Normalization and Primary Keys</title>
      <link>https://tapoueh.org/blog/2018/03/database-normalization-and-primary-keys/</link>
      <pubDate>Fri, 09 Mar 2018 18:41:33 +0100</pubDate>
      
      <guid>https://tapoueh.org/blog/2018/03/database-normalization-and-primary-keys/</guid>
      <description>&lt;p&gt;In our previous article we saw three classic &lt;a href=&#34;https://tapoueh.org/blog/2018/03/database-modelization-anti-patterns/&#34;&gt;Database Modelization
Anti-Patterns&lt;/a&gt;. The
article also contains a reference to a Primary Key section of my book &lt;a href=&#34;https://theartofpostgresql.com&#34;&gt;The
Art of PostgresQL&lt;/a&gt;, so it&amp;rsquo;s only fair that I
would now publish said Primary Key section!&lt;/p&gt;
&lt;p&gt;So in this article, we dive into Primary Keys as being a cornerstone of
database normalization. It&amp;rsquo;s so important to get Primary Keys right that you
would think everybody knows how to do it, and yet, most of the primary key
constraints I&amp;rsquo;ve seen used in database design are actually not primary keys
at all.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Database Modelization Anti-Patterns</title>
      <link>https://tapoueh.org/blog/2018/03/database-modelization-anti-patterns/</link>
      <pubDate>Thu, 08 Mar 2018 18:00:43 +0100</pubDate>
      
      <guid>https://tapoueh.org/blog/2018/03/database-modelization-anti-patterns/</guid>
      <description>&lt;p&gt;Next week we see two awesome PostgreSQL conferences in Europe, back to back,
with a day in between just so that people may attend both! In chronological
order we have first &lt;a href=&#34;https://2018.nordicpgday.org&#34;&gt;Nordic pgDay&lt;/a&gt; in Oslo
where I will have the pleasure to talk about &lt;a href=&#34;https://www.postgresql.eu/events/nordicpgday2018/schedule/session/1896-data-modeling-normalization-and-denormalization/&#34;&gt;Data Modeling, Normalization
and
Denormalization&lt;/a&gt;.
Then we have &lt;a href=&#34;https://2018.pgday.paris&#34;&gt;pgday.paris&lt;/a&gt; with an awesome
schedule and a strong focus on the needs of application developers!&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Find the number of the longest continuously rising days for a stock</title>
      <link>https://tapoueh.org/blog/2018/02/find-the-number-of-the-longest-continuously-rising-days-for-a-stock/</link>
      <pubDate>Tue, 06 Feb 2018 23:24:17 +0100</pubDate>
      
      <guid>https://tapoueh.org/blog/2018/02/find-the-number-of-the-longest-continuously-rising-days-for-a-stock/</guid>
      <description>&lt;p&gt;Today I want to react to an article that claims that &lt;a href=&#34;https://www.datasciencecentral.com/profiles/blogs/relational-algebra-is-the-root-of-sql-problems&#34;&gt;Relational Algebra Is
the Root of SQL
Problems&lt;/a&gt;
in which the author hand-waves the following position:&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;SQL becomes more a hindrance to data manipulation than an efficient tool.
SQL’s greatest problem isn’t in the implementation level, but at its
theory foundation. The problem can’t be solved by application
optimization. Relational algebra isn’t sophisticated enough for handling
the complicated data manipulation scenarios.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;Then they go on to several &lt;em&gt;arguments from authority&lt;/em&gt; to “prove” their
point. My reading of the article is that SQL is very hard when you didn&amp;rsquo;t
care to learn it, as most technologies are.&lt;/p&gt;
&lt;p&gt;In this article, we&amp;rsquo;re going to look at the &lt;em&gt;simple examples&lt;/em&gt; provided where
apparently SQL makes it so much harder to find a solution compared to
writing some Java or C++ code. Contrary to the original article, we go as
far as to actually writing both the SQL solution and a complete Python
solution, so that we can compare.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Exporting a Hierarchy in JSON: with recursive queries</title>
      <link>https://tapoueh.org/blog/2018/01/exporting-a-hierarchy-in-json-with-recursive-queries/</link>
      <pubDate>Wed, 31 Jan 2018 18:00:01 +0100</pubDate>
      
      <guid>https://tapoueh.org/blog/2018/01/exporting-a-hierarchy-in-json-with-recursive-queries/</guid>
      <description>&lt;p&gt;In another article here, entitled &lt;a href=&#34;https://tapoueh.org/blog/2017/09/on-json-and-sql/&#34;&gt;on JSON and
SQL&lt;/a&gt;, we saw in great details how to import
a data set only available as a giant JSON file. Then we normalized the data
set, so as to be able to write SQL and process our data. This approach is
sometimes very useful and was a good way to learn some of the JSON functions
provided by PostgreSQL.&lt;/p&gt;
&lt;p&gt;In this article, we&amp;rsquo;re going to use SQL to export the data from our
relational model into a JSON document. The trick that makes it complex in
this example is that we have a recursive data model, with a notion of a
&lt;em&gt;parent&lt;/em&gt; row that exists in the same table as the current one. That&amp;rsquo;s a nice
excuse to learn more about the SQL construct &lt;a href=&#34;https://www.postgresql.org/docs/current/static/queries-with.html&#34;&gt;WITH
RECURSIVE&lt;/a&gt;.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>A Year in Review: Most Read Articles in 2017</title>
      <link>https://tapoueh.org/blog/2018/01/a-year-in-review-most-read-articles-in-2017/</link>
      <pubDate>Sun, 28 Jan 2018 22:46:43 +0100</pubDate>
      
      <guid>https://tapoueh.org/blog/2018/01/a-year-in-review-most-read-articles-in-2017/</guid>
      <description>&lt;p&gt;It seems to be usual nowadays to review the previous year, and readers
apparently like Top-N Lists — &lt;em&gt;that&amp;rsquo;s you now, so let&amp;rsquo;s hope that my
understanding works with you too&lt;/em&gt;.&lt;/p&gt;
&lt;p&gt;Of course 2018 will see its own amount of new and original content added to
this blog, with a continuous focus towards how to make the best out of the
SQL powerful programming language, and its advanced concurrency semantics.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Setting up psql, the PostgreSQL CLI</title>
      <link>https://tapoueh.org/blog/2017/12/setting-up-psql-the-postgresql-cli/</link>
      <pubDate>Fri, 22 Dec 2017 15:23:43 +0100</pubDate>
      
      <guid>https://tapoueh.org/blog/2017/12/setting-up-psql-the-postgresql-cli/</guid>
      <description>&lt;p&gt;PostgreSQL ships with an interactive console with the command line tool
named &lt;a href=&#34;https://www.postgresql.org/docs/current/static/app-psql.html&#34;&gt;psql&lt;/a&gt;.
It can be used both for scripting and interactive usage and is moreover
quite a powerful tool. Interactive features includes &lt;em&gt;autocompletion&lt;/em&gt;,
&lt;em&gt;readline&lt;/em&gt; support (history searches, modern keyboard movements, etc), input
and output redirection, formatted output, and more.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Mastering PostgreSQL: a reader&#39;s interview</title>
      <link>https://tapoueh.org/blog/2017/12/mastering-postgresql-a-readers-interview/</link>
      <pubDate>Wed, 13 Dec 2017 17:05:56 +0100</pubDate>
      
      <guid>https://tapoueh.org/blog/2017/12/mastering-postgresql-a-readers-interview/</guid>
      <description>&lt;p&gt;&lt;em&gt;&lt;strong&gt;Florent Fourcot&lt;/strong&gt;&lt;/em&gt; has read &lt;a href=&#34;http://masteringpostgresql.com&#34;&gt;Mastering PostgreSQL in Application
Development&lt;/a&gt; and has seen tremendous
inprovements in his production setup from reading the first chapters and
applying the book advices to his use case.&lt;/p&gt;
&lt;p&gt;Here&amp;rsquo;s an interview run with Florent where he explains the context in which
such improvements has been made!&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Mastering PostgreSQL: more about the docker image</title>
      <link>https://tapoueh.org/blog/2017/12/mastering-postgresql-more-about-the-docker-image/</link>
      <pubDate>Tue, 12 Dec 2017 23:27:55 +0100</pubDate>
      
      <guid>https://tapoueh.org/blog/2017/12/mastering-postgresql-more-about-the-docker-image/</guid>
      <description>&lt;p&gt;The Enterprise Edition of &lt;a href=&#34;https://masteringpostgresql.com&#34;&gt;Mastering PostgreSQL in Application
Development&lt;/a&gt; ships with a docker image that
hosts both a PostgreSQL server instance with a pre-loaded database, the one
that&amp;rsquo;s used throughout the book examples, and also with a Jupyter Network
notebook that hosts SQL queries thanks to the
&lt;a href=&#34;https://github.com/pivotal/sql_magic&#34;&gt;sql_magic&lt;/a&gt; plugin.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Simple Data Modeling with a Test Data Set</title>
      <link>https://tapoueh.org/blog/2017/11/simple-data-modeling-with-a-test-data-set/</link>
      <pubDate>Mon, 27 Nov 2017 16:23:44 +0100</pubDate>
      
      <guid>https://tapoueh.org/blog/2017/11/simple-data-modeling-with-a-test-data-set/</guid>
      <description>&lt;p&gt;In &lt;a href=&#34;https://tapoueh.org/blog/2017/06/how-to-write-sql/&#34;&gt;How to Write SQL&lt;/a&gt; we saw how to write
SQL queries as separate &lt;code&gt;.sql&lt;/code&gt; files, and we learnt about using query
parameters with the &lt;em&gt;psql&lt;/em&gt; syntax for that (&lt;code&gt;:variable&lt;/code&gt;, &lt;code&gt;:&#39;variable&#39;&lt;/code&gt;, and
&lt;code&gt;:&amp;quot;identifier&amp;quot;&lt;/code&gt;).&lt;/p&gt;
&lt;p&gt;For writing our database model, the same tooling is all we need. An
important aspect of using &lt;em&gt;psql&lt;/em&gt; is its capacity to provide immediate
feedback, and we can also have that with modeling too.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>The Mode Ordered-Set Aggregate Function</title>
      <link>https://tapoueh.org/blog/2017/11/the-mode-ordered-set-aggregate-function/</link>
      <pubDate>Mon, 13 Nov 2017 18:15:51 +0100</pubDate>
      
      <guid>https://tapoueh.org/blog/2017/11/the-mode-ordered-set-aggregate-function/</guid>
      <description>&lt;p&gt;In our article &lt;a href=&#34;https://tapoueh.org/blog/2017/06/exploring-a-data-set-in-sql/&#34;&gt;Exploring a Data Set in
SQL&lt;/a&gt; we discovered a data set
related to music: the &lt;a href=&#34;https://github.com/lerocha/chinook-database&#34;&gt;Chinook&lt;/a&gt;
sample database.&lt;/p&gt;
&lt;p&gt;Our discovery led us to find albums containing tracks of multiple genres,
and for the analytics we were then pursuing, we wanted to &lt;em&gt;clean&lt;/em&gt; the data
set and assign a single genre per album. We did that in SQL of course, and
didn&amp;rsquo;t actually edit the data.&lt;/p&gt;
&lt;p&gt;Finding the most frequent input value in a group is a job for the &lt;code&gt;mode() WITHIN GROUP (ORDER BY sort_expression)&lt;/code&gt; Ordered-Set Aggregate Function, as
documented in the PostgreSQL page about &lt;a href=&#34;https://www.postgresql.org/docs/current/static/functions-aggregate.html#FUNCTIONS-ORDEREDSET-TABLE&#34;&gt;Aggregate
Functions&lt;/a&gt;.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Set Returning Functions and PostgreSQL 10</title>
      <link>https://tapoueh.org/blog/2017/10/set-returning-functions-and-postgresql-10/</link>
      <pubDate>Fri, 13 Oct 2017 13:25:21 +0200</pubDate>
      
      <guid>https://tapoueh.org/blog/2017/10/set-returning-functions-and-postgresql-10/</guid>
      <description>&lt;p&gt;PostgreSQL 10 is now available for everyone to use, and hinted by &lt;a href=&#34;http://fetter.org&#34;&gt;David
Fetter&lt;/a&gt; I had to review my previous article &lt;a href=&#34;https://tapoueh.org/blog/2017/09/on-json-and-sql/&#34;&gt;on Json and
SQL&lt;/a&gt; to adapt to &lt;em&gt;Set Returning Functions&lt;/em&gt;
changes.&lt;/p&gt;
&lt;p&gt;A &lt;em&gt;Set Returning Function&lt;/em&gt; is a PostgreSQL &lt;em&gt;Stored Procedure&lt;/em&gt; that can be
used as a relation: from a single call it returns an entire result set, much
like a subquery or a table.&lt;/p&gt;
&lt;p&gt;It used to be possible to use &lt;em&gt;SRF&lt;/em&gt; in the &lt;em&gt;SELECT&lt;/em&gt; clause, with dubious
(but useful at times) semantics, and also in &lt;em&gt;scalar&lt;/em&gt; contexts. The
semantics have been fixed and are now much clearer, and the uses in scalar
contexts are forbidden — they were a hack and never made sense anyway.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>on Json and SQL</title>
      <link>https://tapoueh.org/blog/2017/09/on-json-and-sql/</link>
      <pubDate>Mon, 18 Sep 2017 10:49:03 +0200</pubDate>
      
      <guid>https://tapoueh.org/blog/2017/09/on-json-and-sql/</guid>
      <description>&lt;p&gt;PostgreSQL has had proper
&lt;a href=&#34;https://www.postgresql.org/docs/current/static/datatype-json.html&#34;&gt;json&lt;/a&gt;
support for a while now. The unique extensibility approach of the PostgreSQL
system allows it to enable native &lt;a href=&#34;https://www.postgresql.org/docs/current/static/functions-json.html&#34;&gt;SQL friendly JSON
processing&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;In this article we&amp;rsquo;ll play with the &lt;a href=&#34;https://mtgjson.com&#34;&gt;Magic: the Gathering card data in JSON
format&lt;/a&gt; data set, provided with a
&lt;a href=&#34;https://creativecommons.org/choose/zero/&#34;&gt;CC0&lt;/a&gt; licence, and process the
information provided. We also see how to normalize a JSON document into a
proper database model that benefits from some PostgreSQL advanced features,
and how to then inject the JSON documents into the normalized database
schema. Finally, we compare some non-trivial processing done against both
versions of the database schema.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Regular Expressions and Grouping Sets</title>
      <link>https://tapoueh.org/blog/2017/08/regular-expressions-and-grouping-sets/</link>
      <pubDate>Mon, 14 Aug 2017 16:37:53 +0200</pubDate>
      
      <guid>https://tapoueh.org/blog/2017/08/regular-expressions-and-grouping-sets/</guid>
      <description>&lt;p&gt;There&amp;rsquo;s a very rich set of PostgreSQL functions to process text, you can
find them all at
the
&lt;a href=&#34;https://www.postgresql.org/docs/current/static/functions-string.html&#34;&gt;String Functions and Operators&lt;/a&gt; documentation
chapter, with functions such as &lt;em&gt;overlay&lt;/em&gt;, &lt;em&gt;substring&lt;/em&gt;, &lt;em&gt;position&lt;/em&gt; or
&lt;em&gt;trim&lt;/em&gt;. Or aggregates such as &lt;em&gt;string_agg&lt;/em&gt;. And then &lt;em&gt;regular expression&lt;/em&gt;
functions, including the very powerful &lt;em&gt;regexp_split_to_table&lt;/em&gt;.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>SQL Regression Tests</title>
      <link>https://tapoueh.org/blog/2017/08/sql-regression-tests/</link>
      <pubDate>Tue, 08 Aug 2017 17:55:51 +0200</pubDate>
      
      <guid>https://tapoueh.org/blog/2017/08/sql-regression-tests/</guid>
      <description>&lt;p&gt;In a previous article here we
saw &lt;a href=&#34;https://tapoueh.org/blog/2017/06/how-to-write-sql/&#34;&gt;How to Write SQL&lt;/a&gt; in your application
code. The main idea in that article is to maintain your queries in separate
SQL files, where it&amp;rsquo;s easier to maintain them. In particular if you want to
be able to test them again in production, and when you have to work and
rewrite queries.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Playing with Unicode</title>
      <link>https://tapoueh.org/blog/2017/07/playing-with-unicode/</link>
      <pubDate>Mon, 03 Jul 2017 14:32:29 +0200</pubDate>
      
      <guid>https://tapoueh.org/blog/2017/07/playing-with-unicode/</guid>
      <description>&lt;p&gt;The reason why I like Unicode a lot is because it allows me to code in text
based environments and still have nice output. Today, we&amp;rsquo;re going to play
with
&lt;a href=&#34;https://en.wikipedia.org/wiki/Regional_Indicator_Symbol&#34;&gt;Regional Indicator Symbol&lt;/a&gt;,
which is implemented as a Unicode combinaison of letters from 🇦 to 🇿. For
instance, if you display 🇫 then 🇷 concatenated together, you get 🇫🇷. Let&amp;rsquo;s
try that from our &lt;a href=&#34;https://www.postgresql.org/&#34;&gt;PostgreSQL&lt;/a&gt; prompt!&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>PostgreSQL and the calendar</title>
      <link>https://tapoueh.org/blog/2017/06/postgresql-and-the-calendar/</link>
      <pubDate>Fri, 30 Jun 2017 14:35:59 +0200</pubDate>
      
      <guid>https://tapoueh.org/blog/2017/06/postgresql-and-the-calendar/</guid>
      <description>&lt;p&gt;The modern calendar is a trap for the young engineer&amp;rsquo;s mind. We deal with
the calendar on a daily basis and until exposed to its insanity it&amp;rsquo;s rather
common to think that calendar based computations are easy. That&amp;rsquo;s until
you&amp;rsquo;ve tried to do it once. A very good read about how the current calendar
came to be the way it is now is Erik&amp;rsquo;s
Naggum &lt;a href=&#34;http://naggum.no/lugm-time.html&#34;&gt;The Long, Painful History of Time&lt;/a&gt;.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>SQL and Business Logic</title>
      <link>https://tapoueh.org/blog/2017/06/sql-and-business-logic/</link>
      <pubDate>Mon, 19 Jun 2017 13:30:19 +0200</pubDate>
      
      <guid>https://tapoueh.org/blog/2017/06/sql-and-business-logic/</guid>
      <description>&lt;p&gt;Business logic is &lt;em&gt;supposed to be&lt;/em&gt; the part of the application where you
deal with customer or user facing decisions and computations. It is often
argued that this part should be well separated from the rest of the
technical infrastructure of your code. Of course, SQL and relational
database design is meant to support your business cases (or user stories),
so then we can ask ourselves if SQL should be part of your business logic
implementation. Or actually, how much of your business logic should be SQL?&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Exploring a Data Set in SQL</title>
      <link>https://tapoueh.org/blog/2017/06/exploring-a-data-set-in-sql/</link>
      <pubDate>Tue, 13 Jun 2017 13:47:08 +0200</pubDate>
      
      <guid>https://tapoueh.org/blog/2017/06/exploring-a-data-set-in-sql/</guid>
      <description>&lt;p&gt;Sometimes you need to dive in an existing data set that you know very little
about. Let&amp;rsquo;s say we&amp;rsquo;ve been lucky to have had a high level description of
the business case covered by a database, and then access to it. Our next
step is figuring out data organisation, content and quality. Our tool box:
&lt;em&gt;the world&amp;rsquo;s most advanced open source
database&lt;/em&gt;, &lt;a href=&#34;https://www.postgresql.org&#34;&gt;PostgreSQL&lt;/a&gt;, and its &lt;em&gt;Structured
Query Language&lt;/em&gt;, SQL.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>How to Write SQL</title>
      <link>https://tapoueh.org/blog/2017/06/how-to-write-sql/</link>
      <pubDate>Thu, 08 Jun 2017 13:23:26 +0200</pubDate>
      
      <guid>https://tapoueh.org/blog/2017/06/how-to-write-sql/</guid>
      <description>&lt;p&gt;&lt;a href=&#34;https://twitter.com/krisajenkins&#34;&gt;Kris Jenkins&lt;/a&gt; cooked up a very nice way
to embed SQL in your
code: &lt;a href=&#34;https://github.com/krisajenkins/yesql&#34;&gt;YeSQL for Clojure&lt;/a&gt;. The main
idea is that you should be writing your SQL queries in &lt;code&gt;.sql&lt;/code&gt; files in your
code repository and maintain them there.&lt;/p&gt;
&lt;p&gt;The idea is very good and it is now possible to find alternative
implementations of the &lt;a href=&#34;https://clojure.org&#34;&gt;Clojure&lt;/a&gt; &lt;em&gt;yesql&lt;/em&gt; library in
other languages. Today, we are going to have a look at one of them for
the &lt;a href=&#34;https://www.python.org&#34;&gt;python&lt;/a&gt; programming
language: &lt;a href=&#34;https://github.com/honza/anosql&#34;&gt;anosql&lt;/a&gt;.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Find The Missing Integer</title>
      <link>https://tapoueh.org/blog/2017/05/find-the-missing-integer/</link>
      <pubDate>Tue, 30 May 2017 19:56:54 +0200</pubDate>
      
      <guid>https://tapoueh.org/blog/2017/05/find-the-missing-integer/</guid>
      <description>&lt;p&gt;A recent interview question that I had to review was spelled like this:&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;Find missing int element into array 1..100&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;Of course at first read I got it wrong, you have only one integer to look
for into the array. So while the obvious idea was to apply classic &lt;em&gt;sorting&lt;/em&gt;
techniques and minimize array traversal to handle complexity (time and
space), it turns out there&amp;rsquo;s a much simpler way to do it if you remember
your math lessons from younger. But is it that much simpler?&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>PostgreSQL, Aggregates and Histograms</title>
      <link>https://tapoueh.org/blog/2014/02/postgresql-aggregates-and-histograms/</link>
      <pubDate>Fri, 21 Feb 2014 13:25:00 +0100</pubDate>
      
      <guid>https://tapoueh.org/blog/2014/02/postgresql-aggregates-and-histograms/</guid>
      <description>&lt;p&gt;In our previous article
&lt;a href=&#34;https://tapoueh.org/blog/2014/02/17-aggregating-nba-data-PostgreSQL-vs-MongoDB&#34;&gt;Aggregating NBA data, PostgreSQL vs MongoDB&lt;/a&gt; we spent
time comparing the pretty new
&lt;em&gt;MongoDB Aggregation Framework&lt;/em&gt; with the decades
old SQL aggregates. Today, let&amp;rsquo;s showcase more of those SQL aggregates,
producing a nice
&lt;em&gt;histogram&lt;/em&gt; right from our SQL console.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Aggregating NBA data, PostgreSQL vs MongoDB</title>
      <link>https://tapoueh.org/blog/2014/02/aggregating-nba-data-postgresql-vs-mongodb/</link>
      <pubDate>Mon, 17 Feb 2014 23:40:00 +0100</pubDate>
      
      <guid>https://tapoueh.org/blog/2014/02/aggregating-nba-data-postgresql-vs-mongodb/</guid>
      <description>&lt;p&gt;When reading the article
&lt;a href=&#34;http://thecodebarbarian.wordpress.com/2014/02/14/crunching-30-years-of-nba-data-with-mongodb-aggregation/&#34;&gt;Crunching 30 Years of NBA Data with MongoDB Aggregation&lt;/a&gt; I coulnd&amp;rsquo;t help but
think that we&amp;rsquo;ve been enjoying
&lt;a href=&#34;http://www.postgresql.org/docs/current/static/tutorial-agg.html&#34;&gt;aggregates&lt;/a&gt; in SQL for 3 or 4 decades already.
When using
&lt;a href=&#34;http://www.postgresql.org/&#34;&gt;PostgreSQL&lt;/a&gt; it&amp;rsquo;s even easy to actually add your own aggregates
given the SQL command
&lt;a href=&#34;http://www.postgresql.org/docs/current/static/sql-createaggregate.html&#34;&gt;create aggregate&lt;/a&gt;.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Denormalizing Tags</title>
      <link>https://tapoueh.org/blog/2013/10/denormalizing-tags/</link>
      <pubDate>Thu, 24 Oct 2013 13:40:00 +0200</pubDate>
      
      <guid>https://tapoueh.org/blog/2013/10/denormalizing-tags/</guid>
      <description>In our Tour of Extensions today&amp;rsquo;s article is about advanced tag indexing. We have a great data collection to play with and our goal today is to be able to quickly find data matching a complex set of tags. So, let&amp;rsquo;s find out those lastfm tracks that are tagged as blues and rhythm and blues, for instance.
We&amp;rsquo;re going to use the Last.fm dataset from the Million Song Dataset project here.</description>
    </item>
    
    <item>
      <title>PostgreSQL Autonomous Transaction</title>
      <link>https://tapoueh.org/blog/2013/10/postgresql-autonomous-transaction/</link>
      <pubDate>Mon, 14 Oct 2013 11:25:00 +0200</pubDate>
      
      <guid>https://tapoueh.org/blog/2013/10/postgresql-autonomous-transaction/</guid>
      <description>&lt;p&gt;&lt;a href=&#34;http://www.postgresql.org/&#34;&gt;PostgreSQL&lt;/a&gt; is an all round impressive
&lt;em&gt;Relational DataBase Management System&lt;/em&gt;
which implements the SQL standard (see the very useful reference page
&lt;a href=&#34;http://troels.arvin.dk/db/rdbms/&#34;&gt;Comparison of different SQL implementations&lt;/a&gt; for details). PostgreSQL also
provides with unique solutions in the database market and has been leading
innovation for some years now. Still, there&amp;rsquo;s no support for
&lt;em&gt;&lt;strong&gt;Autonomous
Transactions&lt;/strong&gt;&lt;/em&gt; within the server itself. Let&amp;rsquo;s have a look at how to easily
implement them with
&lt;a href=&#34;http://wiki.postgresql.org/wiki/PL/Proxy&#34;&gt;PL/Proxy&lt;/a&gt;.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Using trigrams against typos</title>
      <link>https://tapoueh.org/blog/2013/09/using-trigrams-against-typos/</link>
      <pubDate>Fri, 06 Sep 2013 16:15:00 +0200</pubDate>
      
      <guid>https://tapoueh.org/blog/2013/09/using-trigrams-against-typos/</guid>
      <description>&lt;p&gt;In our ongoing
&lt;a href=&#34;https://tapoueh.org/tags/extensions&#34;&gt;Tour of Extensions&lt;/a&gt; we played with
&lt;a href=&#34;http://www.postgresql.org/docs/current/static/earthdistance.html&#34;&gt;earth distance&lt;/a&gt; in
&lt;a href=&#34;https://tapoueh.org/blog/2013/08/05-earthdistance&#34;&gt;How far is the nearest pub?&lt;/a&gt; then with
&lt;a href=&#34;http://www.postgresql.org/docs/current/static/hstore.html&#34;&gt;hstore&lt;/a&gt; in a series about trigger,
first to generalize
&lt;a href=&#34;https://tapoueh.org/blog/2013/08/23-parametrized-triggers&#34;&gt;Trigger Parameters&lt;/a&gt; then to enable us to
&lt;a href=&#34;https://tapoueh.org/blog/2013/08/27-auditing-changes-with-hstore&#34;&gt;Auditing Changes with Hstore&lt;/a&gt;. Today we are going to work with
&lt;a href=&#34;http://www.postgresql.org/docs/current/static/pgtrgm.html&#34;&gt;pg_trgm&lt;/a&gt; which
is the
&lt;em&gt;trigrams&lt;/em&gt; PostgreSQL extension: its usage got seriously enhanced in
recent PostgreSQL releases and it&amp;rsquo;s now a poor&amp;rsquo;s man
&lt;a href=&#34;http://www.postgresql.org/docs/current/static/textsearch.html&#34;&gt;Full Text Search&lt;/a&gt;
engine.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Auditing Changes with Hstore</title>
      <link>https://tapoueh.org/blog/2013/08/auditing-changes-with-hstore/</link>
      <pubDate>Tue, 27 Aug 2013 17:35:00 +0200</pubDate>
      
      <guid>https://tapoueh.org/blog/2013/08/auditing-changes-with-hstore/</guid>
      <description>&lt;p&gt;In a previous article about
&lt;a href=&#34;https://tapoueh.org/blog/2013/08/23-parametrized-triggers&#34;&gt;Trigger Parameters&lt;/a&gt; we have been using the
extension
&lt;a href=&#34;http://www.postgresql.org/docs/9.2/static/hstore.html&#34;&gt;hstore&lt;/a&gt; in order to compute some extra field in our records, where
the fields used both for the computation and for storing the results were
passed in as
&lt;em&gt;dynamic parameters&lt;/em&gt;. Today we&amp;rsquo;re going to see another
&lt;em&gt;trigger&lt;/em&gt;
use case for
&lt;em&gt;hstore&lt;/em&gt;: we are going to record changes made to our tuples.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Trigger Parameters</title>
      <link>https://tapoueh.org/blog/2013/08/trigger-parameters/</link>
      <pubDate>Fri, 23 Aug 2013 12:08:00 +0200</pubDate>
      
      <guid>https://tapoueh.org/blog/2013/08/trigger-parameters/</guid>
      <description>&lt;p&gt;Sometimes you want to compute values automatically at
&lt;code&gt;INSERT&lt;/code&gt; time, like for
example a
&lt;em&gt;duration&lt;/em&gt; column out of a
&lt;em&gt;start&lt;/em&gt; and an
&lt;em&gt;end&lt;/em&gt; column, both
&lt;em&gt;timestamptz&lt;/em&gt;. It&amp;rsquo;s easy enough to do with a
&lt;code&gt;BEFORE TRIGGER&lt;/code&gt; on your table.
What&amp;rsquo;s more complex is to come up with a parametrized spelling of the
trigger, where you can attach the same
&lt;em&gt;stored procedure&lt;/em&gt; to any table even
when the column names are different from one another.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Understanding Window Functions</title>
      <link>https://tapoueh.org/blog/2013/08/understanding-window-functions/</link>
      <pubDate>Tue, 20 Aug 2013 12:04:00 +0200</pubDate>
      
      <guid>https://tapoueh.org/blog/2013/08/understanding-window-functions/</guid>
      <description>&lt;p&gt;There was SQL
before
&lt;a href=&#34;http://www.postgresql.org/docs/current/static/tutorial-window.html&#34;&gt;window functions&lt;/a&gt; and
SQL after &lt;em&gt;window functions&lt;/em&gt;: that&amp;rsquo;s how powerful this tool is. Being that
of a deal breaker unfortunately means that it can be quite hard to grasp the
feature. This article aims at making it crystal clear so that you can begin
using it today and are able to reason about it and recognize cases where you
want to be using &lt;em&gt;window functions&lt;/em&gt;.&lt;/p&gt;
&lt;center&gt;


 
  
  
  
  
    
      
    
  
    
  
    
      
    
  

&lt;div class=&#34;figure fig50 dim-margin&#34; &gt;
  
    &lt;a class=&#34;fancybox&#34; href=&#34;https://tapoueh.org/img/old/moving_window.gif&#34; data-fancybox=&#34;&#34;&gt;
  
    &lt;img class=&#34;fig-img&#34; src=&#34;https://tapoueh.org/img/old/moving_window.gif&#34; &gt;
  
    &lt;/a&gt;
  
  
&lt;/div&gt;

&lt;/center&gt;
&lt;center&gt;*We see a part of the data as if through a little window*&lt;/center&gt;</description>
    </item>
    
    <item>
      <title>How far is the nearest pub?</title>
      <link>https://tapoueh.org/blog/2013/08/how-far-is-the-nearest-pub/</link>
      <pubDate>Mon, 05 Aug 2013 08:11:00 +0200</pubDate>
      
      <guid>https://tapoueh.org/blog/2013/08/how-far-is-the-nearest-pub/</guid>
      <description>&lt;p&gt;In our recent article
about &lt;a href=&#34;https://tapoueh.org/blog/2013/08/02-pub-names-knn&#34;&gt;The Most Popular Pub Names&lt;/a&gt; we did
have a look at how to find the pubs nearby, but didn&amp;rsquo;t compute the
&lt;strong&gt;distance&lt;/strong&gt; in between that pub and us. That&amp;rsquo;s because how to compute a
distance given a position on the earth expressed as &lt;em&gt;longitude&lt;/em&gt; and
&lt;em&gt;latitude&lt;/em&gt; is not that easy. Today, we are going to solve that problem
nonetheless, thanks
to
&lt;a href=&#34;http://www.postgresql.org/docs/9.2/interactive/extend-extensions.html&#34;&gt;PostgreSQL Extensions&lt;/a&gt;.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>The Most Popular Pub Names</title>
      <link>https://tapoueh.org/blog/2013/08/the-most-popular-pub-names/</link>
      <pubDate>Fri, 02 Aug 2013 10:19:00 +0200</pubDate>
      
      <guid>https://tapoueh.org/blog/2013/08/the-most-popular-pub-names/</guid>
      <description>&lt;p&gt;In his article
titled
&lt;a href=&#34;http://blog.mongodb.org/post/56876800071/the-most-popular-pub-names?utm_content=buffer4922c&amp;amp;utm_source=buffer&amp;amp;utm_medium=facebook&amp;amp;utm_campaign=Buffer&#34;&gt;The Most Popular Pub Names&lt;/a&gt; &lt;em&gt;Ross
Lawley&lt;/em&gt; did show us how to perform some quite interesting &lt;em&gt;geographic
queries&lt;/em&gt; against &lt;a href=&#34;http://www.mongodb.org/&#34;&gt;MongoDB&lt;/a&gt;, using some nice &lt;em&gt;Open
Data&lt;/em&gt; found at the &lt;a href=&#34;http://www.openstreetmap.org/&#34;&gt;Open Street Map&lt;/a&gt; project.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Archiving data as fast as possible</title>
      <link>https://tapoueh.org/blog/2013/07/archiving-data-as-fast-as-possible/</link>
      <pubDate>Fri, 05 Jul 2013 15:30:00 +0200</pubDate>
      
      <guid>https://tapoueh.org/blog/2013/07/archiving-data-as-fast-as-possible/</guid>
      <description>&lt;p&gt;In a recent article here we&amp;rsquo;ve been talking about how do do
&lt;a href=&#34;https://tapoueh.org/blog/2013/03/15-batch-update&#34;&gt;Batch Updates&lt;/a&gt; in
a very efficient way, using the
&lt;em&gt;Writable CTE&lt;/em&gt; features available in
PostgreSQL 9.1. I sometime read how
&lt;a href=&#34;http://www.postgresql.org/docs/current/interactive/queries-with.html&#34;&gt;Common Table Expressions&lt;/a&gt; changed the
life of fellow DBAs and developers, and would say that
&lt;em&gt;Writable CTE&lt;/em&gt; are at
least the same boost again.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Simple Case for Pivoting in SQL</title>
      <link>https://tapoueh.org/blog/2013/07/simple-case-for-pivoting-in-sql/</link>
      <pubDate>Thu, 04 Jul 2013 15:55:00 +0200</pubDate>
      
      <guid>https://tapoueh.org/blog/2013/07/simple-case-for-pivoting-in-sql/</guid>
      <description>In a recent article Craig Kerstiens from Heroku did demo the really useful crosstab extension. That function allows you to pivot a table so that you can see the data from different categories in separate columns in the same row rather than in separate rows. The article from Craig is Pivoting in Postgres.
*Pivoting a matrix, also known as a matrix transposition* Let&amp;rsquo;s do the same setup as he did, with a table containing some randomly generated data about hypothetical visits to a web page, say, by date then by operating system.</description>
    </item>
    
    <item>
      <title>Nearest Big City</title>
      <link>https://tapoueh.org/blog/2013/05/nearest-big-city/</link>
      <pubDate>Thu, 02 May 2013 11:34:00 +0200</pubDate>
      
      <guid>https://tapoueh.org/blog/2013/05/nearest-big-city/</guid>
      <description>In this article, we want to find the town with the greatest number of inhabitants near a given location.
A very localized example We first need to find and import some data, and I found at the following place a CSV listing of french cities with coordinates and population and some numbers of interest for the exercise here.
To import the data set, we first need a table, then a COPY command:</description>
    </item>
    
    <item>
      <title>Batch Update</title>
      <link>https://tapoueh.org/blog/2013/03/batch-update/</link>
      <pubDate>Fri, 15 Mar 2013 10:47:00 +0100</pubDate>
      
      <guid>https://tapoueh.org/blog/2013/03/batch-update/</guid>
      <description>&lt;p&gt;Performance consulting involves some tricks that you have to teach over and
over again. One of them is that SQL tends to be so much better at dealing
with plenty of rows in a single statement when compared to running as many
statements, each one against a single row.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>HyperLogLog Unions</title>
      <link>https://tapoueh.org/blog/2013/02/hyperloglog-unions/</link>
      <pubDate>Tue, 26 Feb 2013 12:44:00 +0100</pubDate>
      
      <guid>https://tapoueh.org/blog/2013/02/hyperloglog-unions/</guid>
      <description>In the article from yesterday we talked about PostgreSQL HyperLogLog with some details. The real magic of that extension has been skimmed over though, and needs another very small article all by itself, in case you missed it.
*Which Set Operation do you want for counting unique values?* The first query here has the default level of magic in it, really. What happens is that each time we do an update of the HyperLogLog hash value, we update some data which are allowing us to compute its cardinality.</description>
    </item>
    
    <item>
      <title>PostgreSQL HyperLogLog</title>
      <link>https://tapoueh.org/blog/2013/02/postgresql-hyperloglog/</link>
      <pubDate>Mon, 25 Feb 2013 10:23:00 +0100</pubDate>
      
      <guid>https://tapoueh.org/blog/2013/02/postgresql-hyperloglog/</guid>
      <description>&lt;p&gt;If you&amp;rsquo;ve been following along at home the newer statistics developments,
you might have heard about this new
&lt;a href=&#34;http://research.google.com/pubs/pub40671.html&#34;&gt;State of The Art Cardinality Estimation Algorithm&lt;/a&gt; called
&lt;a href=&#34;http://metamarkets.com/2012/fast-cheap-and-98-right-cardinality-estimation-for-big-data/&#34;&gt;HyperLogLog&lt;/a&gt;. This
technique is now available for PostgreSQL in the extension
&lt;a href=&#34;http://blog.aggregateknowledge.com/2013/02/04/open-source-release-postgresql-hll/&#34;&gt;postgresql-hll&lt;/a&gt;
available at
&lt;a href=&#34;https://github.com/aggregateknowledge/postgresql-hll&#34;&gt;https://github.com/aggregateknowledge/postgresql-hll&lt;/a&gt; and soon
to be in
&lt;code&gt;debian&lt;/code&gt;.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Reset Counter</title>
      <link>https://tapoueh.org/blog/2012/10/reset-counter/</link>
      <pubDate>Fri, 05 Oct 2012 09:44:00 +0200</pubDate>
      
      <guid>https://tapoueh.org/blog/2012/10/reset-counter/</guid>
      <description>&lt;p&gt;I&amp;rsquo;ve been given a nice puzzle that I think is a good blog article
opportunity, as it involves some thinking and &lt;a href=&#34;https://tapoueh.org/blog/2013/08/understanding-window-functions/&#34;&gt;window
functions&lt;/a&gt;.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Tables and Views dependencies</title>
      <link>https://tapoueh.org/blog/2011/05/tables-and-views-dependencies/</link>
      <pubDate>Wed, 04 May 2011 11:45:00 +0200</pubDate>
      
      <guid>https://tapoueh.org/blog/2011/05/tables-and-views-dependencies/</guid>
      <description>Let&amp;rsquo;s say you need to ALTER TABLE foo ALTER COLUMN bar TYPE bigint;, and PostgreSQL is helpfully telling you that no you can&amp;rsquo;t because such and such views depend on the column. The basic way to deal with that is to copy paste from the error message the names of the views involved, then prepare a script wherein you first DROP VIEW then ALTER TABLE and finally CREATE VIEW again, all in the same transaction.</description>
    </item>
    
    <item>
      <title>Dynamic Triggers in PLpgSQL</title>
      <link>https://tapoueh.org/blog/2010/11/dynamic-triggers-in-plpgsql/</link>
      <pubDate>Wed, 24 Nov 2010 16:45:00 +0100</pubDate>
      
      <guid>https://tapoueh.org/blog/2010/11/dynamic-triggers-in-plpgsql/</guid>
      <description>You certainly know that implementing dynamic triggers in PLpgSQL is impossible. But I had a very bad night, being up from as soon as 3:30 am today, so that when a developer asked me about reusing the same trigger function code from more than one table and for a dynamic column name, I didn&amp;rsquo;t remember about it being impossible.
Here&amp;rsquo;s what happens in such cases, after a long time on the problem (yes, overall, that&amp;rsquo;s a slow day).</description>
    </item>
    
    <item>
      <title>Window Functions example remix</title>
      <link>https://tapoueh.org/blog/2010/09/window-functions-example-remix/</link>
      <pubDate>Sun, 12 Sep 2010 21:35:00 +0200</pubDate>
      
      <guid>https://tapoueh.org/blog/2010/09/window-functions-example-remix/</guid>
      <description>The drawback of hosting a static only website is, obviously, the lack of comments. What happens actually, though, is that I receive very few comments by direct mail. As I don&amp;rsquo;t get another spam source to cleanup, I&amp;rsquo;m left unconvinced that&amp;rsquo;s such a drawback. I still miss the low probability of seeing blog readers exchange directly, but I think a tapoueh.org mailing list would be my answer, here&amp;hellip;
Anyway, David Fetter took the time to send me a comment by mail with a cleaned up rewrite of the previous entry SQL, here&amp;rsquo;s it for your pleasure!</description>
    </item>
    
    <item>
      <title>Window Functions example</title>
      <link>https://tapoueh.org/blog/2010/09/window-functions-example/</link>
      <pubDate>Thu, 09 Sep 2010 16:35:00 +0200</pubDate>
      
      <guid>https://tapoueh.org/blog/2010/09/window-functions-example/</guid>
      <description>So, when 8.4 came out there was all those comments about how getting window functions was an awesome addition. Now, it seems that a lot of people seeking for help in #postgresql just don&amp;rsquo;t know what kind of problem this feature helps solving. I&amp;rsquo;ve already been using them in some cases here in this blog, for getting some nice overview about Partitioning: relation size per “group”.
*That&#39;s another way to count change* Now, another example use case rose on IRC today.</description>
    </item>
    
    <item>
      <title>Happy Numbers</title>
      <link>https://tapoueh.org/blog/2010/08/happy-numbers/</link>
      <pubDate>Mon, 30 Aug 2010 11:00:00 +0200</pubDate>
      
      <guid>https://tapoueh.org/blog/2010/08/happy-numbers/</guid>
      <description>After discovering the excellent Gwene service, which allows you to subscribe to newsgroups to read RSS content ( blogs, planets, commits, etc), I came to read this nice article about Happy Numbers. That&amp;rsquo;s a little problem that fits well an interview style question, so I first solved it yesterday evening in Emacs Lisp as that&amp;rsquo;s the language I use the most those days.
A happy number is defined by the following process.</description>
    </item>
    
    <item>
      <title>Playing with bit strings</title>
      <link>https://tapoueh.org/blog/2010/08/playing-with-bit-strings/</link>
      <pubDate>Thu, 26 Aug 2010 17:45:00 +0200</pubDate>
      
      <guid>https://tapoueh.org/blog/2010/08/playing-with-bit-strings/</guid>
      <description>The idea of the day ain&amp;rsquo;t directly from me, I&amp;rsquo;m just helping with a very thin subpart of the problem. The problem, I can&amp;rsquo;t say much about, let&amp;rsquo;s just assume you want to reduce the storage of MD5 in your database, so you want to abuse bit strings. A solution to use them works fine, but the datatype is still missing some facilities, for example going from and to hexadecimal representation in text.</description>
    </item>
    
    <item>
      <title>Partitioning: relation size per “group”</title>
      <link>https://tapoueh.org/blog/2010/07/partitioning-relation-size-per-group/</link>
      <pubDate>Mon, 26 Jul 2010 17:00:00 +0200</pubDate>
      
      <guid>https://tapoueh.org/blog/2010/07/partitioning-relation-size-per-group/</guid>
      <description>This time, we are trying to figure out where is the bulk of the data on disk. The trick is that we&amp;rsquo;re using DDL partitioning, but we want a “nice” view of size per partition set. Meaning that if you have for example a parent table foo with partitions foo_201006 and foo_201007, you would want to see a single category foo containing the accumulated size of all the partitions underneath foo.</description>
    </item>
    
    <item>
      <title>Finding orphaned sequences</title>
      <link>https://tapoueh.org/blog/2010/03/finding-orphaned-sequences/</link>
      <pubDate>Wed, 17 Mar 2010 13:35:00 +0100</pubDate>
      
      <guid>https://tapoueh.org/blog/2010/03/finding-orphaned-sequences/</guid>
      <description>This time we&amp;rsquo;re having a database where sequences were used, but not systematically as a default value of a given column. It&amp;rsquo;s mainly an historic bad idea, but you know the usual excuse with bad ideas and bad code: the first 6 months it&amp;rsquo;s experimental, after that it&amp;rsquo;s historic.
*Not talking about genome orphaned sequences here, though* Still, here&amp;rsquo;s a query for 8.4 that will allow you to list those sequences you have that are not used as a default value in any of your tables:</description>
    </item>
    
    <item>
      <title>Importing XML content from file</title>
      <link>https://tapoueh.org/blog/2009/02/importing-xml-content-from-file/</link>
      <pubDate>Thu, 05 Feb 2009 00:00:00 +0100</pubDate>
      
      <guid>https://tapoueh.org/blog/2009/02/importing-xml-content-from-file/</guid>
      <description>The problem was raised this week on IRC and this time again I felt it would be a good occasion for a blog entry: how to load an XML file content into a single field?
The usual tool used to import files is COPY, but it&amp;rsquo;ll want each line of the file to host a text representation of a database tuple, so it doesn&amp;rsquo;t apply to the case at hand. RhodiumToad was online and offered the following code to solve the problem:</description>
    </item>
    
  </channel>
</rss>
