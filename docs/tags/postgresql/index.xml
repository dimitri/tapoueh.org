<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Postgresql on Dimitri Fontaine, PostgreSQL Expert</title>
    <link>http://tapoueh.org/tags/postgresql/</link>
    <description>Recent content in Postgresql on Dimitri Fontaine, PostgreSQL Expert</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <lastBuildDate>Tue, 30 May 2017 19:56:54 +0200</lastBuildDate>
    
	<atom:link href="http://tapoueh.org/tags/postgresql/index.xml" rel="self" type="application/rss+xml" />
    
    
    <item>
      <title>Find The Missing Integer</title>
      <link>http://tapoueh.org/blog/2017/05/find-the-missing-integer/</link>
      <pubDate>Tue, 30 May 2017 19:56:54 +0200</pubDate>
      
      <guid>http://tapoueh.org/blog/2017/05/find-the-missing-integer/</guid>
      <description>&lt;p&gt;A recent interview question that I had to review was spelled like this:&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;Find missing int element into array 1..100&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;Of course at first read I got it wrong, you have only one integer to look
for into the array. So while the obvious idea was to apply classing
&lt;em&gt;sorting&lt;/em&gt; techniques and minimize array traversal to handle complexity (time
and space), it turns out there&amp;rsquo;s a much simpler way to do it if you remember
your math lessons from younger. But is is that much simpler?&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Mastering PostgreSQL in Application Development</title>
      <link>http://tapoueh.org/book/</link>
      <pubDate>Mon, 22 May 2017 01:16:47 +0200</pubDate>
      
      <guid>http://tapoueh.org/book/</guid>
      <description>I am writing a book to share my knowledge about how to best use PostgreSQL as an application developer. If you&amp;rsquo;ve evered ask yourself how much should I have my database do for me? this book is for you. If you&amp;rsquo;re thinking that using an ORM might not always be the best option out there, if sometimes you wish SQL was easier to maintain than those concatenated strings with conditionals, then this book can&amp;rsquo;t wait for you!</description>
    </item>
    
    <item>
      <title>PGConf US 2016</title>
      <link>http://tapoueh.org/blog/2016/04/pgconf-us-2016/</link>
      <pubDate>Wed, 20 Apr 2016 00:00:00 +0000</pubDate>
      
      <guid>http://tapoueh.org/blog/2016/04/pgconf-us-2016/</guid>
      <description>&lt;p&gt;&lt;a href=&#34;https://www.pgconf.us/conferences/2016&#34;&gt;PostgreSQL Conference US&lt;/a&gt; took
place in New York City and I had the pleasure to be a speaker there. I
presented there a talk about why &lt;em&gt;You’d Better Have Tested Backups&lt;/em&gt;. The
important bit is that backups are not interesting, recoveries are. Also the
only way to make sure a backup is successful is to be able to use it for
recovery.&lt;/p&gt;

&lt;p&gt;&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>All Your Base Conference 2015</title>
      <link>http://tapoueh.org/blog/2015/11/all-your-base-conference-2015/</link>
      <pubDate>Mon, 16 Nov 2015 14:18:00 +0100</pubDate>
      
      <guid>http://tapoueh.org/blog/2015/11/all-your-base-conference-2015/</guid>
      <description>&lt;p&gt;I had the pleasure to be invited to speak at
&lt;a href=&#34;http://allyourbaseconf.com/2015/speakers#dimitri-fontaine&#34;&gt;All Your Base Conference 2015&lt;/a&gt;
about
&lt;a href=&#34;http://www.postgresql.org&#34;&gt;PostgreSQL&lt;/a&gt; (of course). The conference gathers together lots of user
experience around data management and database products, either in the now
classic meaning of the word (I mean
&lt;em&gt;relational database management systems
here&lt;/em&gt;) or the newer set of trade-offs represented by the NoSQL set of tools.&lt;/p&gt;

&lt;p&gt;&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>a pgDay in Paris!</title>
      <link>http://tapoueh.org/blog/2015/03/a-pgday-in-paris/</link>
      <pubDate>Mon, 16 Mar 2015 15:22:00 +0100</pubDate>
      
      <guid>http://tapoueh.org/blog/2015/03/a-pgday-in-paris/</guid>
      <description>&lt;p&gt;I was lucky to participate as a speaker to the
&lt;a href=&#34;http://2015.nordicpgday.org/&#34;&gt;Nordic PostgreSQL Day 2015&lt;/a&gt;
and it&amp;rsquo;s been another awesome edition of the conference. Really smooth,
everything has been running as it should, with about one hundred people at
the conference.&lt;/p&gt;

&lt;p&gt;&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Back From FOSDEM 2015</title>
      <link>http://tapoueh.org/blog/2015/02/back-from-fosdem-2015/</link>
      <pubDate>Mon, 09 Feb 2015 10:36:00 +0100</pubDate>
      
      <guid>http://tapoueh.org/blog/2015/02/back-from-fosdem-2015/</guid>
      <description>&lt;p&gt;The
&lt;a href=&#34;https://fosdem.org/2015/&#34;&gt;FOSDEM 2015&lt;/a&gt; edition has been awesome this year, the usual mix of meeting
with old friends, talking about interesting topics, seeing tremendous
activity in all Open Source domains, and having Belgium beers in the
evenings.&lt;/p&gt;

&lt;p&gt;&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>My First Slashdot Effect</title>
      <link>http://tapoueh.org/blog/2015/01/my-first-slashdot-effect/</link>
      <pubDate>Thu, 22 Jan 2015 01:48:00 +0100</pubDate>
      
      <guid>http://tapoueh.org/blog/2015/01/my-first-slashdot-effect/</guid>
      <description>&lt;p&gt;Thanks to the
&lt;a href=&#34;http://postgresweekly.com/issues/89&#34;&gt;Postgres Weekly issue #89&lt;/a&gt; and a post to
&lt;a href=&#34;https://news.ycombinator.com/news&#34;&gt;Hacker News&lt;/a&gt; front page
(see
&lt;a href=&#34;https://news.ycombinator.com/item?id=8924270&#34;&gt;Pgloader: A High-speed PostgreSQL Swiss Army Knife, Written in Lisp&lt;/a&gt; it
well seems that I just had my first
&lt;a href=&#34;http://en.wikipedia.org/wiki/Slashdot_effect&#34;&gt;Slashdot effect&lt;/a&gt;&amp;hellip;&lt;/p&gt;

&lt;p&gt;&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>New release: pgloader 3.2</title>
      <link>http://tapoueh.org/blog/2015/01/new-release-pgloader-3.2/</link>
      <pubDate>Fri, 16 Jan 2015 09:35:00 +0100</pubDate>
      
      <guid>http://tapoueh.org/blog/2015/01/new-release-pgloader-3.2/</guid>
      <description>&lt;p&gt;PostgreSQL comes with an awesome bulk copy protocol and tooling best known
as the
&lt;a href=&#34;http://www.postgresql.org/docs/current/static/sql-copy.html&#34;&gt;COPY&lt;/a&gt; and
&lt;code&gt;\copy&lt;/code&gt; commands. Being a transactional system, PostgreSQL
COPY implementation will
&lt;code&gt;ROLLBACK&lt;/code&gt; any work done if a single error is found
in the data set you&amp;rsquo;re importing. That&amp;rsquo;s the reason why
&lt;a href=&#34;http://pgloader.io/&#34;&gt;pgloader&lt;/a&gt; got
started: it provides with error handling for the
&lt;a href=&#34;http://www.postgresql.org/docs/9.3/static/protocol-flow.html#PROTOCOL-COPY&#34;&gt;COPY protocol&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Going to Chicago, Postgres Open</title>
      <link>http://tapoueh.org/blog/2014/08/going-to-chicago-postgres-open/</link>
      <pubDate>Fri, 29 Aug 2014 14:26:00 +0200</pubDate>
      
      <guid>http://tapoueh.org/blog/2014/08/going-to-chicago-postgres-open/</guid>
      <description>Next month, Postgres Open 2014 is happening in Chicago, and I&amp;rsquo;ll have the pleasure to host a tutorial about PostgreSQL Extensions Writing &amp;amp; Using Postgres Extensions, and a talk aimed at developers wanting to make the best out of PostgreSQL, PostgreSQL for developers:
   
The tutorial is based on first hand experience on the PostgreSQL Extension Packaging System both as a user and a developer. It&amp;rsquo;s a series of practical use cases where using extensions will simplify your life a lot, and each of those practical use case is using real world data (thanks to pgloader).</description>
    </item>
    
    <item>
      <title>Turn your PostgreSQL queries into Charts</title>
      <link>http://tapoueh.org/blog/2014/08/turn-your-postgresql-queries-into-charts/</link>
      <pubDate>Mon, 25 Aug 2014 14:09:00 +0200</pubDate>
      
      <guid>http://tapoueh.org/blog/2014/08/turn-your-postgresql-queries-into-charts/</guid>
      <description>Earlier this year we did compare compare Aggregating NBA data, PostgreSQL vs MongoDB then talked about PostgreSQL, Aggregates and histograms where we even produced a nice Histogram chart directly within the awesome psql console. Today, let&amp;rsquo;s get that same idea to the next level, with pgcharts:
   
The new pgcharts application
The application&amp;rsquo;s specifications are quite simple: edit an SQL query, set your categories and your data series, add in some legends, and get a nice chart.</description>
    </item>
    
    <item>
      <title>Why is pgloader so much faster?</title>
      <link>http://tapoueh.org/blog/2014/05/why-is-pgloader-so-much-faster/</link>
      <pubDate>Wed, 14 May 2014 14:59:00 +0200</pubDate>
      
      <guid>http://tapoueh.org/blog/2014/05/why-is-pgloader-so-much-faster/</guid>
      <description>pgloader loads data into PostgreSQL. The new version is stable enough nowadays that it&amp;rsquo;s soon to be released, the last piece of the 3.1.0 puzzle being full debian packaging of the tool.
The pgloader logo is a loader truck, just because.
As you might have noticed if you&amp;rsquo;ve read my blog before, I decided that pgloader needed a full rewrite in order for it to be able to enter the current decade as a relevant tool.</description>
    </item>
    
    <item>
      <title>New York!</title>
      <link>http://tapoueh.org/blog/2014/04/new-york/</link>
      <pubDate>Thu, 17 Apr 2014 13:53:00 +0200</pubDate>
      
      <guid>http://tapoueh.org/blog/2014/04/new-york/</guid>
      <description>A couple of week ago I had the chance to participate into the PGConf NYC 2014 Conference, one of the biggest conferences about PostgreSQL worldwide.
I presented one of my favourite talks over there, where the whole goal is to blow the mind of innocent developers and show them how much they can do in just SQL.
   
PostgreSQL for developers, window functions galore!
The basis for the talk is this detailed blog entry about the Reset Counter application and how to leverage SQL to write the code for it.</description>
    </item>
    
    <item>
      <title>Nordic PostgreSQL Day 2014</title>
      <link>http://tapoueh.org/blog/2014/03/nordic-postgresql-day-2014/</link>
      <pubDate>Tue, 25 Mar 2014 16:54:00 +0100</pubDate>
      
      <guid>http://tapoueh.org/blog/2014/03/nordic-postgresql-day-2014/</guid>
      <description>Last week some PostgreSQL users, contributors and advocates have organized a really great conference in Stockholm, Sweden, where I had the please to give the following talk:
   
PostgreSQL is YeSQL!
Nordic PostgreSQL Conference The conference was very well put together and the occasion to meet with plenty of well known PostgreSQL friends and newcomers to the community too. If you were there, I hope you had as much of a good time than I did!</description>
    </item>
    
    <item>
      <title>PostgreSQL, Aggregates and Histograms</title>
      <link>http://tapoueh.org/blog/2014/02/postgresql-aggregates-and-histograms/</link>
      <pubDate>Fri, 21 Feb 2014 13:25:00 +0100</pubDate>
      
      <guid>http://tapoueh.org/blog/2014/02/postgresql-aggregates-and-histograms/</guid>
      <description>&lt;p&gt;In our previous article
&lt;a href=&#34;http://tapoueh.org/blog/2014/02/17-aggregating-nba-data-PostgreSQL-vs-MongoDB&#34;&gt;Aggregating NBA data, PostgreSQL vs MongoDB&lt;/a&gt; we spent
time comparing the pretty new
&lt;em&gt;MongoDB Aggregation Framework&lt;/em&gt; with the decades
old SQL aggregates. Today, let&amp;rsquo;s showcase more of those SQL aggregates,
producing a nice
&lt;em&gt;histogram&lt;/em&gt; right from our SQL console.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Aggregating NBA data, PostgreSQL vs MongoDB</title>
      <link>http://tapoueh.org/blog/2014/02/aggregating-nba-data-postgresql-vs-mongodb/</link>
      <pubDate>Mon, 17 Feb 2014 23:40:00 +0100</pubDate>
      
      <guid>http://tapoueh.org/blog/2014/02/aggregating-nba-data-postgresql-vs-mongodb/</guid>
      <description>&lt;p&gt;When reading the article
&lt;a href=&#34;http://thecodebarbarian.wordpress.com/2014/02/14/crunching-30-years-of-nba-data-with-mongodb-aggregation/&#34;&gt;Crunching 30 Years of NBA Data with MongoDB Aggregation&lt;/a&gt; I coulnd&amp;rsquo;t help but
think that we&amp;rsquo;ve been enjoying
&lt;a href=&#34;http://www.postgresql.org/docs/current/static/tutorial-agg.html&#34;&gt;aggregates&lt;/a&gt; in SQL for 3 or 4 decades already.
When using
&lt;a href=&#34;http://www.postgresql.org/&#34;&gt;PostgreSQL&lt;/a&gt; it&amp;rsquo;s even easy to actually add your own aggregates
given the SQL command
&lt;a href=&#34;http://www.postgresql.org/docs/current/static/sql-createaggregate.html&#34;&gt;create aggregate&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>PostgreSQL FOSDEM Conference</title>
      <link>http://tapoueh.org/blog/2014/02/postgresql-fosdem-conference/</link>
      <pubDate>Mon, 03 Feb 2014 10:04:00 +0100</pubDate>
      
      <guid>http://tapoueh.org/blog/2014/02/postgresql-fosdem-conference/</guid>
      <description>Back from the FODESM 2014 Conference, here&amp;rsquo;s the slides I&amp;rsquo;ve been using for the Advanced Extension Use Cases talk I gave, based on the ongoing work to be found under the Tour of Extensions index in this web site.
   
If you&amp;rsquo;re interested into the talk contents, then you might be interested into the following list of articles where I actually did all the work leading to the slides in the above PDF:</description>
    </item>
    
    <item>
      <title>FOSDEM 2014</title>
      <link>http://tapoueh.org/blog/2014/01/fosdem-2014/</link>
      <pubDate>Wed, 29 Jan 2014 11:03:00 +0100</pubDate>
      
      <guid>http://tapoueh.org/blog/2014/01/fosdem-2014/</guid>
      <description>This year again the PostgreSQL community is organising a FOSDEM PGDay rigth before the main event. Have a look at the PostgreSQL FOSDEM Schedule, it&amp;rsquo;s packed with awesome talks&amp;hellip; personnaly, it&amp;rsquo;s been awhile since I wanted to see so many of them!
I will be talking about Advanced Extension Use Cases on Friday, see you in Brussels!</description>
    </item>
    
    <item>
      <title>Import fixed width data with pgloader</title>
      <link>http://tapoueh.org/blog/2013/11/import-fixed-width-data-with-pgloader/</link>
      <pubDate>Mon, 18 Nov 2013 12:48:00 +0100</pubDate>
      
      <guid>http://tapoueh.org/blog/2013/11/import-fixed-width-data-with-pgloader/</guid>
      <description>A long time ago we talked about how to Import fixed width data with pgloader, following up on other stories still online at Postgres OnLine Journal and on David Fetter&amp;rsquo;s blog. Back then, I showed that using pgloader made it easier to import the data, but also showed quite poor performances characteristics due to using the debug mode in the timings. Let&amp;rsquo;s update that article with current pgloader wonders!</description>
    </item>
    
    <item>
      <title>Migrating Sakila from MySQL to PostgreSQL</title>
      <link>http://tapoueh.org/blog/2013/11/migrating-sakila-from-mysql-to-postgresql/</link>
      <pubDate>Tue, 12 Nov 2013 11:37:00 +0100</pubDate>
      
      <guid>http://tapoueh.org/blog/2013/11/migrating-sakila-from-mysql-to-postgresql/</guid>
      <description>As presented at the PostgreSQL Conference Europe the new version of pgloader is now able to fully migrate a MySQL database, including discovering the schema, casting data types, transforming data and default values. Sakila is the traditional MySQL example database, in this article we&amp;rsquo;re going to fully migrate it over to PostgreSQL.
What about switching to PostgreSQL, it&amp;rsquo;s easier than ever.
Without further ado, here&amp;rsquo;s what happens when you ask pgloader to please migrate the whole thing over to PostgreSQL:</description>
    </item>
    
    <item>
      <title>Back From Dublin</title>
      <link>http://tapoueh.org/blog/2013/11/back-from-dublin/</link>
      <pubDate>Tue, 05 Nov 2013 09:53:00 +0100</pubDate>
      
      <guid>http://tapoueh.org/blog/2013/11/back-from-dublin/</guid>
      <description>Last week I had the pleasure to present two talks at the awesome PostgreSQL Conference Europe. The first one was actually a tutorial about Writing &amp;amp; using Postgres Extensions where we spent 3 hours on what are PostgreSQL Extensions, what you can expect from them, and how to develop a new one. Then I also had the opportunity to present the new version of pgloader in a talk about Migrating from MySQL to PostgreSQL.</description>
    </item>
    
    <item>
      <title>Denormalizing Tags</title>
      <link>http://tapoueh.org/blog/2013/10/denormalizing-tags/</link>
      <pubDate>Thu, 24 Oct 2013 13:40:00 +0200</pubDate>
      
      <guid>http://tapoueh.org/blog/2013/10/denormalizing-tags/</guid>
      <description>In our Tour of Extensions today&amp;rsquo;s article is about advanced tag indexing. We have a great data collection to play with and our goal today is to be able to quickly find data matching a complex set of tags. So, let&amp;rsquo;s find out those lastfm tracks that are tagged as blues and rhythm and blues, for instance.
 In this article, we&amp;rsquo;re going to play with music related tags</description>
    </item>
    
    <item>
      <title>An Interview about MariaDB and PostgreSQL</title>
      <link>http://tapoueh.org/blog/2013/10/an-interview-about-mariadb-and-postgresql/</link>
      <pubDate>Wed, 16 Oct 2013 21:07:00 +0200</pubDate>
      
      <guid>http://tapoueh.org/blog/2013/10/an-interview-about-mariadb-and-postgresql/</guid>
      <description>At the Open World Forum two weeks ago I had the pleasure to meet with Colin Charles. We had a nice talk about the current state of both MariaDB and PostgreSQL, and even were both interviewed by the Open World Forum Team. The interview is now available online. Dear French readers, it&amp;rsquo;s in English.
Here&amp;rsquo;s the video:
  Executive Summary: MariaDB is a drop-in fully Open Source replacement for MySQL and sees quite some progress and innovation being made, and PostgreSQL is YeSQL!</description>
    </item>
    
    <item>
      <title>PostgreSQL Autonomous Transaction</title>
      <link>http://tapoueh.org/blog/2013/10/postgresql-autonomous-transaction/</link>
      <pubDate>Mon, 14 Oct 2013 11:25:00 +0200</pubDate>
      
      <guid>http://tapoueh.org/blog/2013/10/postgresql-autonomous-transaction/</guid>
      <description>&lt;p&gt;&lt;a href=&#34;http://www.postgresql.org/&#34;&gt;PostgreSQL&lt;/a&gt; is an all round impressive
&lt;em&gt;Relational DataBase Management System&lt;/em&gt;
which implements the SQL standard (see the very useful reference page
&lt;a href=&#34;http://troels.arvin.dk/db/rdbms/&#34;&gt;Comparison of different SQL implementations&lt;/a&gt; for details). PostgreSQL also
provides with unique solutions in the database market and has been leading
innovation for some years now. Still, there&amp;rsquo;s no support for
&lt;strong&gt;&lt;em&gt;Autonomous
Transactions&lt;/em&gt;&lt;/strong&gt; within the server itself. Let&amp;rsquo;s have a look at how to easily
implement them with
&lt;a href=&#34;http://wiki.postgresql.org/wiki/PL/Proxy&#34;&gt;PL/Proxy&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Geolocation with PostgreSQL</title>
      <link>http://tapoueh.org/blog/2013/10/geolocation-with-postgresql/</link>
      <pubDate>Wed, 09 Oct 2013 17:42:00 +0200</pubDate>
      
      <guid>http://tapoueh.org/blog/2013/10/geolocation-with-postgresql/</guid>
      <description>&lt;p&gt;Let&amp;rsquo;s get back to our
&lt;a href=&#34;http://tapoueh.org/tags/extensions&#34;&gt;Tour of Extensions&lt;/a&gt; that had to be kept aside for
awhile with other concerns such as last chance
&lt;a href=&#34;http://tapoueh.org/blog/2013/09/16-PostgreSQL-data-recovery&#34;&gt;PostgreSQL data recovery&lt;/a&gt;. Now
that we have a
&lt;em&gt;data loading&lt;/em&gt; tool up to the task (read about it in the
&lt;a href=&#34;http://tapoueh.org/blog/2013/10/01-loading-geolocation-data&#34;&gt;Loading Geolocation Data&lt;/a&gt; article) we&amp;rsquo;re going to be able to play with the
awesome
&lt;a href=&#34;https://github.com/RhodiumToad/ip4r&#34;&gt;ip4r&lt;/a&gt; extension from
&lt;a href=&#34;http://blog.rhodiumtoad.org.uk/&#34;&gt;RhodiumToad&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Open World Forum Conference</title>
      <link>http://tapoueh.org/blog/2013/10/open-world-forum-conference/</link>
      <pubDate>Mon, 07 Oct 2013 22:05:00 +0200</pubDate>
      
      <guid>http://tapoueh.org/blog/2013/10/open-world-forum-conference/</guid>
      <description>Last Friday I had the chance to be speaking at the Open World Forum in the NewSQL track, where we had lots of interest and excitement around the NoSQL offerings. Of course, my talk was about explaining how PostgreSQL is Web Scale with some historical background and technical examples about what this database engine is currently capable of.
   
PostgreSQL is Web Scale. PostgreSQL is YeSQL!
The conclusion of the talk is that indeed, PostgreSQL is YeSQL!</description>
    </item>
    
    <item>
      <title>A Worthwile Micro Optimisation</title>
      <link>http://tapoueh.org/blog/2013/10/a-worthwile-micro-optimisation/</link>
      <pubDate>Thu, 03 Oct 2013 22:10:00 +0200</pubDate>
      
      <guid>http://tapoueh.org/blog/2013/10/a-worthwile-micro-optimisation/</guid>
      <description>In our previous article about Loading Geolocation Data, we did load some data into PostgreSQL and saw the quite noticable impact of a user transformation. As it happens, the function that did the integer to IP representation was so naive as to scratch the micro optimisation itch of some Common Lisp hackers: thanks a lot guys, in particular stassats who came up with the solution we&amp;rsquo;re seeing now.
The previous code was a straight rewrite of the provided documentation in Common Lisp.</description>
    </item>
    
    <item>
      <title>Loading Geolocation Data</title>
      <link>http://tapoueh.org/blog/2013/10/loading-geolocation-data/</link>
      <pubDate>Tue, 01 Oct 2013 16:52:00 +0200</pubDate>
      
      <guid>http://tapoueh.org/blog/2013/10/loading-geolocation-data/</guid>
      <description>As I&amp;rsquo;ve been mentionning in the past already, I&amp;rsquo;m currently rewriting pgloader from scratch in Common Lisp. In terms of technical debt that&amp;rsquo;s akin to declaring bankrupcy, which is both sad news and good news as there&amp;rsquo;s suddenly new hope of doing it right this time.
Let&amp;rsquo;s dive into the python to common lisp rewrite
Why rewriting pgloader? Several problems hinted me into doing something other than maintaining the code I had for pgloader.</description>
    </item>
    
    <item>
      <title>Open World Forum 2013</title>
      <link>http://tapoueh.org/blog/2013/09/open-world-forum-2013/</link>
      <pubDate>Thu, 19 Sep 2013 17:44:00 +0200</pubDate>
      
      <guid>http://tapoueh.org/blog/2013/09/open-world-forum-2013/</guid>
      <description>Have you heard about the Open World Forum conference that takes place in Paris, October 3-5, 2013? I&amp;rsquo;ll be presenting a talk about PostgreSQL in the track NewSQL: Managing large data sets with relational technologies.
   
Open World Forum used to be Open Source Developers Conference
My talk is PostgreSQL is web scale and here&amp;rsquo;s the summary:
 We call it the world&amp;rsquo;s most advanced open source database, and we are actually offering in the same package full ACID compliance per default and advanced trade-offs to reach any kind of flexibility needed, all with per-transaction controls.</description>
    </item>
    
    <item>
      <title>PostgreSQL data recovery</title>
      <link>http://tapoueh.org/blog/2013/09/postgresql-data-recovery/</link>
      <pubDate>Tue, 17 Sep 2013 10:39:00 +0200</pubDate>
      
      <guid>http://tapoueh.org/blog/2013/09/postgresql-data-recovery/</guid>
      <description>The following story is only interesting to read if you like it when bad things happen, or if you don&amp;rsquo;t have a trustworthy backup policy in place. By trustworthy I mean that each backup you take must be tested with a test recovery job. Only tested backups will prove useful when you need them. So go read our Backup and Restore documentation chapter then learn how to setup Barman for handling physical backups and Point In Time Recovery.</description>
    </item>
    
    <item>
      <title>Using trigrams against typos</title>
      <link>http://tapoueh.org/blog/2013/09/using-trigrams-against-typos/</link>
      <pubDate>Fri, 06 Sep 2013 16:15:00 +0200</pubDate>
      
      <guid>http://tapoueh.org/blog/2013/09/using-trigrams-against-typos/</guid>
      <description>&lt;p&gt;In our ongoing
&lt;a href=&#34;http://tapoueh.org/tags/extensions&#34;&gt;Tour of Extensions&lt;/a&gt; we played with
&lt;a href=&#34;http://www.postgresql.org/docs/current/static/earthdistance.html&#34;&gt;earth distance&lt;/a&gt; in
&lt;a href=&#34;http://tapoueh.org/blog/2013/08/05-earthdistance&#34;&gt;How far is the nearest pub?&lt;/a&gt; then with
&lt;a href=&#34;http://www.postgresql.org/docs/current/static/hstore.html&#34;&gt;hstore&lt;/a&gt; in a series about trigger,
first to generalize
&lt;a href=&#34;http://tapoueh.org/blog/2013/08/23-parametrized-triggers&#34;&gt;Trigger Parameters&lt;/a&gt; then to enable us to
&lt;a href=&#34;http://tapoueh.org/blog/2013/08/27-auditing-changes-with-hstore&#34;&gt;Auditing Changes with Hstore&lt;/a&gt;. Today we are going to work with
&lt;a href=&#34;http://www.postgresql.org/docs/current/static/pgtrgm.html&#34;&gt;pg_trgm&lt;/a&gt; which
is the
&lt;em&gt;trigrams&lt;/em&gt; PostgreSQL extension: its usage got seriously enhanced in
recent PostgreSQL releases and it&amp;rsquo;s now a poor&amp;rsquo;s man
&lt;a href=&#34;http://www.postgresql.org/docs/current/static/textsearch.html&#34;&gt;Full Text Search&lt;/a&gt;
engine.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Auditing Changes with Hstore</title>
      <link>http://tapoueh.org/blog/2013/08/auditing-changes-with-hstore/</link>
      <pubDate>Tue, 27 Aug 2013 17:35:00 +0200</pubDate>
      
      <guid>http://tapoueh.org/blog/2013/08/auditing-changes-with-hstore/</guid>
      <description>&lt;p&gt;In a previous article about
&lt;a href=&#34;http://tapoueh.org/blog/2013/08/23-parametrized-triggers&#34;&gt;Trigger Parameters&lt;/a&gt; we have been using the
extension
&lt;a href=&#34;http://www.postgresql.org/docs/9.2/static/hstore.html&#34;&gt;hstore&lt;/a&gt; in order to compute some extra field in our records, where
the fields used both for the computation and for storing the results were
passed in as
&lt;em&gt;dynamic parameters&lt;/em&gt;. Today we&amp;rsquo;re going to see another
&lt;em&gt;trigger&lt;/em&gt;
use case for
&lt;em&gt;hstore&lt;/em&gt;: we are going to record changes made to our tuples.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Trigger Parameters</title>
      <link>http://tapoueh.org/blog/2013/08/trigger-parameters/</link>
      <pubDate>Fri, 23 Aug 2013 12:08:00 +0200</pubDate>
      
      <guid>http://tapoueh.org/blog/2013/08/trigger-parameters/</guid>
      <description>&lt;p&gt;Sometimes you want to compute values automatically at
&lt;code&gt;INSERT&lt;/code&gt; time, like for
example a
&lt;em&gt;duration&lt;/em&gt; column out of a
&lt;em&gt;start&lt;/em&gt; and an
&lt;em&gt;end&lt;/em&gt; column, both
&lt;em&gt;timestamptz&lt;/em&gt;. It&amp;rsquo;s easy enough to do with a
&lt;code&gt;BEFORE TRIGGER&lt;/code&gt; on your table.
What&amp;rsquo;s more complex is to come up with a parametrized spelling of the
trigger, where you can attach the same
&lt;em&gt;stored procedure&lt;/em&gt; to any table even
when the column names are different from one another.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Understanding Window Functions</title>
      <link>http://tapoueh.org/blog/2013/08/understanding-window-functions/</link>
      <pubDate>Tue, 20 Aug 2013 12:04:00 +0200</pubDate>
      
      <guid>http://tapoueh.org/blog/2013/08/understanding-window-functions/</guid>
      <description>&lt;p&gt;There was SQL before
&lt;a href=&#34;http://www.postgresql.org/docs/current/static/tutorial-window.html&#34;&gt;window functions&lt;/a&gt; and SQL after
&lt;em&gt;window functions&lt;/em&gt;: that&amp;rsquo;s
how powerful this tool is. Being that of a deal breaker unfortunately means
that it can be quite hard to grasp the feature. This article aims at making
it crystal clear so that you can begin using it today and are able to reason
about it and recognize cases where you want to be using
&lt;em&gt;window functions&lt;/em&gt;.&lt;/p&gt;

&lt;p&gt;&lt;center&gt;


 
  
  
  
  
    
      
    
  
    
  
    
      
    
  

&lt;div class=&#34;figure fig50 dim-margin&#34; &gt;
  
    &lt;a class=&#34;fancybox&#34; href=&#34;http://tapoueh.org/img/old/moving_window.gif&#34; data-fancybox-group=&#34;&#34;&gt;
  
    &lt;img class=&#34;fig-img&#34; src=&#34;http://tapoueh.org/img/old/moving_window.gif&#34; &gt;
  
    &lt;/a&gt;
  
  
&lt;/div&gt;

&lt;/center&gt;
&lt;center&gt;&lt;em&gt;We see a part of the data as if through a little window&lt;/em&gt;&lt;/center&gt;&lt;/p&gt;

&lt;p&gt;&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Migrating from MySQL to PostgreSQL</title>
      <link>http://tapoueh.org/blog/2013/08/migrating-from-mysql-to-postgresql/</link>
      <pubDate>Thu, 08 Aug 2013 17:41:00 +0200</pubDate>
      
      <guid>http://tapoueh.org/blog/2013/08/migrating-from-mysql-to-postgresql/</guid>
      <description>About the only time when I will accept to work with MySQL is when you need help to migrate away from it because you decided to move to PostgreSQL instead. And it&amp;rsquo;s already been too much of a pain really, so after all this time I began consolidating what I know about that topic and am writing a software to help me here. Consider it the MySQL Migration Toolkit.
A real classic that I couldn&amp;rsquo;t resist using here&amp;hellip;</description>
    </item>
    
    <item>
      <title>How far is the nearest pub?</title>
      <link>http://tapoueh.org/blog/2013/08/how-far-is-the-nearest-pub/</link>
      <pubDate>Mon, 05 Aug 2013 08:11:00 +0200</pubDate>
      
      <guid>http://tapoueh.org/blog/2013/08/how-far-is-the-nearest-pub/</guid>
      <description>&lt;p&gt;In our recent article about
&lt;a href=&#34;http://tapoueh.org/blog/2013/08/02-pub-names-knn&#34;&gt;The Most Popular Pub Names&lt;/a&gt; we did have a look at
how to find the pubs nearby, but didn&amp;rsquo;t compute the
&lt;strong&gt;distance&lt;/strong&gt; in between that
pub and us. That&amp;rsquo;s because how to compute a distance given a position on the
earth expressed as
&lt;em&gt;longitude&lt;/em&gt; and
&lt;em&gt;latitude&lt;/em&gt; is not that easy. Today, we are
going to solve that problem nonetheless, thanks to
&lt;a href=&#34;http://www.postgresql.org/docs/9.2/interactive/extend-extensions.html&#34;&gt;PostgreSQL Extensions&lt;/a&gt;.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>The Most Popular Pub Names</title>
      <link>http://tapoueh.org/blog/2013/08/the-most-popular-pub-names/</link>
      <pubDate>Fri, 02 Aug 2013 10:19:00 +0200</pubDate>
      
      <guid>http://tapoueh.org/blog/2013/08/the-most-popular-pub-names/</guid>
      <description>&lt;p&gt;In his article titled
&lt;a href=&#34;http://blog.mongodb.org/post/56876800071/the-most-popular-pub-names?utm_content=buffer4922c&amp;amp;utm_source=buffer&amp;amp;utm_medium=facebook&amp;amp;utm_campaign=Buffer&#34;&gt;The Most Popular Pub Names&lt;/a&gt;
&lt;em&gt;Ross Lawley&lt;/em&gt; did show us how
to perform some quite interesting
&lt;em&gt;geographic queries&lt;/em&gt; against
&lt;a href=&#34;http://www.mongodb.org/&#34;&gt;MongoDB&lt;/a&gt;, using
some nice
&lt;em&gt;Open Data&lt;/em&gt; found at the
&lt;a href=&#34;http://www.openstreetmap.org/&#34;&gt;Open Street Map&lt;/a&gt; project.&lt;/p&gt;

&lt;p&gt;&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>OSCON, Portland, and PDXPUG</title>
      <link>http://tapoueh.org/blog/2013/07/oscon-portland-and-pdxpug/</link>
      <pubDate>Mon, 29 Jul 2013 17:09:00 +0200</pubDate>
      
      <guid>http://tapoueh.org/blog/2013/07/oscon-portland-and-pdxpug/</guid>
      <description>After spending an awesome week in San Francisco, CA I&amp;rsquo;m lucky enough to be spending another week in the USA, in Portand, OR. The main excuse for showing up here has been OSCON where I presented a talk about the fotolog migration from MySQL to PostgreSQL.
Mark Wong is doing some serious database crochet work!
Fotolog is a photo sharing website having more than 32 millions of users sharing more than a billion of photos, which made for a very interesting migration use case.</description>
    </item>
    
    <item>
      <title>Talking at the SFPUG</title>
      <link>http://tapoueh.org/blog/2013/07/talking-at-the-sfpug/</link>
      <pubDate>Fri, 19 Jul 2013 10:24:00 +0200</pubDate>
      
      <guid>http://tapoueh.org/blog/2013/07/talking-at-the-sfpug/</guid>
      <description>Those days feel really lucky to me. I&amp;rsquo;m currently visiting friends and customers in San Francisco, and really enjoying my trip here! Of course Josh Berkus took the opportunity to organise a SFPUG meeting and I had the pleasure of being the speaker over there.
My talk was about the most recent version of Skytools and the opportunity to realise that we&amp;rsquo;re still missing a lot on documentation. One of the attendee did propose to help us on that front as he apparently really likes technical writing.</description>
    </item>
    
    <item>
      <title>Back from CHAR(13)</title>
      <link>http://tapoueh.org/blog/2013/07/back-from-char13/</link>
      <pubDate>Mon, 15 Jul 2013 09:49:00 +0200</pubDate>
      
      <guid>http://tapoueh.org/blog/2013/07/back-from-char13/</guid>
      <description>Last week was held the CHAR(13) conference in a great venue in the UK countryside. Not only did we discover UK under good weather conditions and some local beers, we also did share a lot of good ideas!
The Hordwood House is quite of a maze really!
The conference was run side to side with PGDAY UK, and those two days were packed with great conferences!
I had the pleasure to present a talk about Advanced Distributed Architectures where some examples of architectures using Streaming Replication, Skytools and PLproxy are shown.</description>
    </item>
    
    <item>
      <title>Archiving data as fast as possible</title>
      <link>http://tapoueh.org/blog/2013/07/archiving-data-as-fast-as-possible/</link>
      <pubDate>Fri, 05 Jul 2013 15:30:00 +0200</pubDate>
      
      <guid>http://tapoueh.org/blog/2013/07/archiving-data-as-fast-as-possible/</guid>
      <description>&lt;p&gt;In a recent article here we&amp;rsquo;ve been talking about how do do
&lt;a href=&#34;http://tapoueh.org/blog/2013/03/15-batch-update&#34;&gt;Batch Updates&lt;/a&gt; in
a very efficient way, using the
&lt;em&gt;Writable CTE&lt;/em&gt; features available in
PostgreSQL 9.1. I sometime read how
&lt;a href=&#34;http://www.postgresql.org/docs/current/interactive/queries-with.html&#34;&gt;Common Table Expressions&lt;/a&gt; changed the
life of fellow DBAs and developers, and would say that
&lt;em&gt;Writable CTE&lt;/em&gt; are at
least the same boost again.&lt;/p&gt;

&lt;p&gt;&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Simple Case for Pivoting in SQL</title>
      <link>http://tapoueh.org/blog/2013/07/simple-case-for-pivoting-in-sql/</link>
      <pubDate>Thu, 04 Jul 2013 15:55:00 +0200</pubDate>
      
      <guid>http://tapoueh.org/blog/2013/07/simple-case-for-pivoting-in-sql/</guid>
      <description>In a recent article Craig Kerstiens from Heroku did demo the really useful crosstab extension. That function allows you to pivot a table so that you can see the data from different categories in separate columns in the same row rather than in separate rows. The article from Craig is Pivoting in Postgres.
Pivoting a matrix, also known as a matrix transposition
Let&amp;rsquo;s do the same setup as he did, with a table containing some randomly generated data about hypothetical visits to a web page, say, by date then by operating system.</description>
    </item>
    
    <item>
      <title>Conferences Report</title>
      <link>http://tapoueh.org/blog/2013/07/conferences-report/</link>
      <pubDate>Wed, 03 Jul 2013 16:53:00 +0200</pubDate>
      
      <guid>http://tapoueh.org/blog/2013/07/conferences-report/</guid>
      <description>Recently I&amp;rsquo;ve been to some more conferences and didn&amp;rsquo;t take the time to blog about them, even though I really did have great fun over there. So I felt I should take some time and report about my experience at those conferences. And of course, some more is on the way, as the PostgreSQL Conference Tour gets busier each year it seems.
And PostgreSQL Conferences get more attendees each year!</description>
    </item>
    
    <item>
      <title>Make the Most ouf of SQL</title>
      <link>http://tapoueh.org/blog/2013/07/make-the-most-ouf-of-sql/</link>
      <pubDate>Tue, 02 Jul 2013 22:22:00 +0200</pubDate>
      
      <guid>http://tapoueh.org/blog/2013/07/make-the-most-ouf-of-sql/</guid>
      <description>Tonight I had the pleasure to present a talk at the Dublin PostgreSQL User Group using remote technologies. The talk is about how to make the most ouf of PostgreSQL when using SQL as a developer, and tries to convince you to dive into mastering SQL by showing how to solve an application example all in SQL, using window functions and common table expressions.
   
PostgreSQL for developer</description>
    </item>
    
    <item>
      <title>Nearest Big City</title>
      <link>http://tapoueh.org/blog/2013/05/nearest-big-city/</link>
      <pubDate>Thu, 02 May 2013 11:34:00 +0200</pubDate>
      
      <guid>http://tapoueh.org/blog/2013/05/nearest-big-city/</guid>
      <description>In this article, we want to find the town with the greatest number of inhabitants near a given location.
 A very localized example We first need to find and import some data, and I found at the following place a CSV listing of french cities with coordinates and population and some numbers of interest for the exercise here.
To import the data set, we first need a table, then a COPY command:</description>
    </item>
    
    <item>
      <title>Bulk Replication</title>
      <link>http://tapoueh.org/blog/2013/03/bulk-replication/</link>
      <pubDate>Mon, 18 Mar 2013 14:54:00 +0100</pubDate>
      
      <guid>http://tapoueh.org/blog/2013/03/bulk-replication/</guid>
      <description>In the previous article here we talked about how to properly update more than one row at a time, under the title Batch Update. We did consider performances, including network round trips, and did look at the behavior of our results when used concurrently.
A case where we want to apply the previous article approach is when replicating data with a trigger based solution, such as SkyTools and londiste. Well, maybe not in all cases, we need to have a amount of UPDATE trafic worthy of setting up the solution.</description>
    </item>
    
    <item>
      <title>Batch Update</title>
      <link>http://tapoueh.org/blog/2013/03/batch-update/</link>
      <pubDate>Fri, 15 Mar 2013 10:47:00 +0100</pubDate>
      
      <guid>http://tapoueh.org/blog/2013/03/batch-update/</guid>
      <description>&lt;p&gt;Performance consulting involves some tricks that you have to teach over and
over again. One of them is that SQL tends to be so much better at dealing
with plenty of rows in a single statement when compared to running as many
statements, each one against a single row.&lt;/p&gt;

&lt;p&gt;&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Emacs Conference</title>
      <link>http://tapoueh.org/blog/2013/03/emacs-conference/</link>
      <pubDate>Mon, 04 Mar 2013 13:58:00 +0100</pubDate>
      
      <guid>http://tapoueh.org/blog/2013/03/emacs-conference/</guid>
      <description>The Emacs Conference is happening, it&amp;rsquo;s real, and it will take place at the end of this month in London. Check it out, and register at Emacs Conference Event Brite. It&amp;rsquo;s free and there&amp;rsquo;s still some availability.
It&amp;rsquo;s all about Emacs, and it rocks!
We have a great line-up for this conference, which makes me proud to be able to be there. If you&amp;rsquo;ve ever been paying attention when using Emacs then you&amp;rsquo;ve already heard those names: Sacha Chua is frequently blogging about how she manages to improve her workflow thanks to Emacs Lisp, John Wiegley is a proficient Emacs contributor maybe best known for his ledger Emacs Mode, then we have Luke Gorrie who hacked up SLIME among other things, we also have Nic Ferrier who is starting a revolution in how to use Emacs Lisp with elnode.</description>
    </item>
    
    <item>
      <title>HyperLogLog Unions</title>
      <link>http://tapoueh.org/blog/2013/02/hyperloglog-unions/</link>
      <pubDate>Tue, 26 Feb 2013 12:44:00 +0100</pubDate>
      
      <guid>http://tapoueh.org/blog/2013/02/hyperloglog-unions/</guid>
      <description>In the article from yesterday we talked about PostgreSQL HyperLogLog with some details. The real magic of that extension has been skimmed over though, and needs another very small article all by itself, in case you missed it.
Which Set Operation do you want for counting unique values?
The first query here has the default level of magic in it, really. What happens is that each time we do an update of the HyperLogLog hash value, we update some data which are allowing us to compute its cardinality.</description>
    </item>
    
    <item>
      <title>PostgreSQL HyperLogLog</title>
      <link>http://tapoueh.org/blog/2013/02/postgresql-hyperloglog/</link>
      <pubDate>Mon, 25 Feb 2013 10:23:00 +0100</pubDate>
      
      <guid>http://tapoueh.org/blog/2013/02/postgresql-hyperloglog/</guid>
      <description>&lt;p&gt;If you&amp;rsquo;ve been following along at home the newer statistics developments,
you might have heard about this new
&lt;a href=&#34;http://research.google.com/pubs/pub40671.html&#34;&gt;State of The Art Cardinality Estimation Algorithm&lt;/a&gt; called
&lt;a href=&#34;http://metamarkets.com/2012/fast-cheap-and-98-right-cardinality-estimation-for-big-data/&#34;&gt;HyperLogLog&lt;/a&gt;. This
technique is now available for PostgreSQL in the extension
&lt;a href=&#34;http://blog.aggregateknowledge.com/2013/02/04/open-source-release-postgresql-hll/&#34;&gt;postgresql-hll&lt;/a&gt;
available at
&lt;a href=&#34;https://github.com/aggregateknowledge/postgresql-hll&#34;&gt;https://github.com/aggregateknowledge/postgresql-hll&lt;/a&gt; and soon
to be in
&lt;code&gt;debian&lt;/code&gt;.&lt;/p&gt;

&lt;p&gt;&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Playing with pgloader</title>
      <link>http://tapoueh.org/blog/2013/02/playing-with-pgloader/</link>
      <pubDate>Tue, 12 Feb 2013 11:17:00 +0100</pubDate>
      
      <guid>http://tapoueh.org/blog/2013/02/playing-with-pgloader/</guid>
      <description>While making progress with both Event Triggers and Extension Templates, I needed to make a little break. My current keeping sane mental exercise seems to mainly involve using Common Lisp, a programming language that ships with about all the building blocks you need.
Yes, that old language brings so much on the table
When using Common Lisp, you have an awesome interactive development environment where you can redefine function and objects while testing them.</description>
    </item>
    
    <item>
      <title>Live Upgrading PGQ</title>
      <link>http://tapoueh.org/blog/2013/02/live-upgrading-pgq/</link>
      <pubDate>Fri, 08 Feb 2013 15:52:00 +0100</pubDate>
      
      <guid>http://tapoueh.org/blog/2013/02/live-upgrading-pgq/</guid>
      <description>Some skytools related new today, it&amp;rsquo;s been a while. For those who where at my FOSDEM&amp;rsquo;s talk about Implementing High Availability you might have heard that I really like working with PGQ. A new version has been released a while ago, and the most recent verion is now 3.1.3, as announced in the Skytools 3.1.3 email.
Upgrade time!
Skytools 3.1.3 enters debian First news is that Skytools 3.1.3 has been entering debian today (I hope that by the time you reach that URL, it&amp;rsquo;s been updated to show information according to the news here, but I might be early).</description>
    </item>
    
    <item>
      <title>Another Great FOSDEM</title>
      <link>http://tapoueh.org/blog/2013/02/another-great-fosdem/</link>
      <pubDate>Mon, 04 Feb 2013 09:55:00 +0100</pubDate>
      
      <guid>http://tapoueh.org/blog/2013/02/another-great-fosdem/</guid>
      <description>This year&amp;rsquo;s FOSDEM has been a great edition, in particular the FOSDEM PGDAY 2013 was a great way to begin a 3 days marathon of talking about PostgreSQL with people not only from our community but also from plenty other Open Source communities too: users!
  
  
PostgreSQL at FOSDEM made for a great event
Having had the opportunity to meet more people from those other development communities, I really think we should go and reach for them in their own conferences.</description>
    </item>
    
    <item>
      <title>A Sunday at FOSDEM</title>
      <link>http://tapoueh.org/blog/2013/01/a-sunday-at-fosdem/</link>
      <pubDate>Wed, 30 Jan 2013 10:50:00 +0100</pubDate>
      
      <guid>http://tapoueh.org/blog/2013/01/a-sunday-at-fosdem/</guid>
      <description>The previous article FOSDEM 2013 said to be careful with the PostgreSQL devroom schedule because one of my talks there might get swapped with a slot on the FOSDEM PGDay 2013 which happens this Friday and has been sold out anyway.
Turns out it&amp;rsquo;s not true, because we still depend on past century technologies somehow. Not everybody will be looking at the schedule on the web using a connected mobile device (you know, you&amp;rsquo;ve heard of them, those tracking and surveillance devices, if you want to believe Stallman), and as the schedule gets printed on little paper sheets, it&amp;rsquo;s unfortunately too late to change it now.</description>
    </item>
    
    <item>
      <title>FOSDEM 2013</title>
      <link>http://tapoueh.org/blog/2013/01/fosdem-2013/</link>
      <pubDate>Tue, 29 Jan 2013 10:11:00 +0100</pubDate>
      
      <guid>http://tapoueh.org/blog/2013/01/fosdem-2013/</guid>
      <description>This year again I&amp;rsquo;m going to FOSDEM, and to the extra special PostgreSQL FOSDEM day. It will be the first time that I&amp;rsquo;m going to be at the event for the full week-end rather than just commuting in for the day.
   
I&amp;rsquo;m Going to the FOSDEM, hope to see you there!
And I&amp;rsquo;m presenting two talks over there that are both currently scheduled on the Sunday in the PostgreSQL devroom.</description>
    </item>
    
    <item>
      <title>pgloader: what&#39;s next?</title>
      <link>http://tapoueh.org/blog/2013/01/pgloader-whats-next/</link>
      <pubDate>Mon, 28 Jan 2013 10:48:00 +0100</pubDate>
      
      <guid>http://tapoueh.org/blog/2013/01/pgloader-whats-next/</guid>
      <description>pgloader is a tool to help loading data into PostgreSQL, adding some error management to the COPY command. COPY is the fast way of loading data into PostgreSQL and is transaction safe. That means that if a single error appears within your bulk of data, you will have loaded none of it. pgloader will submit the data again in smaller chunks until it&amp;rsquo;s able to isolate the bad from the good, and then the good is loaded in.</description>
    </item>
    
    <item>
      <title>Automated Setup for pgloader</title>
      <link>http://tapoueh.org/blog/2013/01/automated-setup-for-pgloader/</link>
      <pubDate>Thu, 17 Jan 2013 14:32:00 +0100</pubDate>
      
      <guid>http://tapoueh.org/blog/2013/01/automated-setup-for-pgloader/</guid>
      <description>Another day, another migration from MySQL to PostgreSQL&amp;hellip; or at least that&amp;rsquo;s how it feels sometimes. This time again I&amp;rsquo;ve been using some quite old scripts to help me do the migration.
That&amp;rsquo;s how I feel for MySQL users
Migrating the schema For the schema parts, I&amp;rsquo;ve been using mysql2pgsql with success for many years. This tool is not complete and will do only about 80% of the work. As I think that the schema should always be validated manually when doing a migration anyway, I happen to think that it&amp;rsquo;s good news.</description>
    </item>
    
    <item>
      <title>Extensions Templates</title>
      <link>http://tapoueh.org/blog/2013/01/extensions-templates/</link>
      <pubDate>Tue, 08 Jan 2013 17:53:00 +0100</pubDate>
      
      <guid>http://tapoueh.org/blog/2013/01/extensions-templates/</guid>
      <description>In a recent article titled Inline Extensions we detailed the problem of how to distribute an extension&amp;rsquo;s package to a remote server without having access to its file system at all. The solution to that problem is non trivial, let&amp;rsquo;s say. But thanks to the awesome PostgreSQL Community we finaly have some practical ideas on how to address the problem as discussed on pgsql-hackers, our development mailing list.
PostgreSQL is first an Awesome Community</description>
    </item>
    
    <item>
      <title>Inline Extensions</title>
      <link>http://tapoueh.org/blog/2012/12/inline-extensions/</link>
      <pubDate>Thu, 13 Dec 2012 11:34:00 +0100</pubDate>
      
      <guid>http://tapoueh.org/blog/2012/12/inline-extensions/</guid>
      <description>We&amp;rsquo;ve been having the CREATE EXTENSION feature in PostgreSQL for a couple of releases now, so let&amp;rsquo;s talk about how to go from here. The first goal of the extension facility has been to allow for a clean dump and restore process of contrib modules. As such it&amp;rsquo;s been tailored to the needs of deploying files on the file system because there&amp;rsquo;s no escaping from that when you have to ship binary and executable files, those infamous .</description>
    </item>
    
    <item>
      <title>Editing SQL</title>
      <link>http://tapoueh.org/blog/2012/11/editing-sql/</link>
      <pubDate>Tue, 06 Nov 2012 09:55:00 +0100</pubDate>
      
      <guid>http://tapoueh.org/blog/2012/11/editing-sql/</guid>
      <description>It&amp;rsquo;s hard to read my blog yet not know I&amp;rsquo;m using Emacs. It really is a great tool and has a lot to compare to PostgreSQL in terms of extensibility, documentation quality and community. And there&amp;rsquo;s even a native implementation of the PostgreSQL Protocol written in Emacs Lisp.
   
One of the things where Emacs really shines is that interactive development environment you get when working on some Emacs Lisp code.</description>
    </item>
    
    <item>
      <title>PostgreSQL for developers</title>
      <link>http://tapoueh.org/blog/2012/11/postgresql-for-developers/</link>
      <pubDate>Fri, 02 Nov 2012 16:22:00 +0100</pubDate>
      
      <guid>http://tapoueh.org/blog/2012/11/postgresql-for-developers/</guid>
      <description>As Guillaume says, we&amp;rsquo;ve been enjoying a great evening conference in Lyon 2 days ago, presenting PostgreSQL to developers. He did the first hour presenting the project and the main things you want to know to start using PostgreSQL in production, then I took the opportunity to be talking to developers to show off some SQL.
   
That slide deck contains mainly SQL language, but some french too, rather than english.</description>
    </item>
    
    <item>
      <title>Another awesome conf</title>
      <link>http://tapoueh.org/blog/2012/10/another-awesome-conf/</link>
      <pubDate>Tue, 30 Oct 2012 12:50:00 +0100</pubDate>
      
      <guid>http://tapoueh.org/blog/2012/10/another-awesome-conf/</guid>
      <description>Last week was PostgreSQL Conference Europe 2012 in Prague, and it&amp;rsquo;s been awesome. Many thanks to the organisers who did manage to host a very smooth conference with 290 attendees, including speakers. That means you kept walking into interesting people to talk to, and in particular the Hallway Track has been a giant success.
   
Photo by Oleg Bartunov
I did have the chance to speak several times at that event, and you can get the slides at my Conferences page that I try to keep up to date.</description>
    </item>
    
    <item>
      <title>Prefixes and Ranges</title>
      <link>http://tapoueh.org/blog/2012/10/prefixes-and-ranges/</link>
      <pubDate>Tue, 16 Oct 2012 10:47:00 +0200</pubDate>
      
      <guid>http://tapoueh.org/blog/2012/10/prefixes-and-ranges/</guid>
      <description>It&amp;rsquo;s been a long time since I last had some time to spend on the prefix PostgreSQL extension and its prefix_range data type. With PostgreSQL 9.2 out, some users wanted me to update the extension for that release, and hinted me that it was high time that I fix that old bug for which I already had a patch.
prefix_range release 1.2.0 I&amp;rsquo;m sorry it took that long. It&amp;rsquo;s now done, you can have prefix 1.</description>
    </item>
    
    <item>
      <title>Reset Counter</title>
      <link>http://tapoueh.org/blog/2012/10/reset-counter/</link>
      <pubDate>Fri, 05 Oct 2012 09:44:00 +0200</pubDate>
      
      <guid>http://tapoueh.org/blog/2012/10/reset-counter/</guid>
      <description>&lt;p&gt;I&amp;rsquo;ve been given a nice puzzle that I think is a good blog article
opportunity, as it involves some thinking
and &lt;a href=&#34;http://tapoueh.org/blog/2013/08/understanding-window-functions/&#34;&gt;window functions&lt;/a&gt;.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>PostgreSQL 9.3</title>
      <link>http://tapoueh.org/blog/2012/09/postgresql-9.3/</link>
      <pubDate>Sat, 15 Sep 2012 18:43:00 +0200</pubDate>
      
      <guid>http://tapoueh.org/blog/2012/09/postgresql-9.3/</guid>
      <description>PostgreSQL 9.2 is released! It&amp;rsquo;s an awesome new release that I urge you to consider trying and adopting, an upgrade from even 9.1 should be very well worth it, as your hardware could suddenly be able to process a much higher load. Indeed, better performances mean more work done on the same budget, that&amp;rsquo;s the name of the game!
As a PostgreSQL contributor though, the release of 9.2 mainly means to me that it&amp;rsquo;s time to fully concentrate on preparing 9.</description>
    </item>
    
    <item>
      <title>Autumn 2012 Conferences</title>
      <link>http://tapoueh.org/blog/2012/08/autumn-2012-conferences/</link>
      <pubDate>Thu, 02 Aug 2012 01:08:00 +0200</pubDate>
      
      <guid>http://tapoueh.org/blog/2012/08/autumn-2012-conferences/</guid>
      <description>The PostgreSQL community host a number of conferences all over the year, and the next ones I&amp;rsquo;m lucky enough to get to are approaching fast now. First, next month in September, we have Postgres Open in Chicago, where my talk about Large Scale Migration from MySQL to PostgreSQL has been selected!
This talk shares hindsights about the why and the how of that migration, what problems couldn&amp;rsquo;t be solved without moving away and how the solution now looks.</description>
    </item>
    
    <item>
      <title>PGDay France 2012</title>
      <link>http://tapoueh.org/blog/2012/06/pgday-france-2012/</link>
      <pubDate>Fri, 08 Jun 2012 16:17:00 +0200</pubDate>
      
      <guid>http://tapoueh.org/blog/2012/06/pgday-france-2012/</guid>
      <description>The french PostgreSQL Conference, pgday.fr, was yesterday in Lyon. We had a very good time and a great schedule with a single track packed with 7 talks, addressing a diverse set of PostgreSQL related topics, from GIS to fuzzy logic, including replication.
You might have guessed it already, I did talk about replication. Here&amp;rsquo;s the slide deck I did use, it&amp;rsquo;s in french, sorry if you don&amp;rsquo;t grok that language.</description>
    </item>
    
    <item>
      <title>Back From PgCon</title>
      <link>http://tapoueh.org/blog/2012/05/back-from-pgcon/</link>
      <pubDate>Thu, 24 May 2012 09:40:00 +0200</pubDate>
      
      <guid>http://tapoueh.org/blog/2012/05/back-from-pgcon/</guid>
      <description>Last week was the annual PostgreSQL Hackers gathering in Canada, thanks to the awesome pgcon conference. This year&amp;rsquo;s issue has been packed with good things, beginning with the Cluster Summit then followed the next day by the Developer Meeting just followed (yes, in the same day) with the In Core Replication Meeting. That was a packed shedule!
The in core replication project has been presented with slides titled Future In-Core Replication for PostgreSQL and got a very good reception.</description>
    </item>
    
    <item>
      <title>Clean PGQ Subconsumers</title>
      <link>http://tapoueh.org/blog/2012/04/clean-pgq-subconsumers/</link>
      <pubDate>Thu, 26 Apr 2012 15:05:00 +0200</pubDate>
      
      <guid>http://tapoueh.org/blog/2012/04/clean-pgq-subconsumers/</guid>
      <description>Now that you&amp;rsquo;re all using the wonders of Cooperative Consumers to help you efficiently and reliably implement your business constraints and offload them from the main user transactions, you&amp;rsquo;re reaching a point where you have to clean up your development environment (because that&amp;rsquo;s what happens to development environments, right?), and you want a way to start again from a clean empty place.
Here we go. It used to be much more simple than that, so if you&amp;rsquo;re still using PGQ from Skytools2, just jump to the next step.</description>
    </item>
    
    <item>
      <title>PGQ Coop Consumers</title>
      <link>http://tapoueh.org/blog/2012/03/pgq-coop-consumers/</link>
      <pubDate>Mon, 12 Mar 2012 14:43:00 +0100</pubDate>
      
      <guid>http://tapoueh.org/blog/2012/03/pgq-coop-consumers/</guid>
      <description>While working a new PostgreSQL architecture for an high scale project that used to be in the top 10 of internet popular web sites (in terms of visitors), I needed to be able to off load some processing from the main path: that&amp;rsquo;s called a batch job. This needs to be transactional: don&amp;rsquo;t run the job if we did rollback; the transaction, process all events that were part of the same transaction in the same transaction, etc.</description>
    </item>
    
    <item>
      <title>Extension White Listing</title>
      <link>http://tapoueh.org/blog/2012/03/extension-white-listing/</link>
      <pubDate>Thu, 08 Mar 2012 14:25:00 +0100</pubDate>
      
      <guid>http://tapoueh.org/blog/2012/03/extension-white-listing/</guid>
      <description>PostgreSQL 9.1 includes proper extension support, as you might well know if you ever read this very blog here. Some hosting facilities are playing with PostgreSQL at big scale (hello Heroku!) and still meet with small caveats making their life uneasy.
To be specific, only superusers are allowed to install C coded stored procedures, and that impacts a lot of very useful PostgreSQL extension: all those shiped in the contrib package are coded in C.</description>
    </item>
    
    <item>
      <title>pgbouncer munin plugin</title>
      <link>http://tapoueh.org/blog/2011/11/pgbouncer-munin-plugin/</link>
      <pubDate>Wed, 16 Nov 2011 14:00:00 +0100</pubDate>
      
      <guid>http://tapoueh.org/blog/2011/11/pgbouncer-munin-plugin/</guid>
      <description>It seems that if you search for a munin plugin for pgbouncer it&amp;rsquo;s easy enough to reach an old page of mine with an old version of my plugin, and a broken link. Let&amp;rsquo;s remedy that by publishing here the newer version of the plugin. To be honest, I though it already made its way into the official munin 1.4 set of plugins, but I&amp;rsquo;ve not been following closely enough.</description>
    </item>
    
    <item>
      <title>Back From Amsterdam</title>
      <link>http://tapoueh.org/blog/2011/10/back-from-amsterdam/</link>
      <pubDate>Wed, 26 Oct 2011 10:08:00 +0200</pubDate>
      
      <guid>http://tapoueh.org/blog/2011/10/back-from-amsterdam/</guid>
      <description>Another great conference took place last week, PostgreSQL Conference Europe 2011 was in Amsterdam and plenty of us PostgreSQL geeks were too. I attended to lot of talks and did learn some more about our project, its community and its features, but more than that it was a perfect occasion to meet with the community.
Dave Page talked about SQL/MED under the title PostgreSQL at the center of your dataverse and detailed what to expert from a Foreign Data Wrapper in PostgreSQL 9.</description>
    </item>
    
    <item>
      <title>Implementing backups</title>
      <link>http://tapoueh.org/blog/2011/10/implementing-backups/</link>
      <pubDate>Wed, 12 Oct 2011 22:22:00 +0200</pubDate>
      
      <guid>http://tapoueh.org/blog/2011/10/implementing-backups/</guid>
      <description>I&amp;rsquo;ve been asked about my opinion on backup strategy and best practices, and it so happens that I have some kind of an opinion on the matter.
I tend to think best practice here begins with defining properly the backup plan you want to implement. It&amp;rsquo;s quite a complex matter, so be sure to ask yourself about your needs: what do you want to be protected from?
The two main things to want to protect from are hardware loss (crash disaster, plane in the data center, fire, water flood, etc) and human error ( UPDATE without a where clause).</description>
    </item>
    
    <item>
      <title>Scaling Stored Procedures</title>
      <link>http://tapoueh.org/blog/2011/10/scaling-stored-procedures/</link>
      <pubDate>Thu, 06 Oct 2011 18:23:00 +0200</pubDate>
      
      <guid>http://tapoueh.org/blog/2011/10/scaling-stored-procedures/</guid>
      <description>In the news recently stored procedures where used as an excuse for moving away logic from the database layer to application layer, and to migrate away from a powerful technology to a simpler one, now that there&amp;rsquo;s no logic anymore in the database.
It&amp;rsquo;s not the way I would typically approach scaling problems, and apparently I&amp;rsquo;m not alone on the Stored Procedures camp. Did you read this nice blog post Mythbusters: Stored Procedures Edition already?</description>
    </item>
    
    <item>
      <title>See you in Amsterdam</title>
      <link>http://tapoueh.org/blog/2011/10/see-you-in-amsterdam/</link>
      <pubDate>Tue, 04 Oct 2011 14:25:00 +0200</pubDate>
      
      <guid>http://tapoueh.org/blog/2011/10/see-you-in-amsterdam/</guid>
      <description>The next PostgreSQL conference is approaching very fast now, I hope you have your ticket already: it&amp;rsquo;s a very promissing event! If you want some help in deciding whether to register or not, just have another look at the schedule. Pick the talks you want to see. It&amp;rsquo;s hard, given how packed with good ones the schedule is. When you&amp;rsquo;re mind is all set, review the list. Registered?
I&amp;rsquo;ll be presenting another talk about extensions, but this time I&amp;rsquo;ve geared up to use cases, with Extensions are good for business logic.</description>
    </item>
    
    <item>
      <title>Skytools3: walmgr</title>
      <link>http://tapoueh.org/blog/2011/09/skytools3-walmgr/</link>
      <pubDate>Wed, 21 Sep 2011 17:21:00 +0200</pubDate>
      
      <guid>http://tapoueh.org/blog/2011/09/skytools3-walmgr/</guid>
      <description>Let&amp;rsquo;s begin the Skytools 3 documentation effort, which is long overdue. The code is waiting for you over at github, and is stable and working. Why is it still in release candidate status, I hear you asking? Well because it&amp;rsquo;s missing updated documentation.
WalMgr is the Skytools component that manages WAL shipping for you, and archiving too. It knows how to prepare your master and standby setup, how to take a base backup and push it to the standby&amp;rsquo;s system, how to archive (at the satndby) master&amp;rsquo;s WAL files as they are produced and have the standby restore from this archive.</description>
    </item>
    
    <item>
      <title>PostgreSQL and debian</title>
      <link>http://tapoueh.org/blog/2011/09/postgresql-and-debian/</link>
      <pubDate>Mon, 05 Sep 2011 17:14:00 +0200</pubDate>
      
      <guid>http://tapoueh.org/blog/2011/09/postgresql-and-debian/</guid>
      <description>After talking about it for a very long time, work finally did begin! I&amp;rsquo;m talking about the apt.postgresql.org build system that will allow us, in the long run, to propose debian versions of binary packages for PostgreSQL and its extensions, compiled for a bunch of debian and ubuntu versions.
We&amp;rsquo;re now thinking to support the i386 and amd64 architectures for lenny, squeeze, wheezy and sid, and also for maverick and natty, maybe oneiric too while at it.</description>
    </item>
    
    <item>
      <title>pg_restore -L &amp; pg_staging</title>
      <link>http://tapoueh.org/blog/2011/08/pg_restore--l--pg_staging/</link>
      <pubDate>Mon, 29 Aug 2011 18:05:00 +0200</pubDate>
      
      <guid>http://tapoueh.org/blog/2011/08/pg_restore--l--pg_staging/</guid>
      <description>On the PostgreSQL Hackers mailing lists, Andrew Dunstan just proposed some new options for pg_dump and pg_restore to ease our lives. One of the answers was talking about some scripts available to exploit the pg_restore listing that you play with using options -l and -L, or the long name versions --list and --use-list. The pg_staging tool allows you to easily exploit those lists too.
The pg_restore list is just a listing of one object per line of all objects contained into a custom dump, that is one made with pg_dump -Fc.</description>
    </item>
    
    <item>
      <title>Skytools, version 3</title>
      <link>http://tapoueh.org/blog/2011/08/skytools-version-3/</link>
      <pubDate>Fri, 26 Aug 2011 21:30:00 +0200</pubDate>
      
      <guid>http://tapoueh.org/blog/2011/08/skytools-version-3/</guid>
      <description>You can find skytools3 in debian experimental already, it&amp;rsquo;s in release candidate status. What&amp;rsquo;s missing is the documentation, so here&amp;rsquo;s an idea: I&amp;rsquo;m going to make a blog post series about skytools next features, how to use them, what they are good for, etc. This first article of the series will just list what are those new features.
Here are the slides from the CHAR(11) talk I made last month, about that very subject:</description>
    </item>
    
    <item>
      <title>pgfincore in debian</title>
      <link>http://tapoueh.org/blog/2011/08/pgfincore-in-debian/</link>
      <pubDate>Fri, 19 Aug 2011 23:00:00 +0200</pubDate>
      
      <guid>http://tapoueh.org/blog/2011/08/pgfincore-in-debian/</guid>
      <description>As of pretty recently, pgfincore is now in debian, as you can see on its postgresql-9.0-pgfincore page. The reason why it entered the debian archives is that it reached the 1.0 release!
Rather than talking about what pgfincore is all about ( A set of functions to manage pages in memory from PostgreSQL), I will talk about its packaging and support as a debian package. Here&amp;rsquo;s the first example of a modern multi-version packaging I have to offer.</description>
    </item>
    
    <item>
      <title>pgloader tutorial</title>
      <link>http://tapoueh.org/blog/2011/08/pgloader-tutorial/</link>
      <pubDate>Mon, 15 Aug 2011 15:33:00 +0200</pubDate>
      
      <guid>http://tapoueh.org/blog/2011/08/pgloader-tutorial/</guid>
      <description>To finish up the pgloader series, I&amp;rsquo;ve compiled all the information into a single page, the long awaited pgloader tutorial. That should help lots of users to get started with pgloader.</description>
    </item>
    
    <item>
      <title>pgloader constant cols</title>
      <link>http://tapoueh.org/blog/2011/08/pgloader-constant-cols/</link>
      <pubDate>Fri, 12 Aug 2011 11:00:00 +0200</pubDate>
      
      <guid>http://tapoueh.org/blog/2011/08/pgloader-constant-cols/</guid>
      <description>The previous articles in the pgloader series detailed How To Use PgLoader then How to Setup pgloader, then what to expect from a parallel pgloader setup, and then pgloader reformating. Another need you might encounter when you get to use pgloader is adding constant values into a table&amp;rsquo;s column.
The basic situation where you need to do so is adding an origin field to your table. The value of that is not to be found in the data file itself, typically, but known in the pgloader setup.</description>
    </item>
    
    <item>
      <title>pgloader reformating</title>
      <link>http://tapoueh.org/blog/2011/08/pgloader-reformating/</link>
      <pubDate>Fri, 05 Aug 2011 11:30:00 +0200</pubDate>
      
      <guid>http://tapoueh.org/blog/2011/08/pgloader-reformating/</guid>
      <description>Back to our series about pgloader. The previous articles detailed How To Use PgLoader then How to Setup pgloader, then what to expect from a parallel pgloader setup. This article will detail how to reformat input columns so that what PostgreSQL sees is not what&amp;rsquo;s in the data file, but the result of a transformation from this data into something acceptable as an input for the target data type.
Here&amp;rsquo;s what the pgloader documentation has to say about this reformat parameter: The value of this option is a comma separated list of columns to rewrite, which are a colon separated list of column name, reformat module name, reformat function name.</description>
    </item>
    
    <item>
      <title>See Tsung in action</title>
      <link>http://tapoueh.org/blog/2011/08/see-tsung-in-action/</link>
      <pubDate>Tue, 02 Aug 2011 10:30:00 +0200</pubDate>
      
      <guid>http://tapoueh.org/blog/2011/08/see-tsung-in-action/</guid>
      <description>Tsung is an open-source multi-protocol distributed load testing tool and a mature project. It&amp;rsquo;s been available for about 10 years and is built with the Erlang system. It supports several protocols, including the PostgreSQL one.
When you want to benchmark your own application, to know how many more clients it can handle or how much gain you will see with some new shiny hardware, Tsung is the tool to use. It will allow you to record a number of sessions then replay them at high scale.</description>
    </item>
    
    <item>
      <title>Parallel pgloader</title>
      <link>http://tapoueh.org/blog/2011/08/parallel-pgloader/</link>
      <pubDate>Mon, 01 Aug 2011 12:15:00 +0200</pubDate>
      
      <guid>http://tapoueh.org/blog/2011/08/parallel-pgloader/</guid>
      <description>This article continues the series that began with How To Use PgLoader then detailed How to Setup pgloader. We have some more fine points to talk about here, today&amp;rsquo;s article is about loading your data in parallel with pgloader.
several files at a time Parallelism is implemented in 3 different ways in pgloader. First, you can load more than one file at a time thanks to the max_parallel_sections parameter, that has to be setup in the global section of the file.</description>
    </item>
    
    <item>
      <title>How to Setup pgloader</title>
      <link>http://tapoueh.org/blog/2011/07/how-to-setup-pgloader/</link>
      <pubDate>Fri, 29 Jul 2011 15:00:00 +0200</pubDate>
      
      <guid>http://tapoueh.org/blog/2011/07/how-to-setup-pgloader/</guid>
      <description>In a previous article we detailed how to use pgloader, let&amp;rsquo;s now see how to write the pgloader.conf that instructs pgloader about what to do.
This file is expected in the INI format, with a global section then one section per file you want to import. The global section defines some default options and how to connect to the PostgreSQL server.
The configuration setup is fully documented on the pgloader man page that you can even easily find online.</description>
    </item>
    
    <item>
      <title>Next month partitions</title>
      <link>http://tapoueh.org/blog/2011/07/next-month-partitions/</link>
      <pubDate>Wed, 27 Jul 2011 22:35:00 +0200</pubDate>
      
      <guid>http://tapoueh.org/blog/2011/07/next-month-partitions/</guid>
      <description>When you do partition your tables monthly, then comes the question of when to create next partitions. I tend to create them just the week before next month and I have some nice nagios scripts to alert me in case I&amp;rsquo;ve forgotten to do so. How to check that by hand in the end of a month?
Here&amp;rsquo;s a catalog query to help you there:
=&amp;gt; select * -&amp;gt; from -&amp;gt; ( (&amp;gt; select &#39;previous parts&#39; as schemaname, count(*)::text as tablename (&amp;gt; from pg_tables (&amp;gt; where schemaname not in (&#39;pg_catalog&#39;,&#39;information_schema&#39;) (&amp;gt; and tablename like to_char(now(), &#39;%YYYYMM&#39;) (&amp;gt; (&amp;gt; union (&amp;gt; (&amp;gt; select schemaname, substring(tablename,1,length(tablename)-6) || &#39;201108&#39; (&amp;gt; from pg_tables (&amp;gt; where schemaname not in (&#39;pg_catalog&#39;,&#39;information_schema&#39;) (&amp;gt; and tablename like to_char(now(), &#39;%YYYYMM&#39;) (&amp;gt; (&amp;gt; except (&amp;gt; (&amp;gt; select schemaname, tablename (&amp;gt; from pg_tables (&amp;gt; where schemaname not in (&#39;pg_catalog&#39;,&#39;information_schema&#39;) (&amp;gt; and tablename like to_char(now() + interval &#39;1 month&#39;, &#39;%YYYYMM&#39;) (&amp;gt; ) as t -&amp;gt; order by schemaname &amp;lt;&amp;gt; &#39;previous parts&#39;, schemaname; schemaname | tablename ----------------+------------------------ previous parts | 1 central | stats_entrantes_201108 (2 rows)  As you see, our partitions are named _YYYYMM so that&amp;rsquo;s it&amp;rsquo;s easy to match them in our queries, but I guess about everyone does about the same here.</description>
    </item>
    
    <item>
      <title>How To Use PgLoader</title>
      <link>http://tapoueh.org/blog/2011/07/how-to-use-pgloader/</link>
      <pubDate>Fri, 22 Jul 2011 13:38:00 +0200</pubDate>
      
      <guid>http://tapoueh.org/blog/2011/07/how-to-use-pgloader/</guid>
      <description>This question about pgloader usage coms in quite frequently, and I think the examples README goes a long way in answering it. It&amp;rsquo;s not exactly a tutorial but is almost there. Let me paste it here for reference:
installing pgloader Either use the debian package or the one for your distribution of choice if you use another one. RedHat, CentOS, FreeBSD, OpenBSD and some more already include a binary package that you can use directly.</description>
    </item>
    
    <item>
      <title>Skytools3 talk Slides</title>
      <link>http://tapoueh.org/blog/2011/07/skytools3-talk-slides/</link>
      <pubDate>Tue, 19 Jul 2011 14:24:00 +0200</pubDate>
      
      <guid>http://tapoueh.org/blog/2011/07/skytools3-talk-slides/</guid>
      <description>In case you&amp;rsquo;re wondering, here are the slides from the CHAR(11) talk I gave, about Skytools 3.0, soon to be released. That means as soon as I have enough time available to polish (or write) the documentation.
  The slides for all the talks should eventually make their way to a central place, but expect some noticable delay here. Sorry about that, and have a good reading meanwhile!</description>
    </item>
    
    <item>
      <title>Back From CHAR(11)</title>
      <link>http://tapoueh.org/blog/2011/07/back-from-char11/</link>
      <pubDate>Wed, 13 Jul 2011 17:15:00 +0200</pubDate>
      
      <guid>http://tapoueh.org/blog/2011/07/back-from-char11/</guid>
      <description>CHAR(11) finished somewhen in the night leading to today, if you consider the social events to be part of it, which I definitely do. This conference has been a very good one, both on the organisation side of things and of course for its content.
It began with a perspective about the evolution of replication solutions, by Jan Wieck himself. In some way Skytools is an evolution of Slony, in the sense that it reuses the same concepts, a part of the design, and even share bits of the implementation (like the txid_snapshot datatype that were added in PostgreSQL 8.</description>
    </item>
    
    <item>
      <title>Multi-Version support for Extensions</title>
      <link>http://tapoueh.org/blog/2011/06/multi-version-support-for-extensions/</link>
      <pubDate>Wed, 29 Jun 2011 09:50:00 +0200</pubDate>
      
      <guid>http://tapoueh.org/blog/2011/06/multi-version-support-for-extensions/</guid>
      <description>We still have this problem to solve with extensions and their packaging. How to best organize things so that your extension is compatible with before 9.1 and 9.1 and following releases of PostgreSQL?
Well, I had to do it for the ip4r contribution, and I wanted the following to happen:
dpkg-deb: building package `postgresql-8.3-ip4r&#39; ... dpkg-deb: building package `postgresql-8.4-ip4r&#39; ... dpkg-deb: building package `postgresql-9.0-ip4r&#39; ... dpkg-deb: building package `postgresql-9.1-ip4r&#39; ...  And here&amp;rsquo;s a simple enough way to achieve that.</description>
    </item>
    
    <item>
      <title>Back from Ottawa, preparing for Cambridge</title>
      <link>http://tapoueh.org/blog/2011/05/back-from-ottawa-preparing-for-cambridge/</link>
      <pubDate>Mon, 30 May 2011 11:00:00 +0200</pubDate>
      
      <guid>http://tapoueh.org/blog/2011/05/back-from-ottawa-preparing-for-cambridge/</guid>
      <description>While Magnus is all about PG Conf EU already, you have to realize we&amp;rsquo;re just landed back from PG Con in Ottawa. My next stop in the annual conferences is CHAR 11, the Clustering, High Availability and Replication conference in Cambridge, 11-12 July. Yes, on the old continent this time.
This year&amp;rsquo;s pgcon hot topics, for me, have been centered around a better grasp at SSI and DDL Triggers. Having those beasts in PostgreSQL would allow for auditing, finer privileges management and some more automated replication facilities.</description>
    </item>
    
    <item>
      <title>Preparing for PGCON</title>
      <link>http://tapoueh.org/blog/2011/05/preparing-for-pgcon/</link>
      <pubDate>Thu, 12 May 2011 10:30:00 +0200</pubDate>
      
      <guid>http://tapoueh.org/blog/2011/05/preparing-for-pgcon/</guid>
      <description>It&amp;rsquo;s this time of the year again, the main international PostgreSQL Conference is next week in Ottawa, Canada. If previous years are any indication, this will be great event where to meet with a lot of the members of your community. The core team will be there, developers will be there, and we will meet with users and their challenging use cases.
This is a very good time to review both what you did in the project those last 12 months, and what you plan to do next year.</description>
    </item>
    
    <item>
      <title>Tables and Views dependencies</title>
      <link>http://tapoueh.org/blog/2011/05/tables-and-views-dependencies/</link>
      <pubDate>Wed, 04 May 2011 11:45:00 +0200</pubDate>
      
      <guid>http://tapoueh.org/blog/2011/05/tables-and-views-dependencies/</guid>
      <description>Let&amp;rsquo;s say you need to ALTER TABLE foo ALTER COLUMN bar TYPE bigint;, and PostgreSQL is helpfully telling you that no you can&amp;rsquo;t because such and such views depend on the column. The basic way to deal with that is to copy paste from the error message the names of the views involved, then prepare a script wherein you first DROP VIEW ...; then ALTER TABLE and finally CREATE VIEW again, all in the same transaction.</description>
    </item>
    
    <item>
      <title>Extension module_pathname and .sql.in</title>
      <link>http://tapoueh.org/blog/2011/05/extension-module_pathname-and-.sql.in/</link>
      <pubDate>Mon, 02 May 2011 17:30:00 +0200</pubDate>
      
      <guid>http://tapoueh.org/blog/2011/05/extension-module_pathname-and-.sql.in/</guid>
      <description>While currently too busy at work to deliver much Open Source contributions, let&amp;rsquo;s debunk an old habit of PostgreSQL extension authors. It&amp;rsquo;s all down to copy pasting from contrib, and there&amp;rsquo;s no reason to continue doing $libdir this way ever since 7.4 days.
Let&amp;rsquo;s take an example here, with the prefix extension. This one too will need some love, but is still behind on my spare time todo list, sorry about that.</description>
    </item>
    
    <item>
      <title>Some notes about Skytools3</title>
      <link>http://tapoueh.org/blog/2011/04/some-notes-about-skytools3/</link>
      <pubDate>Mon, 11 Apr 2011 11:30:00 +0200</pubDate>
      
      <guid>http://tapoueh.org/blog/2011/04/some-notes-about-skytools3/</guid>
      <description>I&amp;rsquo;ve been working on skytools3 packaging lately. I&amp;rsquo;ve been pushing quite a lot of work into it, in order to have exactly what I needed out of the box, after some 3 years of production and experiences with the products. Plural, yes, because even if pgbouncer and plproxy are siblings to the projets (same developers team, separate life cycle and releases), then skytools still includes several sub-projects.
Here&amp;rsquo;s what the skytools3 packaging is going to look like:</description>
    </item>
    
    <item>
      <title>towards pg_staging 1.0</title>
      <link>http://tapoueh.org/blog/2011/03/towards-pg_staging-1.0/</link>
      <pubDate>Tue, 29 Mar 2011 15:30:00 +0200</pubDate>
      
      <guid>http://tapoueh.org/blog/2011/03/towards-pg_staging-1.0/</guid>
      <description>If you don&amp;rsquo;t remember about what pg_staging is all about, it&amp;rsquo;s a central console from where to control all your PostgreSQL databases. Typically you use it to manage your development and pre-production setup, where developers ask you pretty often to install them some newer dump from the production, and you want that operation streamlined and easy.
Usage The typical session would be something like this:
pg_staging&amp;gt; databases foodb.dev foodb foodb_20100824 :5432 foodb_20100209 foodb_20100209 :5432 foodb_20100824 foodb_20100824 :5432 pgbouncer pgbouncer :6432 postgres postgres :5432 pg_staging&amp;gt; dbsizes foodb.</description>
    </item>
    
    <item>
      <title>Extensions in 9.1</title>
      <link>http://tapoueh.org/blog/2011/03/extensions-in-9.1/</link>
      <pubDate>Tue, 01 Mar 2011 16:30:00 +0100</pubDate>
      
      <guid>http://tapoueh.org/blog/2011/03/extensions-in-9.1/</guid>
      <description>If you&amp;rsquo;ve not been following closely you might have missed out on extensions integration. Well, Tom spent some time on the patches I&amp;rsquo;ve been preparing for the last 4 months. And not only did he commit most of the work but he also enhanced some parts of the code (better factoring) and basically finished it.
At the previous developer meeting his advice was to avoid putting too much into the very first version of the patch for it to stand its chances of being integrated, and while in the review process more than one major PostgreSQL contributor expressed worries about the size of the patch and the number of features proposed.</description>
    </item>
    
    <item>
      <title>Back from FOSDEM</title>
      <link>http://tapoueh.org/blog/2011/02/back-from-fosdem/</link>
      <pubDate>Mon, 07 Feb 2011 11:10:00 +0100</pubDate>
      
      <guid>http://tapoueh.org/blog/2011/02/back-from-fosdem/</guid>
      <description>This year we were in the main building of the conference, and apparently the booth went very well, solding lots of PostgreSQL merchandise etc. I had the pleasure to once again meet with the community, but being there only 1 day I didn&amp;rsquo;t spend as much time as I would have liked with some of the people there.
In case you&amp;rsquo;re wondering, my extension&amp;rsquo;s talk went quite well, and several people were kind enough to tell me they appreciated it!</description>
    </item>
    
    <item>
      <title>Going to FOSDEM</title>
      <link>http://tapoueh.org/blog/2011/02/going-to-fosdem/</link>
      <pubDate>Tue, 01 Feb 2011 13:35:00 +0100</pubDate>
      
      <guid>http://tapoueh.org/blog/2011/02/going-to-fosdem/</guid>
      <description>A quick blog entry to say that yes:
And I will even do my Extension&amp;rsquo;s talk which had a success at pgday.eu. The talk will be updated to include the last developments of the extension&amp;rsquo;s feature, as some of it changed already in between, and to detail the plan for the ALTER EXTENSION ... UPGRADE feature that I&amp;rsquo;d like to see included as soon as 9.1, but time is running so fast.</description>
    </item>
    
    <item>
      <title>pg_basebackup</title>
      <link>http://tapoueh.org/blog/2010/11/pg_basebackup/</link>
      <pubDate>Sun, 07 Nov 2010 13:45:00 +0100</pubDate>
      
      <guid>http://tapoueh.org/blog/2010/11/pg_basebackup/</guid>
      <description>Hannu just gave me a good idea in this email on -hackers, proposing that pg_basebackup should get the xlog files again and again in a loop for the whole duration of the base backup. That&amp;rsquo;s now done in the aforementioned tool, whose options got a little more useful now:
Usage: pg_basebackup.py [-v] [-f] [-j jobs] &amp;quot;dsn&amp;quot; dest Options: -h, --help show this help message and exit --version show version and quit -x, --pg_xlog backup the pg_xlog files -v, --verbose be verbose and about processing progress -d, --debug show debug information, including SQL queries -f, --force remove destination directory if it exists -j JOBS, --jobs=JOBS how many helper jobs to launch -D DELAY, --delay=DELAY pg_xlog subprocess loop delay, see -x -S, --slave auxilliary process --stdin get list of files to backup from stdin  Yeah, as implementing the xlog idea required having some kind of parallelism, I built on it and the script now has a --jobs option for you to setup how many processes to launch in parallel, all fetching some base backup files in its own standard ( libpq) PostgreSQL connection, in compressed chunks of 8 MB (so that&amp;rsquo;s not 8 MB chunks sent over).</description>
    </item>
    
    <item>
      <title>Introducing Extensions</title>
      <link>http://tapoueh.org/blog/2010/10/introducing-extensions/</link>
      <pubDate>Thu, 21 Oct 2010 13:45:00 +0200</pubDate>
      
      <guid>http://tapoueh.org/blog/2010/10/introducing-extensions/</guid>
      <description>After reading Simon&amp;rsquo;s blog post, I can&amp;rsquo;t help but try to give some details about what it is exactly that I&amp;rsquo;m working on. As he said, there are several aspects to extensions in PostgreSQL, it all begins here: Chapter 35. Extending SQL.
It&amp;rsquo;s possible, and mostly simple enough, to add your own code or behavior to PostgreSQL, so that it will use your code and your semantics while solving user queries.</description>
    </item>
    
    <item>
      <title>Extensions: writing a patch for PostgreSQL</title>
      <link>http://tapoueh.org/blog/2010/10/extensions-writing-a-patch-for-postgresql/</link>
      <pubDate>Fri, 15 Oct 2010 11:30:00 +0200</pubDate>
      
      <guid>http://tapoueh.org/blog/2010/10/extensions-writing-a-patch-for-postgresql/</guid>
      <description>These days, thanks to my community oriented job, I&amp;rsquo;m working full time on a PostgreSQL patch to terminate basic support for extending SQL. First thing I want to share is that patching the backend code is not as hard as one would think. Second one is that git really is helping.
“Not as hard as one would think, are you kidding me?”, I hear some say. Well, that&amp;rsquo;s true. It&amp;rsquo;s C code in there, but with a very good layer of abstractions so that you&amp;rsquo;re not dealing with subtle problems that much.</description>
    </item>
    
    <item>
      <title>Date puzzle for starters</title>
      <link>http://tapoueh.org/blog/2010/10/date-puzzle-for-starters/</link>
      <pubDate>Fri, 08 Oct 2010 10:00:00 +0200</pubDate>
      
      <guid>http://tapoueh.org/blog/2010/10/date-puzzle-for-starters/</guid>
      <description>The PostgreSQL IRC channel is a good place to be, for all the very good help you can get there, because people are always wanting to remain helpful, because of the off-topics discussions sometime, or to get to talk with community core members. And to start up your day too.
This morning&amp;rsquo;s question started simple : “how can I check if today is the &amp;ldquo;first sunday fo the month&amp;rdquo;. or &amp;ldquo;the second tuesday of the month&amp;rdquo; etc?</description>
    </item>
    
    <item>
      <title>Resuming work on Extensions, first little step</title>
      <link>http://tapoueh.org/blog/2010/10/resuming-work-on-extensions-first-little-step/</link>
      <pubDate>Thu, 07 Oct 2010 17:15:00 +0200</pubDate>
      
      <guid>http://tapoueh.org/blog/2010/10/resuming-work-on-extensions-first-little-step/</guid>
      <description>Yeah I&amp;rsquo;m back on working on my part of the extension thing in PostgreSQL.
First step is a little one, but as it has public consequences, I figured I&amp;rsquo;d talk about it already. I&amp;rsquo;ve just refreshed my git repository to follow the new master one, and you can see that here http://git.postgresql.org/gitweb?p=postgresql-extension.git;a=commitdiff;h=9a88e9de246218e93c04b6b97e1ef61d97925430.
It&amp;rsquo;s been easier than I feared, mainly:
$ git --no-pager diff master..extension $ git --no-pager format-patch master..extension $ cp 0001-First-stab-at-writing-pg_execute_from_file-function.</description>
    </item>
    
    <item>
      <title>Regexp performances and Finite Automata</title>
      <link>http://tapoueh.org/blog/2010/09/regexp-performances-and-finite-automata/</link>
      <pubDate>Sun, 26 Sep 2010 21:00:00 +0200</pubDate>
      
      <guid>http://tapoueh.org/blog/2010/09/regexp-performances-and-finite-automata/</guid>
      <description>The major reason why I dislike perl so much, and ruby too, and the thing I&amp;rsquo;d want different in the Emacs Lisp API so far is how they set developers mind into using regexp. You know the quote, don&amp;rsquo;t you?
 Some people, when confronted with a problem, think “I know, I&amp;rsquo;ll use regular expressions.” Now they have two problems.
 That said, some situations require the use of regexp — or are so much simpler to solve using them than the maintenance hell you&amp;rsquo;re building here ain&amp;rsquo;t that big a drag.</description>
    </item>
    
    <item>
      <title>Window Functions example remix</title>
      <link>http://tapoueh.org/blog/2010/09/window-functions-example-remix/</link>
      <pubDate>Sun, 12 Sep 2010 21:35:00 +0200</pubDate>
      
      <guid>http://tapoueh.org/blog/2010/09/window-functions-example-remix/</guid>
      <description>The drawback of hosting a static only website is, obviously, the lack of comments. What happens actually, though, is that I receive very few comments by direct mail. As I don&amp;rsquo;t get another spam source to cleanup, I&amp;rsquo;m left unconvinced that&amp;rsquo;s such a drawback. I still miss the low probability of seeing blog readers exchange directly, but I think a tapoueh.org mailing list would be my answer, here&amp;hellip;
Anyway, David Fetter took the time to send me a comment by mail with a cleaned up rewrite of the previous entry SQL, here&amp;rsquo;s it for your pleasure!</description>
    </item>
    
    <item>
      <title>Window Functions example</title>
      <link>http://tapoueh.org/blog/2010/09/window-functions-example/</link>
      <pubDate>Thu, 09 Sep 2010 16:35:00 +0200</pubDate>
      
      <guid>http://tapoueh.org/blog/2010/09/window-functions-example/</guid>
      <description>So, when 8.4 came out there was all those comments about how getting window functions was an awesome addition. Now, it seems that a lot of people seeking for help in #postgresql just don&amp;rsquo;t know what kind of problem this feature helps solving. I&amp;rsquo;ve already been using them in some cases here in this blog, for getting some nice overview about Partitioning: relation size per “group”.
That&amp;rsquo;s another way to count change</description>
    </item>
    
    <item>
      <title>Synchronous Replication</title>
      <link>http://tapoueh.org/blog/2010/09/synchronous-replication/</link>
      <pubDate>Mon, 06 Sep 2010 18:05:00 +0200</pubDate>
      
      <guid>http://tapoueh.org/blog/2010/09/synchronous-replication/</guid>
      <description>Although the new asynchronous replication facility that ships with 9.0 ain&amp;rsquo;t released to the wide public yet, our hackers hero are already working on the synchronous version of it. A part of the facility is rather easy to design, we want something comparable to DRBD flexibility, but specific to our database world. So synchronous would either mean recv, fsync or apply, depending on what you need the standby to have already done when the master acknowledges the COMMIT.</description>
    </item>
    
    <item>
      <title>Happy Numbers</title>
      <link>http://tapoueh.org/blog/2010/08/happy-numbers/</link>
      <pubDate>Mon, 30 Aug 2010 11:00:00 +0200</pubDate>
      
      <guid>http://tapoueh.org/blog/2010/08/happy-numbers/</guid>
      <description>After discovering the excellent Gwene service, which allows you to subscribe to newsgroups to read RSS content ( blogs, planets, commits, etc), I came to read this nice article about Happy Numbers. That&amp;rsquo;s a little problem that fits well an interview style question, so I first solved it yesterday evening in Emacs Lisp as that&amp;rsquo;s the language I use the most those days.
 A happy number is defined by the following process.</description>
    </item>
    
    <item>
      <title>Playing with bit strings</title>
      <link>http://tapoueh.org/blog/2010/08/playing-with-bit-strings/</link>
      <pubDate>Thu, 26 Aug 2010 17:45:00 +0200</pubDate>
      
      <guid>http://tapoueh.org/blog/2010/08/playing-with-bit-strings/</guid>
      <description>The idea of the day ain&amp;rsquo;t directly from me, I&amp;rsquo;m just helping with a very thin subpart of the problem. The problem, I can&amp;rsquo;t say much about, let&amp;rsquo;s just assume you want to reduce the storage of MD5 in your database, so you want to abuse bit strings. A solution to use them works fine, but the datatype is still missing some facilities, for example going from and to hexadecimal representation in text.</description>
    </item>
    
    <item>
      <title>Editing constants in constraints</title>
      <link>http://tapoueh.org/blog/2010/08/editing-constants-in-constraints/</link>
      <pubDate>Mon, 09 Aug 2010 14:45:00 +0200</pubDate>
      
      <guid>http://tapoueh.org/blog/2010/08/editing-constants-in-constraints/</guid>
      <description>We&amp;rsquo;re using constants in some constraints here, for example in cases where several servers are replicating to the same federating one: each origin server has his own schema, and all is replicated nicely on the central host, thanks to Londiste, as you might have guessed already.
For bare-metal recovery scripts, I&amp;rsquo;m working on how to change those constants in the constraints, so that pg_dump -s plus some schema tweaking would kick-start a server.</description>
    </item>
    
    <item>
      <title>debian packaging PostgreSQL extensions</title>
      <link>http://tapoueh.org/blog/2010/08/debian-packaging-postgresql-extensions/</link>
      <pubDate>Fri, 06 Aug 2010 13:00:00 +0200</pubDate>
      
      <guid>http://tapoueh.org/blog/2010/08/debian-packaging-postgresql-extensions/</guid>
      <description>In trying to help an extension debian packaging effort, I&amp;rsquo;ve once again proposed to handle it. That&amp;rsquo;s because I now begin to know how to do it, as you can see in my package overview page at debian QA facility. There&amp;rsquo;s a reason why I proposed myself here, it&amp;rsquo;s that yet another tool of mine is now to be found in debian, and should greatly help extension packaging there. You can already check for the postgresql-server-dev-all package page if you&amp;rsquo;re that impatient!</description>
    </item>
    
    <item>
      <title>Querying the Catalog to plan an upgrade</title>
      <link>http://tapoueh.org/blog/2010/08/querying-the-catalog-to-plan-an-upgrade/</link>
      <pubDate>Thu, 05 Aug 2010 11:00:00 +0200</pubDate>
      
      <guid>http://tapoueh.org/blog/2010/08/querying-the-catalog-to-plan-an-upgrade/</guid>
      <description>Some user on IRC was reading the releases notes in order to plan for a minor upgrade of his 8.3.3 installation, and was puzzled about potential needs for rebuilding GIST indexes. That&amp;rsquo;s from the 8.3.5 release notes, and from the 8.3.8 notes you see that you need to consider hash indexes on interval columns too. Now the question is, how to find out if any such beasts are in use in your database?</description>
    </item>
    
    <item>
      <title>Database Virtual Machines</title>
      <link>http://tapoueh.org/blog/2010/08/database-virtual-machines/</link>
      <pubDate>Tue, 03 Aug 2010 13:30:00 +0200</pubDate>
      
      <guid>http://tapoueh.org/blog/2010/08/database-virtual-machines/</guid>
      <description>Today I&amp;rsquo;m being told once again about SQLite as an embedded database software. That one ain&amp;rsquo;t a database server but a software library that you can use straight into your main program. I&amp;rsquo;m yet to use it, but it looks like its SQL support is good enough for simple things — and that covers loads of things. I guess read-only cache and configuration storage would be the obvious ones, because it seems that SQLite use cases aren&amp;rsquo;t including mixed concurrency, that is workloads with concurrent readers and writers.</description>
    </item>
    
    <item>
      <title>Partitioning: relation size per “group”</title>
      <link>http://tapoueh.org/blog/2010/07/partitioning-relation-size-per-group/</link>
      <pubDate>Mon, 26 Jul 2010 17:00:00 +0200</pubDate>
      
      <guid>http://tapoueh.org/blog/2010/07/partitioning-relation-size-per-group/</guid>
      <description>This time, we are trying to figure out where is the bulk of the data on disk. The trick is that we&amp;rsquo;re using DDL partitioning, but we want a “nice” view of size per partition set. Meaning that if you have for example a parent table foo with partitions foo_201006 and foo_201007, you would want to see a single category foo containing the accumulated size of all the partitions underneath foo.</description>
    </item>
    
    <item>
      <title>Emacs and PostgreSQL</title>
      <link>http://tapoueh.org/blog/2010/07/emacs-and-postgresql/</link>
      <pubDate>Thu, 22 Jul 2010 09:30:00 +0200</pubDate>
      
      <guid>http://tapoueh.org/blog/2010/07/emacs-and-postgresql/</guid>
      <description>Those are my two all times favorite Open Source Software. Or Free Software in the GNU sense of the world, as both the BSD and the GPL are labeled free there. Even if I prefer the The Debian Free Software Guidelines as a global definition and the WTFPL license. But that&amp;rsquo;s a digression.
I think that Emacs and PostgreSQL do share a lot in common. I&amp;rsquo;d begin with the documentation, which quality is amazing for both projects.</description>
    </item>
    
    <item>
      <title>Background writers</title>
      <link>http://tapoueh.org/blog/2010/07/background-writers/</link>
      <pubDate>Mon, 19 Jul 2010 16:30:00 +0200</pubDate>
      
      <guid>http://tapoueh.org/blog/2010/07/background-writers/</guid>
      <description>There&amp;rsquo;s currently a thread on hackers about bg worker: overview and a series of 6 patches. Thanks a lot Markus! This is all about generalizing a concept already in use in the autovacuum process, where you have an independent subsystem that require having an autonomous daemon running and able to start its own workers.
I&amp;rsquo;ve been advocating about generalizing this concept for awhile already, in order to have postmaster able to communicate to subsystems when to shut down and start and reload, etc.</description>
    </item>
    
    <item>
      <title>Logs analysis</title>
      <link>http://tapoueh.org/blog/2010/07/logs-analysis/</link>
      <pubDate>Tue, 13 Jul 2010 14:15:00 +0200</pubDate>
      
      <guid>http://tapoueh.org/blog/2010/07/logs-analysis/</guid>
      <description>Nowadays to analyze logs and provide insights, the more common tool to use is pgfouine, which does an excellent job. But there has been some improvements in logs capabilities that we&amp;rsquo;re not benefiting from yet, and I&amp;rsquo;m thinking about the CSV log format.
So the idea would be to turn pgfouine into a set of SQL queries against the logs themselves once imported into the database. Wait. What about having our next PostgreSQL version, which is meant (I believe) to include CSV support in SQL/MED, to directly expose its logs as a system view?</description>
    </item>
    
    <item>
      <title>Using indexes as column store?</title>
      <link>http://tapoueh.org/blog/2010/07/using-indexes-as-column-store/</link>
      <pubDate>Thu, 08 Jul 2010 11:15:00 +0200</pubDate>
      
      <guid>http://tapoueh.org/blog/2010/07/using-indexes-as-column-store/</guid>
      <description>There&amp;rsquo;s a big trend nowadays about using column storage as opposed to what PostgreSQL is doing, which would be row storage. The difference is that if you have the same column value in a lot of rows, you could get to a point where you have this value only once in the underlying storage file. That means high compression. Then you tweak the executor to be able to load this value only once, not once per row, and you win another huge source of data traffic (often enough, from disk).</description>
    </item>
    
    <item>
      <title>MVCC in the Cloud</title>
      <link>http://tapoueh.org/blog/2010/07/mvcc-in-the-cloud/</link>
      <pubDate>Tue, 06 Jul 2010 10:50:00 +0200</pubDate>
      
      <guid>http://tapoueh.org/blog/2010/07/mvcc-in-the-cloud/</guid>
      <description>At CHAR(10) Markus had a talk about Using MVCC for Clustered Database Systems and explained how Postgres-R does it. The scope of his project is to maintain a set of database servers in the same state, eventually.
Now, what does it mean to get &amp;ldquo;In the Cloud&amp;rdquo;? Well there are more than one answer I&amp;rsquo;m sure, mine would insist on including this &amp;ldquo;Elasticity&amp;rdquo; bit. What I mean here is that it&amp;rsquo;d be great to be able to add or lose nodes and stay online.</description>
    </item>
    
    <item>
      <title>Back from CHAR(10)</title>
      <link>http://tapoueh.org/blog/2010/07/back-from-char10/</link>
      <pubDate>Mon, 05 Jul 2010 09:30:00 +0200</pubDate>
      
      <guid>http://tapoueh.org/blog/2010/07/back-from-char10/</guid>
      <description>It surely does not feel like a full month and some more went by since we were enjoying PGCon 2010, but in fact it was already the time for CHAR(10). The venue was most excellent, as Oxford is a very beautiful city. Also, the college was like a city in the city, and having the accomodation all in there really smoothed it all.
On a more technical viewpoint, the range of topics we talked about and the even broader one in the &amp;ldquo;Hall Track&amp;rdquo; make my mind full of ideas, again.</description>
    </item>
    
    <item>
      <title>Back from PgCon2010</title>
      <link>http://tapoueh.org/blog/2010/05/back-from-pgcon2010/</link>
      <pubDate>Thu, 27 May 2010 14:26:00 +0200</pubDate>
      
      <guid>http://tapoueh.org/blog/2010/05/back-from-pgcon2010/</guid>
      <description>This year&amp;rsquo;s edition has been the best pgcon ever for me. Granted, it&amp;rsquo;s only my third time, but still :) As Josh said the &amp;ldquo;Hall Track&amp;rdquo; in particular was very good, and the Dev Meeting has been very effective!
Extensions This time I prepared some slides to present the extension design and I tried hard to make it so that we get to agree on a plan, even recognizing it&amp;rsquo;s not solving all of our problems from the get go.</description>
    </item>
    
    <item>
      <title>Import fixed width data with pgloader</title>
      <link>http://tapoueh.org/blog/2010/04/import-fixed-width-data-with-pgloader/</link>
      <pubDate>Tue, 27 Apr 2010 12:01:00 +0200</pubDate>
      
      <guid>http://tapoueh.org/blog/2010/04/import-fixed-width-data-with-pgloader/</guid>
      <description>So, following previous blog entries about importing fixed width data, from Postgres Online Journal and David (perl) Fetter, I couldn&amp;rsquo;t resist following the meme and showing how to achieve the same thing with pgloader.
I can&amp;rsquo;t say how much I dislike such things as the following, and I can&amp;rsquo;t help thinking that non IT people are right looking at us like this when encountering such prose.
map {s/\D*(\d+)-(\d+).*/$a.=&amp;quot;A&amp;quot;.(1+$2-$1). &amp;quot; &amp;quot;/e} split(/\n/,&amp;lt;&amp;lt;&#39;EOT&#39;);  So, the pgloader way.</description>
    </item>
    
    <item>
      <title>pgloader activity report</title>
      <link>http://tapoueh.org/blog/2010/04/pgloader-activity-report/</link>
      <pubDate>Tue, 06 Apr 2010 09:10:00 +0200</pubDate>
      
      <guid>http://tapoueh.org/blog/2010/04/pgloader-activity-report/</guid>
      <description>Yes. This pgloader project is still maintained and somewhat active. Development happens when I receive a complaint, either about a bug in existing code or a feature in yet-to-write code. If you have a bug to report, just send me an email!
If you&amp;rsquo;re following the development of it, the sources just moved from CVS at pgfoundry to http://github.com/dimitri/pgloader. I will still put the releases at pgfoundry, and the existing binary packages maintenance should continue.</description>
    </item>
    
    <item>
      <title>Finding orphaned sequences</title>
      <link>http://tapoueh.org/blog/2010/03/finding-orphaned-sequences/</link>
      <pubDate>Wed, 17 Mar 2010 13:35:00 +0100</pubDate>
      
      <guid>http://tapoueh.org/blog/2010/03/finding-orphaned-sequences/</guid>
      <description>This time we&amp;rsquo;re having a database where sequences were used, but not systematically as a default value of a given column. It&amp;rsquo;s mainly an historic bad idea, but you know the usual excuse with bad ideas and bad code: the first 6 months it&amp;rsquo;s experimental, after that it&amp;rsquo;s historic.
Not talking about genome orphaned sequences here, though
Still, here&amp;rsquo;s a query for 8.4 that will allow you to list those sequences you have that are not used as a default value in any of your tables:</description>
    </item>
    
    <item>
      <title>Getting out of SQL_ASCII, part 2</title>
      <link>http://tapoueh.org/blog/2010/02/getting-out-of-sql_ascii-part-2/</link>
      <pubDate>Tue, 23 Feb 2010 17:30:00 +0100</pubDate>
      
      <guid>http://tapoueh.org/blog/2010/02/getting-out-of-sql_ascii-part-2/</guid>
      <description>So, if you followed the previous blog entry, now you have a new database containing all the static tables encoded in UTF-8 rather than SQL_ASCII. Because if it was not yet the case, you now severely distrust this non-encoding.
Now is the time to have a look at properly encoding the live data, those stored in tables that continue to receive write traffic. The idea is to use the UPDATE facilities of PostgreSQL to tweak the data, and too fix the applications so as not to continue inserting badly encoded strings in there.</description>
    </item>
    
    <item>
      <title>Getting out of SQL_ASCII, part 1</title>
      <link>http://tapoueh.org/blog/2010/02/getting-out-of-sql_ascii-part-1/</link>
      <pubDate>Thu, 18 Feb 2010 11:37:00 +0100</pubDate>
      
      <guid>http://tapoueh.org/blog/2010/02/getting-out-of-sql_ascii-part-1/</guid>
      <description>It happens that you have to manage databases designed by your predecessor, and it even happens that the team used to not have a DBA. Those histerical raisins can lead to having a SQL_ASCII database. The horror!
What SQL_ASCII means, if you&amp;rsquo;re not already familiar with the consequences of such a choice, is that all the text and varchar data that you put in the database is accepted as-is. No checks.</description>
    </item>
    
    <item>
      <title>Resetting sequences. All of them, please!</title>
      <link>http://tapoueh.org/blog/2010/02/resetting-sequences.-all-of-them-please/</link>
      <pubDate>Tue, 16 Feb 2010 16:23:00 +0100</pubDate>
      
      <guid>http://tapoueh.org/blog/2010/02/resetting-sequences.-all-of-them-please/</guid>
      <description>So, after restoring a production dump with intermediate filtering, none of our sequences were set to the right value. I could have tried to review the process of filtering the dump here, but it&amp;rsquo;s a one-shot action and you know what that sometimes mean. With some pressure you don&amp;rsquo;t script enough of it and you just crawl more and more.
Still, I think how I solved it is worthy of a blog entry.</description>
    </item>
    
    <item>
      <title>prefix 1.1.0</title>
      <link>http://tapoueh.org/blog/2009/11/prefix-1.1.0/</link>
      <pubDate>Mon, 30 Nov 2009 12:10:00 +0100</pubDate>
      
      <guid>http://tapoueh.org/blog/2009/11/prefix-1.1.0/</guid>
      <description>So I had two bug reports about prefix in less than a week. It means several things, one of them is that my code is getting used in the wild, which is nice. The other side of the coin is that people do find bugs in there. This one is about the behavior of the btree opclass of the type prefix range. We cheat a lot there by simply having written one, because a range does not have a strict ordering: is [1-3] before of after [2-4]?</description>
    </item>
    
    <item>
      <title>PGDay.eu, Paris: it was awesome!</title>
      <link>http://tapoueh.org/blog/2009/11/pgday.eu-paris-it-was-awesome/</link>
      <pubDate>Mon, 09 Nov 2009 09:50:00 +0100</pubDate>
      
      <guid>http://tapoueh.org/blog/2009/11/pgday.eu-paris-it-was-awesome/</guid>
      <description>moment. Lots of attendees, lots of quality talks ( slides are online), good food, great party: all the ingredients were there!
It also was for me the occasion to first talk about this tool I&amp;rsquo;ve been working on for months, called pg_staging, which aims to empower those boring production backups to help maintaining staging environments (for your developers and testers).
All in all such events keep reminding me what it means exactly when we way that one of the greatest things about PostgreSQL is its community.</description>
    </item>
    
    <item>
      <title>prefix 1.0.0</title>
      <link>http://tapoueh.org/blog/2009/10/prefix-1.0.0/</link>
      <pubDate>Tue, 06 Oct 2009 15:56:00 +0200</pubDate>
      
      <guid>http://tapoueh.org/blog/2009/10/prefix-1.0.0/</guid>
      <description>So there it is, at long last, the final 1.0.0 release of prefix! It&amp;rsquo;s on its way into the debian repository (targetting sid, in testing in 10 days) and available on pgfoundry to.
In order to make it clear that I intend to maintain this version, the number has 3 digits rather than 2&amp;hellip; which is also what PostgreSQL users will expect.
The only last minute change is that you can now use the first version of the two following rather than the second one:</description>
    </item>
    
    <item>
      <title>prefix 1.0~rc2-1</title>
      <link>http://tapoueh.org/blog/2009/07/prefix-1.0~rc2-1/</link>
      <pubDate>Thu, 09 Jul 2009 12:48:00 +0200</pubDate>
      
      <guid>http://tapoueh.org/blog/2009/07/prefix-1.0~rc2-1/</guid>
      <description>I&amp;rsquo;ve been having problem with building both postgresql-8.3-prefix and postgresql-8.4-prefix debian packages from the same source package, and fixing the packaging issue forced me into modifying the main prefix Makefile. So while reaching rc2, I tried to think about missing pieces easy to add this late in the game: and there&amp;rsquo;s one, that&amp;rsquo;s a function length(prefix_range), so that you don&amp;rsquo;t have to cast to text no more in the following wildspread query:</description>
    </item>
    
    <item>
      <title>prefix extension reaches 1.0 (rc1)</title>
      <link>http://tapoueh.org/blog/2009/06/prefix-extension-reaches-1.0-rc1/</link>
      <pubDate>Tue, 23 Jun 2009 10:53:00 +0200</pubDate>
      
      <guid>http://tapoueh.org/blog/2009/06/prefix-extension-reaches-1.0-rc1/</guid>
      <description>At long last, after millions and millions of queries just here at work and some more in other places, the prefix project is reaching 1.0 milestone. The release candidate is getting uploaded into debian at the moment of this writing, and available at the following place: prefix-1.0~rc1.tar.gz.
If you have any use for it (as some VoIP companies have already), please consider testing it, in order for me to release a shiny 1.</description>
    </item>
    
    <item>
      <title>PgCon 2009</title>
      <link>http://tapoueh.org/blog/2009/05/pgcon-2009/</link>
      <pubDate>Wed, 27 May 2009 14:30:00 +0200</pubDate>
      
      <guid>http://tapoueh.org/blog/2009/05/pgcon-2009/</guid>
      <description>I can&amp;rsquo;t really compare PgCon 2009 with previous years versions, last time I enjoyed the event it was in 2006, in Toronto. But still I found the experience to be a great one, and I hope I&amp;rsquo;ll be there next year too!
I&amp;rsquo;ve met a lot of known people in the community, some of them I already had the chance to run into at Toronto or Prato, but this was the first time I got to talk to many of them about interresting projects and ideas.</description>
    </item>
    
    <item>
      <title>Prepared Statements and pgbouncer</title>
      <link>http://tapoueh.org/blog/2009/05/prepared-statements-and-pgbouncer/</link>
      <pubDate>Thu, 14 May 2009 00:00:00 +0200</pubDate>
      
      <guid>http://tapoueh.org/blog/2009/05/prepared-statements-and-pgbouncer/</guid>
      <description>On the performance mailing list, a recent thread drew my attention. It devired to be about using a connection pool software and prepared statements in order to increase scalability of PostgreSQL when confronted to a lot of concurrent clients all doing simple select queries. The advantage of the pooler is to reduce the number of backends needed to serve the queries, thus reducing PostgreSQL internal bookkeeping. Of course, my choice of software here is clear: PgBouncer is an excellent top grade solution, performs real well (it won&amp;rsquo;t parse queries), reliable, flexible.</description>
    </item>
    
    <item>
      <title>Skytools 3.0 reaches alpha1</title>
      <link>http://tapoueh.org/blog/2009/04/skytools-3.0-reaches-alpha1/</link>
      <pubDate>Tue, 14 Apr 2009 00:00:00 +0200</pubDate>
      
      <guid>http://tapoueh.org/blog/2009/04/skytools-3.0-reaches-alpha1/</guid>
      <description>It&amp;rsquo;s time for Skytools news again! First, we did improve documentation of current stable branch with hosting high level presentations and tutorials on the PostgreSQL wiki. Do check out the Londiste Tutorial, it seems that&amp;rsquo;s what people hesitating to try out londiste were missing the most.
The other things people miss out a lot in current stable Skytools (version 2.1.9 currently) are cascading replication (which allows for switchover and failover) and DDL support.</description>
    </item>
    
    <item>
      <title>Prefix GiST index now in 8.1</title>
      <link>http://tapoueh.org/blog/2009/02/prefix-gist-index-now-in-8.1/</link>
      <pubDate>Tue, 10 Feb 2009 00:00:00 +0100</pubDate>
      
      <guid>http://tapoueh.org/blog/2009/02/prefix-gist-index-now-in-8.1/</guid>
      <description>The prefix project is about matching a literal against prefixes in your table, the typical example being a telecom routing table. Thanks to the excellent work around generic indexes in PostgreSQL with GiST, indexing prefix matches is easy to support in an external module. Which is what the prefix extension is all about.
Maybe you didn&amp;rsquo;t come across this project before, so here&amp;rsquo;s the typical query you want to run to benefit from the special indexing, where the @&amp;gt; operator is read contains or is a prefix of:</description>
    </item>
    
    <item>
      <title>Importing XML content from file</title>
      <link>http://tapoueh.org/blog/2009/02/importing-xml-content-from-file/</link>
      <pubDate>Thu, 05 Feb 2009 00:00:00 +0100</pubDate>
      
      <guid>http://tapoueh.org/blog/2009/02/importing-xml-content-from-file/</guid>
      <description>The problem was raised this week on IRC and this time again I felt it would be a good occasion for a blog entry: how to load an XML file content into a single field?
The usual tool used to import files is COPY, but it&amp;rsquo;ll want each line of the file to host a text representation of a database tuple, so it doesn&amp;rsquo;t apply to the case at hand. RhodiumToad was online and offered the following code to solve the problem:</description>
    </item>
    
    <item>
      <title>Asko Oja talks about Skype architecture</title>
      <link>http://tapoueh.org/blog/2009/02/asko-oja-talks-about-skype-architecture/</link>
      <pubDate>Wed, 04 Feb 2009 00:00:00 +0100</pubDate>
      
      <guid>http://tapoueh.org/blog/2009/02/asko-oja-talks-about-skype-architecture/</guid>
      <description>In this russian page you&amp;rsquo;ll see a nice presentation of Skype databases architectures by Asko Oja himself. It&amp;rsquo;s the talk at Russian PostgreSQL Community meeting, October 2008, Moscow, and it&amp;rsquo;s a good read.
   
The presentation page is in russian but the slides are in English, so have a nice read!</description>
    </item>
    
    <item>
      <title>Comparing Londiste and Slony</title>
      <link>http://tapoueh.org/blog/2009/01/comparing-londiste-and-slony/</link>
      <pubDate>Sat, 31 Jan 2009 00:00:00 +0100</pubDate>
      
      <guid>http://tapoueh.org/blog/2009/01/comparing-londiste-and-slony/</guid>
      <description>In the page about Skytools I&amp;rsquo;ve encouraged people to ask some more questions in order for me to be able to try and answer them. That just happened, as usual on the #postgresql IRC, and the question is What does londiste lack that slony has?</description>
    </item>
    
    <item>
      <title>Controling HOT usage in 8.3</title>
      <link>http://tapoueh.org/blog/2009/01/controling-hot-usage-in-8.3/</link>
      <pubDate>Wed, 28 Jan 2009 00:00:00 +0100</pubDate>
      
      <guid>http://tapoueh.org/blog/2009/01/controling-hot-usage-in-8.3/</guid>
      <description>As it happens, I&amp;rsquo;ve got some environments where I want to make sure HOT ( aka Heap Only Tuples) is in use. Because we&amp;rsquo;re doing so much updates a second that I want to get sure it&amp;rsquo;s not killing my database server. I not only wrote some checking view to see about it, but also made a quick article about it in the French PostgreSQL website. Handling around in #postgresql means that I&amp;rsquo;m now bound to write about it in English too!</description>
    </item>
    
    <item>
      <title>Londiste Trick</title>
      <link>http://tapoueh.org/blog/2009/01/londiste-trick/</link>
      <pubDate>Wed, 21 Jan 2009 00:00:00 +0100</pubDate>
      
      <guid>http://tapoueh.org/blog/2009/01/londiste-trick/</guid>
      <description>So, you&amp;rsquo;re using londiste and the ticker has not been running all night long, due to some restart glitch in your procedures, and the on call admin didn&amp;rsquo;t notice the restart failure. If you blindly restart the replication daemon, it will load in memory all those events produced during the night, at once, because you now have only one tick where to put them all.
The following query allows you to count how many events that represents, with the magic tick numbers coming from pgq.</description>
    </item>
    
    <item>
      <title>Fake entry</title>
      <link>http://tapoueh.org/blog/2008/12/fake-entry/</link>
      <pubDate>Thu, 04 Dec 2008 00:00:00 +0100</pubDate>
      
      <guid>http://tapoueh.org/blog/2008/12/fake-entry/</guid>
      <description>This is a test of a fake entry to see how muse will manage this.
With some SQL inside:
 SELECT * FROM planet.postgresql.org WHERE author = &amp;quot;dim&amp;quot;; 
 </description>
    </item>
    
  </channel>
</rss>