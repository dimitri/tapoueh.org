#author Dimitri Fontaine
#title tail -f /dev/dim
#desc dim's PostgreSQL blog

* 20090131 Comparing Londiste and Slony

In the page about [[skytools.html][Skytools]] I've encouraged people to ask some more questions
in order for me to be able to try and answer them. That just happened, as
usual on the =#postgresql= IRC, and the question is
[[skytools.html#slony][What does londiste lack that slony has?]]

#20090128

* 20090128 Controling HOT usage in 8.3

As it happens, I've got some environments where I want to make sure =HOT= (*aka
Heap Only Tuples*) is in use. Because we're doing so much updates a second
that I want to get sure it's not killing my database server. I not only
wrote some checking view to see about it, but also made a [[http://www.postgresql.fr/support:trucs_et_astuces:controler_l_utilisation_de_hot_a_partir_de_la_8.3][quick article]]
about it in the [[http://postgresql.fr/][French PostgreSQL website]]. Handling around in =#postgresql=
means that I'm now bound to write about it in English too!

So =HOT= will get used each time you update a row without changing an indexed
value of it, and the benefit is skipping index maintenance, and as far as I
understand it, easying =vacuum= hard work too. To get the benefit, =HOT= will
need some place where to put new version of the =UPDATEd= tuple in the same
disk page, which means you'll probably want to set your table [[http://www.postgresql.org/docs/8.3/static/sql-createtable.html#SQL-CREATETABLE-STORAGE-PARAMETERS][fillfactor]] to
something much less than =100=.

Now, here's how to check you're benefitting from =HOT=:

<src lang="sql">
SELECT schemaname, relname,
       n_tup_upd,n_tup_hot_upd,
       case when n_tup_upd > 0
            then ((n_tup_hot_upd::numeric/n_tup_upd::numeric)*100.0)::numeric(5,2) 
            else NULL
       end AS hot_ratio
 
 FROM pg_stat_all_tables;
 
 schemaname | relname | n_tup_upd | n_tup_hot_upd | hot_ratio
------------+---------+-----------+---------------+-----------
 public     | table1  |         6 |             6 |    100.00
 public     | table2  |   2551200 |       2549474 |     99.93
</src>

Here's even an extended version of the same request, displaying the
=fillfactor= option value for the tables you're inquiring about. This comes
separated from the first example because you get the =fillfactor= of a
relation into the =pg_class= catalog =reloptions= field, and to filter against a
schema qualified table name, you want to join against =pg_namespace= too.

<src lang="sql">
SELECT t.schemaname, t.relname, c.reloptions, 
       t.n_tup_upd, t.n_tup_hot_upd, 
       case when n_tup_upd > 0 
            then ((n_tup_hot_upd::numeric/n_tup_upd::numeric)*100.0)::numeric(5,2)
            else NULL
        end AS hot_ratio
FROM pg_stat_all_tables t 
      JOIN (pg_class c JOIN pg_namespace n ON c.relnamespace = n.oid) 
        ON n.nspname = t.schemaname AND c.relname = t.relname
 
 schemaname | relname |   reloptions    | n_tup_upd | n_tup_hot_upd | hot_ratio
------------+---------+-----------------+-----------+---------------+-----------
 public     | table1  | {fillfactor=50} |   1585920 |       1585246 |     99.96
 public     | table2  | {fillfactor=50} |   2504880 |       2503154 |     99.93
</src>

Don't let the =HOT= question affect your sleeping no more!

#20090121

* 20090121 Londiste Trick

So, you're using =londiste= and the =ticker= has not been running all night
long, due to some restart glitch in your procedures, and the *on call* admin
didn't notice the restart failure. If you blindly restart the replication
daemon, it will load in memory all those events produced during the night,
at once, because you now have only one tick where to put them all.

The following query allows you to count how many events that represents,
with the magic tick numbers coming from =pgq.subscription= in columns
=sub_last_tick= and =sub_next_tick=.

<src lang="sql">
SELECT count(*) 
  FROM pgq.event_1, 
      (SELECT tick_snapshot
         FROM pgq.tick
        WHERE tick_id BETWEEN 5715138 AND 5715139
      ) as t(snapshots)
WHERE txid_visible_in_snapshot(ev_txid, snapshots);
</src>

In our case, this was more than *5 millions and 400 thousands* of events. With
this many events to care about, if you start londiste, it'll eat as many
memory as needed to have them all around, which might be more that what your
system is able to give it. So you want a way to tell =londiste= not to load
all events at once. Here's how: add the following knob to your *.ini*
configuration file before to restart the londiste daemon:

<src>
    pgq_lazy_fetch = 500
</src>

Now, =londiste= will lazyly fetch =500= events at once or less, even if a single
=batch= (which contains all *events* between two *ticks*) contains a huge number
of events. This number seems a good choice as it's the default =PGQ= setting
of number of events in a single *batch*. This number is only outgrown when the
ticker is not running or when you're producing more *events* than that in a
single transaction.

Hope you'll find the tip useful!


#20081204

* 20081204 Fake entry

This is a test of a fake entry to see how muse will manage this.

With some =SQL= inside:

<quote>
<src lang="sql">
SELECT * FROM planet.postgresql.org WHERE author = "dim";
</src>
</quote>
